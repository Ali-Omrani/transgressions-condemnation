{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3cb2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6ad8c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ta_joe_severity_r4',\n",
       " 'ta_negin_severity_r5',\n",
       " 'ta_sanjna_severity_r4_review',\n",
       " 'ta_joe_severity_r1',\n",
       " 'ta_xiaoyan_severity_r6',\n",
       " 'ta_jillian_severity_r2',\n",
       " 'ta_negin_severity_r4_review',\n",
       " 'ta_xiaoyan_severity_r6_review',\n",
       " 'ta_joe_severity_r2',\n",
       " 'ta_xiaoyan_severity_r3',\n",
       " 'ta_xiaoyan_severity_r5',\n",
       " 'ta_sanjna_severity_r1',\n",
       " 'ta_nour_severity_r1',\n",
       " 'ta_joe_target_severity_r3',\n",
       " 'ta_sanjna_severity_r3',\n",
       " 'ta_sanjna_severity_r6_review',\n",
       " 'ta_sanjna_severity_r2',\n",
       " 'ta_mcgill_severity_r4_review',\n",
       " 'ta_sanjna_severity_r4',\n",
       " 'ta_nour_severity_r2',\n",
       " 'ta_negin_severity_r1',\n",
       " 'ta_sanjna_severity_r5',\n",
       " 'ta_jillian_severity_r1',\n",
       " 'ta_sanjna_severity_r6',\n",
       " 'ta_negin_severity_r3',\n",
       " 'ta_xiaoyan_severity_r1',\n",
       " 'ta_joe_severity_training_r1',\n",
       " 'ta_xiaoyan_severity_r4_review',\n",
       " 'ta_xiaoyan_severity_r4',\n",
       " 'ta_xiaoyan_severity_r2',\n",
       " 'ta_joe_severity_r3',\n",
       " 'ta_negin_severity_r4',\n",
       " 'ta_negin_severity_r2']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"./severity_dumps/\"\n",
    "filenames = os.listdir(data_dir)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a451397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ds_by_keyword(data_dir, keyword, cols=['text', 'meta', 'label', 'accept', 'answer']):\n",
    "    filenames = os.listdir(data_dir)\n",
    "    filtered_fns = [name for name in filenames if keyword in name]\n",
    "    datasets = {}\n",
    "    for filename in filtered_fns:\n",
    "        ds = pd.DataFrame(pickle.load(open(os.path.join(data_dir, filename), \"rb\")))\n",
    "        datasets[filename] = ds\n",
    "#         print(ds.columns)\n",
    "#         print(\"{} has {} annotations\".format(filename, len(datasets[filename])))\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d51e291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 25.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "skipping ta_joe_severity_training_r1\n",
      "********************\n",
      "********************\n",
      "skipping ta_joe_target_severity_r3\n",
      "********************\n",
      "********************\n",
      "ta_joe_severity_r3 has no meta but has 0 records\n",
      "********************\n",
      "********************\n",
      "skipping ta_sanjna_severity_r4_review\n",
      "********************\n",
      "********************\n",
      "skipping ta_negin_severity_r4_review\n",
      "********************\n",
      "********************\n",
      "skipping ta_mcgill_severity_r4_review\n",
      "********************\n",
      "********************\n",
      "skipping ta_xiaoyan_severity_r4_review\n",
      "********************\n",
      "********************\n",
      "ta_negin_severity_r5 has no meta but has 0 records\n",
      "********************\n",
      "********************\n",
      "ta_xiaoyan_severity_r5 has no meta but has 0 records\n",
      "********************\n",
      "********************\n",
      "ta_sanjna_severity_r5 has no meta but has 0 records\n",
      "********************\n",
      "********************\n",
      "skipping ta_xiaoyan_severity_r6_review\n",
      "********************\n",
      "********************\n",
      "skipping ta_sanjna_severity_r6_review\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cleaning annotations\n",
    "round_data_dict = {}\n",
    "for i in tqdm(range(1, 7)):\n",
    "    round_title = \"r\"+str(i)\n",
    "    round_data_dict[round_title] = load_ds_by_keyword(data_dir, round_title)\n",
    "    keys_to_pop = []\n",
    "    for annotator_file in round_data_dict[round_title].keys():\n",
    "#         print(annotator_file)\n",
    "    \n",
    "        if len(annotator_file.split(\"_\"))>4:\n",
    "            print(\"*\"*20)\n",
    "            print(\"skipping {}\".format(annotator_file))\n",
    "            print(\"*\"*20)\n",
    "            keys_to_pop.append(annotator_file)\n",
    "            continue\n",
    "        \n",
    "        curr_df = round_data_dict[round_title][annotator_file] \n",
    "        if \"meta\" not in curr_df.columns:\n",
    "            print(\"*\"*20)\n",
    "            print(\"{} has no meta but has {} records\".format(annotator_file, len(curr_df)))\n",
    "            print(\"*\"*20)\n",
    "            keys_to_pop.append(annotator_file)\n",
    "            continue\n",
    "        tweet_ids = [item[\"tweet_id\"] for item in curr_df[\"meta\"]]\n",
    "        curr_df[\"tweet_id\"] = tweet_ids\n",
    "        annotator = annotator_file.split(\"_\")[1]\n",
    "        curr_df[\"annotator\"] = [annotator]*len(curr_df)\n",
    "        curr_df[\"round\"] = [round_title]*len(curr_df)\n",
    "\n",
    "        round_data_dict[round_title][annotator_file] = curr_df[[\"tweet_id\", \"annotator\", \"round\", \"text\", \"label\", \"accept\"]]\n",
    "    for key in keys_to_pop:\n",
    "        round_data_dict[round_title].pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9f79429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>round</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>925856978475171841</td>\n",
       "      <td>xiaoyan</td>\n",
       "      <td>r1</td>\n",
       "      <td>Here we go again. Yet another LIBERAL accused ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>930292240416731137</td>\n",
       "      <td>xiaoyan</td>\n",
       "      <td>r1</td>\n",
       "      <td>I remember when everyone was dickriding -JOHN ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>918439998898294784</td>\n",
       "      <td>xiaoyan</td>\n",
       "      <td>r1</td>\n",
       "      <td>I'm a Matt Damon fan, can't even believe he wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>921475052125614080</td>\n",
       "      <td>xiaoyan</td>\n",
       "      <td>r1</td>\n",
       "      <td>Darn it. I was hoping a generation of tech emp...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>929109853267746818</td>\n",
       "      <td>xiaoyan</td>\n",
       "      <td>r1</td>\n",
       "      <td>Moore, &lt;OTHER TARGET 2&gt;, -JOHN DOE-, Mueller, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>929015378600124418</td>\n",
       "      <td>xiaoyan</td>\n",
       "      <td>r1</td>\n",
       "      <td>If proven true, id not only disqualify Moore, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>929176298630647808</td>\n",
       "      <td>xiaoyan</td>\n",
       "      <td>r1</td>\n",
       "      <td>&lt;OTHER TARGET 2&gt;, Polansky, Allen, -JOHN DOE-,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>929176298630647808</td>\n",
       "      <td>xiaoyan</td>\n",
       "      <td>r1</td>\n",
       "      <td>-JOHN DOE-, Polansky, Allen, &lt;OTHER TARGET 1&gt;,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>922904919081963520</td>\n",
       "      <td>xiaoyan</td>\n",
       "      <td>r1</td>\n",
       "      <td>\"-JOHN DOE-\" is the kind of person we don't ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>929177717332787200</td>\n",
       "      <td>xiaoyan</td>\n",
       "      <td>r1</td>\n",
       "      <td>*Sees -JOHN DOE- trending* please dont be dead...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id annotator round  \\\n",
       "0    925856978475171841   xiaoyan    r1   \n",
       "1    930292240416731137   xiaoyan    r1   \n",
       "2    918439998898294784   xiaoyan    r1   \n",
       "3    921475052125614080   xiaoyan    r1   \n",
       "4    929109853267746818   xiaoyan    r1   \n",
       "..                  ...       ...   ...   \n",
       "140  929015378600124418   xiaoyan    r1   \n",
       "141  929176298630647808   xiaoyan    r1   \n",
       "142  929176298630647808   xiaoyan    r1   \n",
       "143  922904919081963520   xiaoyan    r1   \n",
       "144  929177717332787200   xiaoyan    r1   \n",
       "\n",
       "                                                  text  label  accept  \n",
       "0    Here we go again. Yet another LIBERAL accused ...      1  [1, 6]  \n",
       "1    I remember when everyone was dickriding -JOHN ...      1  [1, 7]  \n",
       "2    I'm a Matt Damon fan, can't even believe he wa...      1  [1, 2]  \n",
       "3    Darn it. I was hoping a generation of tech emp...      1  [1, 4]  \n",
       "4    Moore, <OTHER TARGET 2>, -JOHN DOE-, Mueller, ...      1  [1, 3]  \n",
       "..                                                 ...    ...     ...  \n",
       "140  If proven true, id not only disqualify Moore, ...      1  [1, 8]  \n",
       "141  <OTHER TARGET 2>, Polansky, Allen, -JOHN DOE-,...      1  [1, 3]  \n",
       "142  -JOHN DOE-, Polansky, Allen, <OTHER TARGET 1>,...      1  [1, 3]  \n",
       "143  \"-JOHN DOE-\" is the kind of person we don't ne...      1  [1, 8]  \n",
       "144  *Sees -JOHN DOE- trending* please dont be dead...      1  [1, 7]  \n",
       "\n",
       "[145 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_data_dict[\"r1\"][\"ta_xiaoyan_severity_r1\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdba36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_ids(df):\n",
    "    print(df.columns)\n",
    "    print(\"total_records {}\".format(len(df)))\n",
    "    if \"label\" in df.columns:\n",
    "        print(\"label==1 {}\".format(sum(df.label)))\n",
    "    else:\n",
    "        print(\"no label col\")\n",
    "#         print(df.columns)\n",
    "        print(\"answer==accept {}\".format(sum(df.answer==\"accept\")))\n",
    "\n",
    "    print(\"-\"*30)\n",
    "    try:\n",
    "        tweet_ids = [m[\"tweet_id\"] for m in df.meta]\n",
    "        df[\"tweet_id\"] = tweet_ids\n",
    "        return tweet_ids\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "922a58ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'annotator', 'text', 'label', 'accept'], dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# curr_df[\"tweet_id\"] = curr_df[\"meta\"][\"tweet_id\"]\n",
    "round_data_dict[\"r1\"][\"ta_joe_severity_r1\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fee50d58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r1_filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-8c8dddf379c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mr1_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr1_filenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mr1_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r1_filenames' is not defined"
     ]
    }
   ],
   "source": [
    "r1_datasets = {}\n",
    "for filename in r1_filenames:\n",
    "    \n",
    "    r1_datasets[filename] = pickle.load(open(os.path.join(data_dir, filename), \"rb\"))\n",
    "    print(filename, len(r1_datasets[filename]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a863812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ta_joe_severity_r1', 'ta_sanjna_severity_r1', 'ta_nour_severity_r1', 'ta_negin_severity_r1', 'ta_jillian_severity_r1', 'ta_xiaoyan_severity_r1', 'ta_joe_severity_training_r1'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d68432b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'meta', 'spans', 'label', 'accept', '_input_hash', '_task_hash', 'options', '_session_id', '_view_id', 'answer'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_datasets[\"ta_joe_severity_r1\"][0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f6d5a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet_id': '925856978475171841',\n",
       " 'mask_map': {'<TARGET 1>': 'Michael Oreskes'},\n",
       " 'pattern_match': True,\n",
       " 'target_label': '<TARGET 1>',\n",
       " 'target': 'Michael Oreskes'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_datasets[\"ta_joe_severity_r1\"][0][\"meta\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aef5f990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, '2']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_datasets[\"ta_joe_severity_r1\"][2][\"accept\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b291c4ca",
   "metadata": {},
   "source": [
    "# plan to clean\n",
    "- [ ] go over rounds, on each round collect all items\n",
    "- [ ] take majority vote (look into the paper and see what the did)\n",
    "- [ ] based on tweet id, extract text, maj_vote, tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632dfa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transgression-env",
   "language": "python",
   "name": "transgression-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
