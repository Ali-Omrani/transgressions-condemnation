{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592fc393",
   "metadata": {},
   "source": [
    "# Condemnation Inference\n",
    "This notebook will hold the code for inferring condemnation on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf91aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datasets import Value\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import IPython\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e0d1c5",
   "metadata": {},
   "source": [
    "## Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d6fef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db_metoo_tweets = client[\"jason_twitter\"]\n",
    "metoo_tweets = db_metoo_tweets.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d91297",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cursor = metoo_tweets.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f8b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "model_path = \"./models/hf\"\n",
    "\n",
    "# model = torch.load(model_path)\n",
    "# model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1772d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(cursor, n):\n",
    "        result = []\n",
    "        for tweet in tqdm(cursor):\n",
    "            result.append(tweet)\n",
    "            if len(result)==n:\n",
    "                result_to_return = result\n",
    "                result = []\n",
    "                yield result_to_return\n",
    "        yield result\n",
    "        \n",
    "def update_tweet_in_db( document):\n",
    "    try:\n",
    "        metoo_tweets.update_one(\n",
    "            {'_id': document['_id']},\n",
    "            {'$set': document}\n",
    "        )\n",
    "    except Exception:\n",
    "        print(\"couldn't update \", document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea3f8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"exp/bart/results\",\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=128,\n",
    "    gradient_accumulation_steps=2,\n",
    "    eval_accumulation_steps=1,\n",
    ")\n",
    "# training_args = TrainingArguments(\"test-trainer\")\n",
    "# training_args.eval_accumulation_steps = 1  # pushes predictions out of GPU to mitigate GPU out of memory\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"models/hf/hf_fold_{}_model./\"),\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed6ed3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "102it [00:00, 230.14it/s]\u001b[A\n",
      "3360it [00:00, 4799.95it/s]\u001b[A\n",
      "6887it [00:01, 6321.49it/s]\u001b[A\n",
      "10003it [00:01, 6390.82it/s]\u001b[A\n",
      "13238it [00:02, 6159.03it/s]\u001b[A\n",
      "16408it [00:02, 5601.37it/s]\u001b[A\n",
      "19612it [00:03, 7049.39it/s]\u001b[A\n",
      "22795it [00:03, 5652.12it/s]\u001b[A\n",
      "25961it [00:04, 7040.67it/s]\u001b[A\n",
      "29123it [00:04, 8485.89it/s]\u001b[A\n",
      "32250it [00:05, 5688.13it/s]\u001b[A\n",
      "35412it [00:05, 7063.42it/s]\u001b[A\n",
      "38532it [00:05, 8397.69it/s]\u001b[A\n",
      "41667it [00:06, 5147.42it/s]\u001b[A\n",
      "44812it [00:07, 6459.06it/s]\u001b[A\n",
      "47910it [00:07, 7808.83it/s]\u001b[A\n",
      "51067it [00:07, 9190.99it/s]\u001b[A\n",
      "54221it [00:08, 4762.81it/s]\u001b[A\n",
      "57435it [00:09, 6100.48it/s]\u001b[A\n",
      "60677it [00:09, 7607.04it/s]\u001b[A\n",
      "63940it [00:09, 9181.44it/s]\u001b[A\n",
      "67241it [00:11, 4309.81it/s]\u001b[A\n",
      "70601it [00:11, 5635.92it/s]\u001b[A\n",
      "73878it [00:11, 7095.24it/s]\u001b[A\n",
      "77122it [00:11, 8587.69it/s]\u001b[A\n",
      "80440it [00:11, 10229.90it/s]\u001b[A\n",
      "83764it [00:12, 11769.96it/s]\u001b[A\n",
      "87085it [00:14, 4040.31it/s] \u001b[A\n",
      "90446it [00:14, 5268.29it/s]\u001b[A\n",
      "93664it [00:14, 6574.40it/s]\u001b[A\n",
      "96911it [00:14, 8019.19it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1237da4f6704c348d62e99f344474cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22144' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [391/391 4:19:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "96911it [00:31, 8019.19it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "1it [05:18, 318.81s/it]\n",
      "100000it [05:18, 35.20it/s] \u001b[A\n",
      "100148it [05:19, 35.86it/s]\u001b[A\n",
      "103375it [05:19, 57.35it/s]\u001b[A\n",
      "106558it [05:19, 87.55it/s]\u001b[A\n",
      "109763it [05:19, 130.78it/s]\u001b[A\n",
      "112929it [05:19, 191.37it/s]\u001b[A\n",
      "116167it [05:22, 260.86it/s]\u001b[A\n",
      "119447it [05:22, 378.24it/s]\u001b[A\n",
      "122696it [05:22, 541.39it/s]\u001b[A\n",
      "125911it [05:23, 766.40it/s]\u001b[A\n",
      "129041it [05:23, 1067.71it/s]\u001b[A\n",
      "132166it [05:23, 1477.31it/s]\u001b[A\n",
      "135345it [05:23, 2034.46it/s]\u001b[A\n",
      "138552it [05:23, 2768.72it/s]\u001b[A\n",
      "141688it [05:24, 3670.73it/s]\u001b[A\n",
      "144835it [05:27, 1951.83it/s]\u001b[A\n",
      "147968it [05:27, 2639.58it/s]\u001b[A\n",
      "151242it [05:27, 3561.80it/s]\u001b[A\n",
      "154573it [05:28, 4700.81it/s]\u001b[A\n",
      "157833it [05:28, 5973.18it/s]\u001b[A\n",
      "161010it [05:28, 7307.82it/s]\u001b[A\n",
      "164219it [05:28, 8731.34it/s]\u001b[A\n",
      "167480it [05:28, 10165.97it/s]\u001b[A\n",
      "170758it [05:29, 11499.67it/s]\u001b[A\n",
      "173942it [05:29, 12488.42it/s]\u001b[A\n",
      "177190it [05:29, 13443.73it/s]\u001b[A\n",
      "180422it [05:29, 14180.43it/s]\u001b[A\n",
      "183591it [05:33, 2263.30it/s] \u001b[A\n",
      "186675it [05:34, 3004.02it/s]\u001b[A\n",
      "189888it [05:34, 3954.54it/s]\u001b[A\n",
      "193121it [05:34, 5087.56it/s]\u001b[A\n",
      "196323it [05:34, 6327.76it/s]\u001b[A\n",
      "199517it [05:34, 7704.24it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afed01323a25486093332446fd229210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "199517it [05:53, 7704.24it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "2it [09:44, 287.64s/it]\n",
      "200000it [09:44, 31.71it/s]  \u001b[A\n",
      "202681it [09:44, 46.94it/s]\u001b[A\n",
      "205946it [09:45, 73.39it/s]\u001b[A\n",
      "209098it [09:45, 109.72it/s]\u001b[A\n",
      "212025it [09:45, 157.64it/s]\u001b[A\n",
      "215239it [09:45, 232.28it/s]\u001b[A\n",
      "218369it [09:50, 290.07it/s]\u001b[A\n",
      "221606it [09:50, 419.97it/s]\u001b[A\n",
      "224810it [09:50, 599.82it/s]\u001b[A\n",
      "228038it [09:51, 852.26it/s]\u001b[A\n",
      "231288it [09:51, 1199.76it/s]\u001b[A\n",
      "234552it [09:51, 1674.04it/s]\u001b[A\n",
      "237698it [09:51, 2279.57it/s]\u001b[A\n",
      "240925it [09:51, 3069.56it/s]\u001b[A\n",
      "244176it [09:52, 4064.03it/s]\u001b[A\n",
      "247400it [09:52, 5224.13it/s]\u001b[A\n",
      "250631it [09:52, 6564.59it/s]\u001b[A\n",
      "253879it [09:52, 8048.79it/s]\u001b[A\n",
      "257057it [09:52, 9508.93it/s]\u001b[A\n",
      "260206it [09:53, 10551.18it/s]\u001b[A\n",
      "263307it [09:53, 11513.83it/s]\u001b[A\n",
      "266574it [09:53, 12670.99it/s]\u001b[A\n",
      "269838it [09:53, 13833.88it/s]\u001b[A\n",
      "273086it [09:53, 14544.65it/s]\u001b[A\n",
      "276327it [09:59, 1661.80it/s] \u001b[A\n",
      "279595it [09:59, 2283.68it/s]\u001b[A\n",
      "282849it [10:00, 3080.80it/s]\u001b[A\n",
      "286119it [10:00, 4097.94it/s]\u001b[A\n",
      "289462it [10:00, 5332.36it/s]\u001b[A\n",
      "292784it [10:00, 6753.01it/s]\u001b[A\n",
      "296099it [10:00, 8244.40it/s]\u001b[A\n",
      "299429it [10:01, 9737.10it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7a5e53550d4648bf16b07502b77e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "299429it [10:13, 9737.10it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "3it [13:54, 270.52s/it]\n",
      "300000it [13:54, 35.37it/s]  \u001b[A\n",
      "302748it [13:54, 52.06it/s]\u001b[A\n",
      "306019it [13:55, 80.38it/s]\u001b[A\n",
      "309324it [13:55, 121.10it/s]\u001b[A\n",
      "312629it [13:55, 178.92it/s]\u001b[A\n",
      "315936it [13:55, 260.79it/s]\u001b[A\n",
      "319253it [13:55, 376.70it/s]\u001b[A\n",
      "322507it [13:56, 536.17it/s]\u001b[A\n",
      "325727it [13:56, 756.34it/s]\u001b[A\n",
      "328943it [13:59, 829.41it/s]\u001b[A\n",
      "332089it [13:59, 1152.69it/s]\u001b[A\n",
      "335324it [13:59, 1603.01it/s]\u001b[A\n",
      "338640it [13:59, 2220.27it/s]\u001b[A\n",
      "341943it [14:00, 3004.14it/s]\u001b[A\n",
      "345307it [14:00, 4014.07it/s]\u001b[A\n",
      "348619it [14:00, 5180.50it/s]\u001b[A\n",
      "351990it [14:00, 6577.19it/s]\u001b[A\n",
      "355309it [14:00, 8042.65it/s]\u001b[A\n",
      "358620it [14:01, 9384.13it/s]\u001b[A\n",
      "361978it [14:01, 10874.32it/s]\u001b[A\n",
      "365322it [14:05, 2505.17it/s] \u001b[A\n",
      "368688it [14:05, 3381.95it/s]\u001b[A\n",
      "372019it [14:05, 4455.54it/s]\u001b[A\n",
      "375302it [14:05, 5693.42it/s]\u001b[A\n",
      "378670it [14:05, 7102.03it/s]\u001b[A\n",
      "381990it [14:06, 8573.98it/s]\u001b[A\n",
      "385252it [14:06, 9858.48it/s]\u001b[A\n",
      "388592it [14:06, 11218.04it/s]\u001b[A\n",
      "391905it [14:06, 12507.91it/s]\u001b[A\n",
      "395234it [14:06, 13649.52it/s]\u001b[A\n",
      "398565it [14:07, 14616.82it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095b73f2e3954e1bbe63007d30562ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "398565it [14:25, 14616.82it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "4it [18:07, 263.39s/it]\n",
      "400000it [18:07, 38.18it/s]   \u001b[A\n",
      "401871it [18:07, 49.23it/s]\u001b[A\n",
      "405173it [18:07, 77.07it/s]\u001b[A\n",
      "408383it [18:07, 115.54it/s]\u001b[A\n",
      "411637it [18:08, 170.95it/s]\u001b[A\n",
      "414794it [18:08, 247.09it/s]\u001b[A\n",
      "417975it [18:08, 355.47it/s]\u001b[A\n",
      "421247it [18:08, 512.31it/s]\u001b[A\n",
      "424574it [18:08, 734.76it/s]\u001b[A\n",
      "427845it [18:09, 1036.95it/s]\u001b[A\n",
      "430963it [18:09, 1429.99it/s]\u001b[A\n",
      "434059it [18:09, 1954.51it/s]\u001b[A\n",
      "436971it [18:09, 2592.69it/s]\u001b[A\n",
      "439987it [18:09, 3441.49it/s]\u001b[A\n",
      "443060it [18:15, 1377.22it/s]\u001b[A\n",
      "446257it [18:15, 1921.46it/s]\u001b[A\n",
      "449293it [18:15, 2592.85it/s]\u001b[A\n",
      "452420it [18:15, 3478.56it/s]\u001b[A\n",
      "455629it [18:15, 4597.90it/s]\u001b[A\n",
      "458780it [18:16, 5870.25it/s]\u001b[A\n",
      "461951it [18:16, 7273.03it/s]\u001b[A\n",
      "464964it [18:16, 8552.72it/s]\u001b[A\n",
      "467943it [18:16, 9773.90it/s]\u001b[A\n",
      "470972it [18:16, 10955.94it/s]\u001b[A\n",
      "473978it [18:17, 11970.29it/s]\u001b[A\n",
      "477222it [18:17, 13022.35it/s]\u001b[A\n",
      "480474it [18:17, 13994.12it/s]\u001b[A\n",
      "483827it [18:17, 14763.24it/s]\u001b[A\n",
      "487242it [18:17, 15322.80it/s]\u001b[A\n",
      "490803it [18:18, 16025.42it/s]\u001b[A\n",
      "494158it [18:18, 16354.50it/s]\u001b[A\n",
      "497392it [18:18, 16343.59it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2a0365040846cc8473845239e31fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "497392it [18:37, 16343.59it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "5it [22:08, 255.56s/it]\n",
      "500000it [22:08, 44.84it/s]   \u001b[A\n",
      "500660it [22:09, 48.87it/s]\u001b[A\n",
      "504114it [22:09, 79.24it/s]\u001b[A\n",
      "507610it [22:09, 122.99it/s]\u001b[A\n",
      "511244it [22:09, 187.55it/s]\u001b[A\n",
      "514868it [22:09, 278.74it/s]\u001b[A\n",
      "518341it [22:12, 368.36it/s]\u001b[A\n",
      "521849it [22:12, 528.86it/s]\u001b[A\n",
      "525331it [22:12, 751.58it/s]\u001b[A\n",
      "528870it [22:13, 1065.31it/s]\u001b[A\n",
      "532483it [22:13, 1502.59it/s]\u001b[A\n",
      "536032it [22:13, 2078.61it/s]\u001b[A\n",
      "539658it [22:13, 2857.03it/s]\u001b[A\n",
      "543270it [22:13, 3847.74it/s]\u001b[A\n",
      "546832it [22:14, 5024.16it/s]\u001b[A\n",
      "550439it [22:14, 6429.16it/s]\u001b[A\n",
      "553780it [22:17, 2501.56it/s]\u001b[A\n",
      "557006it [22:17, 3293.67it/s]\u001b[A\n",
      "560296it [22:18, 4292.22it/s]\u001b[A\n",
      "563874it [22:18, 5618.36it/s]\u001b[A\n",
      "567265it [22:18, 7049.70it/s]\u001b[A\n",
      "570820it [22:18, 8730.09it/s]\u001b[A\n",
      "574232it [22:18, 10334.72it/s]\u001b[A\n",
      "577473it [22:19, 11566.55it/s]\u001b[A\n",
      "580709it [22:19, 12673.12it/s]\u001b[A\n",
      "584085it [22:19, 13775.75it/s]\u001b[A\n",
      "587648it [22:19, 14823.20it/s]\u001b[A\n",
      "591221it [22:19, 15550.78it/s]\u001b[A\n",
      "594681it [22:24, 2459.48it/s] \u001b[A\n",
      "597890it [22:24, 3247.32it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b097fb67ac274a9f971a238628ff7fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "597890it [22:37, 3247.32it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "6it [25:27, 236.13s/it]\n",
      "600000it [25:27, 53.96it/s]  \u001b[A\n",
      "600714it [25:27, 59.37it/s]\u001b[A\n",
      "603661it [25:27, 91.54it/s]\u001b[A\n",
      "606929it [25:27, 142.26it/s]\u001b[A\n",
      "610252it [25:28, 215.28it/s]\u001b[A\n",
      "613734it [25:28, 323.49it/s]\u001b[A\n",
      "617354it [25:28, 481.82it/s]\u001b[A\n",
      "620666it [25:28, 683.55it/s]\u001b[A\n",
      "624076it [25:28, 971.71it/s]\u001b[A\n",
      "627641it [25:29, 1386.72it/s]\u001b[A\n",
      "631347it [25:34, 1096.85it/s]\u001b[A\n",
      "634999it [25:34, 1549.58it/s]\u001b[A\n",
      "638489it [25:34, 2125.39it/s]\u001b[A\n",
      "641910it [25:34, 2852.88it/s]\u001b[A\n",
      "645443it [25:34, 3811.68it/s]\u001b[A\n",
      "648763it [25:35, 4873.32it/s]\u001b[A\n",
      "652379it [25:35, 6263.28it/s]\u001b[A\n",
      "655997it [25:35, 7807.70it/s]\u001b[A\n",
      "659566it [25:35, 9468.81it/s]\u001b[A\n",
      "663144it [25:35, 11109.27it/s]\u001b[A\n",
      "666384it [25:36, 12062.81it/s]\u001b[A\n",
      "669565it [25:36, 12901.45it/s]\u001b[A\n",
      "672912it [25:36, 13751.14it/s]\u001b[A\n",
      "676251it [25:36, 14375.82it/s]\u001b[A\n",
      "679838it [25:36, 15239.55it/s]\u001b[A\n",
      "683412it [25:37, 15529.27it/s]\u001b[A\n",
      "687147it [25:37, 16499.76it/s]\u001b[A\n",
      "690654it [25:37, 17007.43it/s]\u001b[A\n",
      "694104it [25:37, 17269.09it/s]\u001b[A\n",
      "697502it [25:43, 1725.59it/s] \u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee0c76a0f5c4d34b5b581d6d1cf10bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "697502it [25:58, 1725.59it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "7it [28:52, 225.88s/it]\n",
      "700000it [28:52, 55.03it/s]  \u001b[A\n",
      "701081it [28:52, 62.95it/s]\u001b[A\n",
      "704546it [28:52, 99.37it/s]\u001b[A\n",
      "708124it [28:52, 152.77it/s]\u001b[A\n",
      "711497it [28:52, 224.09it/s]\u001b[A\n",
      "715005it [28:53, 328.91it/s]\u001b[A\n",
      "718370it [28:53, 470.64it/s]\u001b[A\n",
      "721568it [28:53, 659.09it/s]\u001b[A\n",
      "725047it [28:53, 944.31it/s]\u001b[A\n",
      "728624it [28:53, 1346.29it/s]\u001b[A\n",
      "732249it [28:54, 1893.11it/s]\u001b[A\n",
      "735637it [28:54, 2560.54it/s]\u001b[A\n",
      "739124it [28:54, 3441.57it/s]\u001b[A\n",
      "742601it [28:54, 4528.62it/s]\u001b[A\n",
      "746007it [28:54, 5792.08it/s]\u001b[A\n",
      "749408it [28:55, 7262.64it/s]\u001b[A\n",
      "752941it [28:55, 8942.08it/s]\u001b[A\n",
      "756501it [28:58, 2775.56it/s]\u001b[A\n",
      "760049it [28:58, 3728.58it/s]\u001b[A\n",
      "763670it [28:59, 4926.99it/s]\u001b[A\n",
      "767162it [28:59, 6259.61it/s]\u001b[A\n",
      "770908it [28:59, 7892.55it/s]\u001b[A\n",
      "774518it [28:59, 9495.45it/s]\u001b[A\n",
      "778040it [28:59, 11145.33it/s]\u001b[A\n",
      "781557it [28:59, 12642.03it/s]\u001b[A\n",
      "785274it [29:00, 14123.66it/s]\u001b[A\n",
      "788937it [29:00, 15316.86it/s]\u001b[A\n",
      "792467it [29:00, 15942.47it/s]\u001b[A\n",
      "795977it [29:00, 16434.10it/s]\u001b[A\n",
      "799438it [29:00, 16671.35it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fffe019c8946898f84ba0874591dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "799438it [29:18, 16671.35it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "8it [32:09, 216.93s/it]\n",
      "800000it [32:09, 46.55it/s]   \u001b[A\n",
      "802927it [32:10, 68.52it/s]\u001b[A\n",
      "806392it [32:10, 105.58it/s]\u001b[A\n",
      "809865it [32:10, 158.41it/s]\u001b[A\n",
      "813425it [32:10, 235.24it/s]\u001b[A\n",
      "816844it [32:10, 339.50it/s]\u001b[A\n",
      "820260it [32:11, 485.97it/s]\u001b[A\n",
      "823573it [32:11, 684.32it/s]\u001b[A\n",
      "826977it [32:11, 967.46it/s]\u001b[A\n",
      "830299it [32:11, 1345.51it/s]\u001b[A\n",
      "833717it [32:11, 1870.06it/s]\u001b[A\n",
      "837250it [32:16, 1273.15it/s]\u001b[A\n",
      "840558it [32:16, 1749.70it/s]\u001b[A\n",
      "844183it [32:16, 2448.94it/s]\u001b[A\n",
      "847650it [32:17, 3304.07it/s]\u001b[A\n",
      "851026it [32:17, 4336.13it/s]\u001b[A\n",
      "854562it [32:17, 5634.05it/s]\u001b[A\n",
      "857862it [32:17, 6985.07it/s]\u001b[A\n",
      "861231it [32:17, 8539.42it/s]\u001b[A\n",
      "864270it [32:18, 9897.98it/s]\u001b[A\n",
      "867304it [32:18, 11154.83it/s]\u001b[A\n",
      "870380it [32:18, 12256.08it/s]\u001b[A\n",
      "873380it [32:18, 12986.85it/s]\u001b[A\n",
      "876333it [32:18, 13417.74it/s]\u001b[A\n",
      "879397it [32:19, 13891.16it/s]\u001b[A\n",
      "882505it [32:19, 14376.47it/s]\u001b[A\n",
      "885638it [32:19, 14818.35it/s]\u001b[A\n",
      "888649it [32:19, 15294.68it/s]\u001b[A\n",
      "891690it [32:19, 15465.20it/s]\u001b[A\n",
      "894709it [32:25, 1600.03it/s] \u001b[A\n",
      "897825it [32:25, 2199.24it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec648b616ba84ab58b359007040de640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "897825it [32:40, 2199.24it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "9it [36:10, 224.21s/it]\n",
      "900000it [36:10, 41.06it/s]  \u001b[A\n",
      "900882it [36:10, 46.54it/s]\u001b[A\n",
      "903964it [36:10, 74.04it/s]\u001b[A\n",
      "906985it [36:10, 112.40it/s]\u001b[A\n",
      "910081it [36:10, 168.21it/s]\u001b[A\n",
      "913137it [36:11, 246.18it/s]\u001b[A\n",
      "916240it [36:11, 357.95it/s]\u001b[A\n",
      "919284it [36:11, 511.26it/s]\u001b[A\n",
      "922416it [36:11, 730.80it/s]\u001b[A\n",
      "925561it [36:11, 1033.74it/s]\u001b[A\n",
      "928676it [36:12, 1439.90it/s]\u001b[A\n",
      "931746it [36:12, 1970.02it/s]\u001b[A\n",
      "934912it [36:12, 2676.04it/s]\u001b[A\n",
      "938005it [36:12, 3525.11it/s]\u001b[A\n",
      "941157it [36:13, 4581.46it/s]\u001b[A\n",
      "944228it [36:13, 5741.61it/s]\u001b[A\n",
      "947308it [36:16, 2256.50it/s]\u001b[A\n",
      "950400it [36:16, 3026.03it/s]\u001b[A\n",
      "953531it [36:16, 4000.52it/s]\u001b[A\n",
      "956611it [36:17, 5120.21it/s]\u001b[A\n",
      "959630it [36:17, 6344.85it/s]\u001b[A\n",
      "962633it [36:17, 7602.02it/s]\u001b[A\n",
      "965785it [36:17, 9006.76it/s]\u001b[A\n",
      "968850it [36:17, 10165.26it/s]\u001b[A\n",
      "971952it [36:18, 11259.23it/s]\u001b[A\n",
      "975007it [36:18, 12083.52it/s]\u001b[A\n",
      "978074it [36:18, 12875.31it/s]\u001b[A\n",
      "981122it [36:18, 13400.44it/s]\u001b[A\n",
      "984155it [36:22, 2209.67it/s] \u001b[A\n",
      "987188it [36:23, 2958.30it/s]\u001b[A\n",
      "990212it [36:23, 3888.71it/s]\u001b[A\n",
      "993282it [36:23, 5012.01it/s]\u001b[A\n",
      "996421it [36:23, 6324.77it/s]\u001b[A\n",
      "999541it [36:23, 7649.84it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2300f216f7f64670ab7e8e122eeda804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "999541it [36:42, 7649.84it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "10it [40:49, 241.10s/it]\n",
      "1000000it [40:49, 28.82it/s] \u001b[A\n",
      "1002609it [40:49, 42.79it/s]\u001b[A\n",
      "1005700it [40:49, 66.37it/s]\u001b[A\n",
      "1008800it [40:49, 100.02it/s]\u001b[A\n",
      "1011965it [40:54, 139.32it/s]\u001b[A\n",
      "1015077it [40:54, 203.08it/s]\u001b[A\n",
      "1018196it [40:54, 293.45it/s]\u001b[A\n",
      "1021295it [40:54, 419.83it/s]\u001b[A\n",
      "1024432it [40:55, 598.98it/s]\u001b[A\n",
      "1027548it [40:55, 846.35it/s]\u001b[A\n",
      "1030713it [40:55, 1188.97it/s]\u001b[A\n",
      "1033835it [40:55, 1646.23it/s]\u001b[A\n",
      "1037027it [40:55, 2261.41it/s]\u001b[A\n",
      "1040124it [40:56, 3031.27it/s]\u001b[A\n",
      "1043227it [40:56, 3978.45it/s]\u001b[A\n",
      "1046350it [40:56, 5105.37it/s]\u001b[A\n",
      "1049450it [40:56, 6350.46it/s]\u001b[A\n",
      "1052604it [40:56, 7735.07it/s]\u001b[A\n",
      "1055711it [40:57, 9062.63it/s]\u001b[A\n",
      "1058853it [40:57, 10289.46it/s]\u001b[A\n",
      "1062022it [40:57, 11404.43it/s]\u001b[A\n",
      "1065140it [41:03, 1594.80it/s] \u001b[A\n",
      "1068294it [41:03, 2180.71it/s]\u001b[A\n",
      "1071398it [41:03, 2918.26it/s]\u001b[A\n",
      "1074539it [41:04, 3845.35it/s]\u001b[A\n",
      "1077712it [41:04, 4951.00it/s]\u001b[A\n",
      "1080804it [41:04, 6142.45it/s]\u001b[A\n",
      "1083914it [41:04, 7428.27it/s]\u001b[A\n",
      "1087068it [41:04, 8697.92it/s]\u001b[A\n",
      "1090207it [41:05, 9921.66it/s]\u001b[A\n",
      "1093359it [41:05, 11036.57it/s]\u001b[A\n",
      "1096497it [41:05, 11805.19it/s]\u001b[A\n",
      "1099681it [41:05, 12457.79it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d09e9aebfd401e89c0a4b30d1eae64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "1099681it [41:24, 12457.79it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "11it [45:33, 254.44s/it]\n",
      "1100000it [45:33, 28.59it/s]   \u001b[A\n",
      "1102812it [45:33, 43.51it/s]\u001b[A\n",
      "1105932it [45:34, 67.11it/s]\u001b[A\n",
      "1109032it [45:34, 100.49it/s]\u001b[A\n",
      "1112171it [45:34, 148.56it/s]\u001b[A\n",
      "1115294it [45:34, 216.39it/s]\u001b[A\n",
      "1118419it [45:34, 312.14it/s]\u001b[A\n",
      "1121593it [45:37, 402.99it/s]\u001b[A\n",
      "1124882it [45:37, 581.46it/s]\u001b[A\n",
      "1128143it [45:38, 827.43it/s]\u001b[A\n",
      "1131299it [45:38, 1153.84it/s]\u001b[A\n",
      "1134426it [45:38, 1584.22it/s]\u001b[A\n",
      "1137595it [45:38, 2168.28it/s]\u001b[A\n",
      "1140664it [45:38, 2894.86it/s]\u001b[A\n",
      "1143789it [45:39, 3818.72it/s]\u001b[A\n",
      "1146965it [45:39, 4935.70it/s]\u001b[A\n",
      "1150111it [45:39, 6185.79it/s]\u001b[A\n",
      "1153207it [45:43, 2237.15it/s]\u001b[A\n",
      "1156276it [45:43, 2976.37it/s]\u001b[A\n",
      "1159424it [45:43, 3912.28it/s]\u001b[A\n",
      "1162552it [45:43, 5036.09it/s]\u001b[A\n",
      "1165655it [45:43, 6293.78it/s]\u001b[A\n",
      "1168777it [45:44, 7647.77it/s]\u001b[A\n",
      "1171827it [45:44, 8937.59it/s]\u001b[A\n",
      "1174873it [45:44, 10153.87it/s]\u001b[A\n",
      "1178010it [45:44, 11271.61it/s]\u001b[A\n",
      "1181111it [45:44, 12002.92it/s]\u001b[A\n",
      "1184197it [45:45, 12483.15it/s]\u001b[A\n",
      "1187328it [45:45, 12983.01it/s]\u001b[A\n",
      "1190395it [45:45, 13261.56it/s]\u001b[A\n",
      "1193577it [45:50, 2073.65it/s] \u001b[A\n",
      "1196702it [45:50, 2799.79it/s]\u001b[A\n",
      "1199853it [45:50, 3722.51it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181dc81d3c8644a08ddb8c7c680e490c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "1199853it [46:04, 3722.51it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "12it [50:29, 267.09s/it]\n",
      "1200000it [50:29, 26.50it/s]  \u001b[A\n",
      "1202923it [50:29, 41.30it/s]\u001b[A\n",
      "1206047it [50:30, 63.84it/s]\u001b[A\n",
      "1209216it [50:30, 96.40it/s]\u001b[A\n",
      "1212406it [50:30, 142.95it/s]\u001b[A\n",
      "1215540it [50:30, 207.79it/s]\u001b[A\n",
      "1218675it [50:31, 299.42it/s]\u001b[A\n",
      "1221845it [50:35, 358.44it/s]\u001b[A\n",
      "1225042it [50:36, 512.85it/s]\u001b[A\n",
      "1228255it [50:36, 728.77it/s]\u001b[A\n",
      "1231357it [50:36, 1015.37it/s]\u001b[A\n",
      "1234567it [50:36, 1419.20it/s]\u001b[A\n",
      "1237733it [50:37, 1941.43it/s]\u001b[A\n",
      "1240898it [50:37, 2623.49it/s]\u001b[A\n",
      "1244032it [50:37, 3477.28it/s]\u001b[A\n",
      "1247187it [50:37, 4513.16it/s]\u001b[A\n",
      "1250366it [50:37, 5709.44it/s]\u001b[A\n",
      "1253518it [50:38, 6988.78it/s]\u001b[A\n",
      "1256694it [50:38, 8301.70it/s]\u001b[A\n",
      "1259879it [50:38, 9576.11it/s]\u001b[A\n",
      "1263073it [50:38, 10724.97it/s]\u001b[A\n",
      "1266244it [50:39, 11692.32it/s]\u001b[A\n",
      "1269409it [50:39, 12442.64it/s]\u001b[A\n",
      "1272532it [50:39, 12917.05it/s]\u001b[A\n",
      "1275704it [50:39, 13425.66it/s]\u001b[A\n",
      "1278881it [50:45, 1589.09it/s] \u001b[A\n",
      "1282034it [50:45, 2165.69it/s]\u001b[A\n",
      "1285207it [50:46, 2910.19it/s]\u001b[A\n",
      "1288393it [50:46, 3835.75it/s]\u001b[A\n",
      "1291531it [50:46, 4916.30it/s]\u001b[A\n",
      "1294639it [50:46, 6101.14it/s]\u001b[A\n",
      "1297803it [50:47, 7405.34it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e44dcf0282497685a0f4ea3e42ef0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "1297803it [51:05, 7405.34it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "13it [55:32, 277.81s/it]\n",
      "1300000it [55:32, 33.38it/s]  \u001b[A\n",
      "1300962it [55:32, 38.14it/s]\u001b[A\n",
      "1304114it [55:32, 60.52it/s]\u001b[A\n",
      "1307203it [55:32, 91.74it/s]\u001b[A\n",
      "1310347it [55:32, 136.93it/s]\u001b[A\n",
      "1313516it [55:33, 201.56it/s]\u001b[A\n",
      "1316664it [55:33, 292.23it/s]\u001b[A\n",
      "1319821it [55:33, 420.00it/s]\u001b[A\n",
      "1322932it [55:33, 595.78it/s]\u001b[A\n",
      "1326082it [55:34, 842.20it/s]\u001b[A\n",
      "1329230it [55:34, 1179.00it/s]\u001b[A\n",
      "1332374it [55:37, 1130.88it/s]\u001b[A\n",
      "1335535it [55:37, 1565.82it/s]\u001b[A\n",
      "1338613it [55:37, 2122.60it/s]\u001b[A\n",
      "1341783it [55:37, 2856.75it/s]\u001b[A\n",
      "1344944it [55:38, 3760.24it/s]\u001b[A\n",
      "1348084it [55:38, 4821.24it/s]\u001b[A\n",
      "1351292it [55:38, 6035.48it/s]\u001b[A\n",
      "1354468it [55:38, 7323.17it/s]\u001b[A\n",
      "1357650it [55:39, 8584.47it/s]\u001b[A\n",
      "1360840it [55:39, 9772.81it/s]\u001b[A\n",
      "1364012it [55:39, 10783.07it/s]\u001b[A\n",
      "1367216it [55:43, 2398.21it/s] \u001b[A\n",
      "1370406it [55:43, 3195.30it/s]\u001b[A\n",
      "1373574it [55:43, 4159.91it/s]\u001b[A\n",
      "1376777it [55:43, 5292.52it/s]\u001b[A\n",
      "1379949it [55:44, 6516.75it/s]\u001b[A\n",
      "1383119it [55:44, 7787.05it/s]\u001b[A\n",
      "1386347it [55:44, 9034.09it/s]\u001b[A\n",
      "1389539it [55:44, 10099.85it/s]\u001b[A\n",
      "1392751it [55:45, 11081.37it/s]\u001b[A\n",
      "1395953it [55:45, 11957.74it/s]\u001b[A\n",
      "1399134it [55:45, 12631.35it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8130ecf1ff54222bab32e5db4e4413f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "1399134it [55:57, 12631.35it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "14it [1:00:41, 287.33s/it]\n",
      "1400000it [1:00:41, 28.05it/s] \u001b[A\n",
      "1402283it [1:00:41, 39.00it/s]\u001b[A\n",
      "1405452it [1:00:41, 60.69it/s]\u001b[A\n",
      "1408616it [1:00:42, 91.51it/s]\u001b[A\n",
      "1411771it [1:00:42, 135.17it/s]\u001b[A\n",
      "1414916it [1:00:42, 196.90it/s]\u001b[A\n",
      "1418113it [1:00:42, 285.59it/s]\u001b[A\n",
      "1421308it [1:00:43, 410.09it/s]\u001b[A\n",
      "1424514it [1:00:43, 585.13it/s]\u001b[A\n",
      "1427709it [1:00:43, 827.00it/s]\u001b[A\n",
      "1430909it [1:00:43, 1158.46it/s]\u001b[A\n",
      "1434074it [1:00:43, 1600.41it/s]\u001b[A\n",
      "1437268it [1:00:44, 2188.95it/s]\u001b[A\n",
      "1440480it [1:00:44, 2947.51it/s]\u001b[A\n",
      "1443668it [1:00:44, 3874.06it/s]\u001b[A\n",
      "1446843it [1:00:50, 1445.22it/s]\u001b[A\n",
      "1449998it [1:00:50, 1973.05it/s]\u001b[A\n",
      "1453209it [1:00:50, 2672.38it/s]\u001b[A\n",
      "1456379it [1:00:50, 3534.56it/s]\u001b[A\n",
      "1459591it [1:00:50, 4574.51it/s]\u001b[A\n",
      "1462822it [1:00:51, 5725.73it/s]\u001b[A\n",
      "1466034it [1:00:51, 7005.43it/s]\u001b[A\n",
      "1469227it [1:00:51, 8254.18it/s]\u001b[A\n",
      "1472488it [1:00:51, 9484.35it/s]\u001b[A\n",
      "1475695it [1:00:52, 10536.94it/s]\u001b[A\n",
      "1478925it [1:00:52, 11524.96it/s]\u001b[A\n",
      "1482166it [1:00:52, 12275.25it/s]\u001b[A\n",
      "1485436it [1:00:52, 12763.19it/s]\u001b[A\n",
      "1488651it [1:00:52, 13137.48it/s]\u001b[A\n",
      "1491920it [1:00:53, 13710.88it/s]\u001b[A\n",
      "1495249it [1:00:53, 14088.06it/s]\u001b[A\n",
      "1498565it [1:00:53, 14351.62it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2723f032776c45adacd1e7eff58dd47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "1498565it [1:01:10, 14351.62it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "15it [1:05:47, 293.04s/it]\n",
      "1500000it [1:05:47, 30.87it/s]   \u001b[A\n",
      "1501987it [1:05:48, 40.46it/s]\u001b[A\n",
      "1505320it [1:05:48, 63.42it/s]\u001b[A\n",
      "1508509it [1:05:48, 94.70it/s]\u001b[A\n",
      "1511641it [1:05:48, 138.37it/s]\u001b[A\n",
      "1514747it [1:05:48, 199.83it/s]\u001b[A\n",
      "1517791it [1:05:49, 284.84it/s]\u001b[A\n",
      "1520838it [1:05:51, 365.58it/s]\u001b[A\n",
      "1523872it [1:05:52, 516.62it/s]\u001b[A\n",
      "1526974it [1:05:52, 731.00it/s]\u001b[A\n",
      "1530038it [1:05:52, 1020.40it/s]\u001b[A\n",
      "1533128it [1:05:52, 1415.58it/s]\u001b[A\n",
      "1536216it [1:05:53, 1939.17it/s]\u001b[A\n",
      "1539292it [1:05:53, 2609.07it/s]\u001b[A\n",
      "1542439it [1:05:53, 3466.67it/s]\u001b[A\n",
      "1545571it [1:05:53, 4506.69it/s]\u001b[A\n",
      "1548663it [1:05:53, 5670.32it/s]\u001b[A\n",
      "1551782it [1:05:57, 2185.62it/s]\u001b[A\n",
      "1554867it [1:05:57, 2933.44it/s]\u001b[A\n",
      "1557960it [1:05:57, 3870.79it/s]\u001b[A\n",
      "1561007it [1:05:58, 4953.55it/s]\u001b[A\n",
      "1564103it [1:05:58, 6210.74it/s]\u001b[A\n",
      "1567203it [1:05:58, 7537.94it/s]\u001b[A\n",
      "1570345it [1:05:58, 8893.60it/s]\u001b[A\n",
      "1573463it [1:05:58, 10068.66it/s]\u001b[A\n",
      "1576585it [1:05:59, 11138.46it/s]\u001b[A\n",
      "1579696it [1:05:59, 12079.74it/s]\u001b[A\n",
      "1582801it [1:05:59, 12857.44it/s]\u001b[A\n",
      "1585884it [1:05:59, 13329.70it/s]\u001b[A\n",
      "1588992it [1:06:04, 2142.88it/s] \u001b[A\n",
      "1592087it [1:06:04, 2879.49it/s]\u001b[A\n",
      "1595175it [1:06:04, 3784.78it/s]\u001b[A\n",
      "1598267it [1:06:04, 4861.17it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f999e6caba44a3f8fb025c9b6cec7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "1598267it [1:06:23, 4861.17it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "16it [1:10:42, 293.55s/it]\n",
      "1600000it [1:10:42, 32.06it/s]  \u001b[A\n",
      "1601379it [1:10:42, 39.07it/s]\u001b[A\n",
      "1604492it [1:10:42, 61.69it/s]\u001b[A\n",
      "1607616it [1:10:43, 94.01it/s]\u001b[A\n",
      "1610683it [1:10:43, 139.07it/s]\u001b[A\n",
      "1613744it [1:10:43, 202.88it/s]\u001b[A\n",
      "1616804it [1:10:43, 293.04it/s]\u001b[A\n",
      "1619900it [1:10:43, 421.44it/s]\u001b[A\n",
      "1622983it [1:10:49, 465.65it/s]\u001b[A\n",
      "1625994it [1:10:49, 654.61it/s]\u001b[A\n",
      "1629086it [1:10:49, 921.81it/s]\u001b[A\n",
      "1632170it [1:10:49, 1284.02it/s]\u001b[A\n",
      "1635323it [1:10:49, 1776.69it/s]\u001b[A\n",
      "1638464it [1:10:50, 2426.12it/s]\u001b[A\n",
      "1641571it [1:10:50, 3248.75it/s]\u001b[A\n",
      "1644696it [1:10:50, 4266.32it/s]\u001b[A\n",
      "1647864it [1:10:50, 5476.44it/s]\u001b[A\n",
      "1651031it [1:10:50, 6810.61it/s]\u001b[A\n",
      "1654186it [1:10:51, 8204.96it/s]\u001b[A\n",
      "1657368it [1:10:51, 9567.67it/s]\u001b[A\n",
      "1660576it [1:10:51, 10801.72it/s]\u001b[A\n",
      "1663713it [1:10:51, 11791.72it/s]\u001b[A\n",
      "1666877it [1:10:52, 12594.79it/s]\u001b[A\n",
      "1670044it [1:10:52, 13407.26it/s]\u001b[A\n",
      "1673208it [1:10:52, 13970.17it/s]\u001b[A\n",
      "1676427it [1:10:52, 14452.95it/s]\u001b[A\n",
      "1679627it [1:10:58, 1612.24it/s] \u001b[A\n",
      "1682778it [1:10:58, 2198.39it/s]\u001b[A\n",
      "1685936it [1:10:59, 2955.22it/s]\u001b[A\n",
      "1689099it [1:10:59, 3894.15it/s]\u001b[A\n",
      "1692253it [1:10:59, 5033.18it/s]\u001b[A\n",
      "1695371it [1:10:59, 6274.61it/s]\u001b[A\n",
      "1698579it [1:10:59, 7689.60it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9861f5f6c559436aae316f8811414028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "1698579it [1:11:18, 7689.60it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "17it [1:15:36, 293.68s/it]\n",
      "1700000it [1:15:36, 31.75it/s]  \u001b[A\n",
      "1701772it [1:15:36, 40.83it/s]\u001b[A\n",
      "1705008it [1:15:36, 64.51it/s]\u001b[A\n",
      "1708162it [1:15:37, 97.37it/s]\u001b[A\n",
      "1711379it [1:15:37, 145.02it/s]\u001b[A\n",
      "1714581it [1:15:37, 212.29it/s]\u001b[A\n",
      "1717756it [1:15:37, 306.54it/s]\u001b[A\n",
      "1721020it [1:15:37, 442.67it/s]\u001b[A\n",
      "1724230it [1:15:38, 629.52it/s]\u001b[A\n",
      "1727436it [1:15:38, 887.69it/s]\u001b[A\n",
      "1730649it [1:15:38, 1241.26it/s]\u001b[A\n",
      "1733857it [1:15:38, 1714.19it/s]\u001b[A\n",
      "1737105it [1:15:41, 1417.22it/s]\u001b[A\n",
      "1740292it [1:15:42, 1941.20it/s]\u001b[A\n",
      "1743552it [1:15:42, 2638.95it/s]\u001b[A\n",
      "1746767it [1:15:42, 3502.66it/s]\u001b[A\n",
      "1750011it [1:15:42, 4562.15it/s]\u001b[A\n",
      "1753264it [1:15:43, 5776.54it/s]\u001b[A\n",
      "1756509it [1:15:43, 7106.20it/s]\u001b[A\n",
      "1759713it [1:15:43, 8429.98it/s]\u001b[A\n",
      "1763037it [1:15:43, 9809.42it/s]\u001b[A\n",
      "1766360it [1:15:43, 11109.63it/s]\u001b[A\n",
      "1769657it [1:15:44, 12179.00it/s]\u001b[A\n",
      "1773003it [1:15:48, 2385.43it/s] \u001b[A\n",
      "1776310it [1:15:48, 3201.28it/s]\u001b[A\n",
      "1779643it [1:15:48, 4215.52it/s]\u001b[A\n",
      "1782989it [1:15:48, 5408.54it/s]\u001b[A\n",
      "1786285it [1:15:48, 6691.44it/s]\u001b[A\n",
      "1789419it [1:15:49, 7912.74it/s]\u001b[A\n",
      "1792606it [1:15:49, 9220.79it/s]\u001b[A\n",
      "1795789it [1:15:49, 10361.97it/s]\u001b[A\n",
      "1798966it [1:15:49, 11366.02it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b100d3f57304bb0a6aa72291ce1cd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "1798966it [1:16:08, 11366.02it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "18it [1:20:07, 286.94s/it]\n",
      "1800000it [1:20:07, 32.95it/s]   \u001b[A\n",
      "1802144it [1:20:07, 44.74it/s]\u001b[A\n",
      "1805291it [1:20:08, 69.43it/s]\u001b[A\n",
      "1808421it [1:20:12, 99.43it/s]\u001b[A\n",
      "1811573it [1:20:13, 147.07it/s]\u001b[A\n",
      "1814703it [1:20:13, 214.14it/s]\u001b[A\n",
      "1817858it [1:20:13, 309.70it/s]\u001b[A\n",
      "1821020it [1:20:13, 444.40it/s]\u001b[A\n",
      "1824157it [1:20:13, 631.16it/s]\u001b[A\n",
      "1827351it [1:20:14, 894.65it/s]\u001b[A\n",
      "1830504it [1:20:14, 1250.20it/s]\u001b[A\n",
      "1833700it [1:20:14, 1735.22it/s]\u001b[A\n",
      "1836857it [1:20:14, 2363.36it/s]\u001b[A\n",
      "1840016it [1:20:14, 3166.74it/s]\u001b[A\n",
      "1843171it [1:20:15, 4152.67it/s]\u001b[A\n",
      "1846309it [1:20:15, 5274.76it/s]\u001b[A\n",
      "1849513it [1:20:15, 6547.36it/s]\u001b[A\n",
      "1852708it [1:20:15, 7866.41it/s]\u001b[A\n",
      "1855884it [1:20:15, 9163.62it/s]\u001b[A\n",
      "1859123it [1:20:21, 1630.31it/s]\u001b[A\n",
      "1862332it [1:20:21, 2221.42it/s]\u001b[A\n",
      "1865490it [1:20:22, 2964.61it/s]\u001b[A\n",
      "1868635it [1:20:22, 3881.44it/s]\u001b[A\n",
      "1871856it [1:20:22, 4996.75it/s]\u001b[A\n",
      "1875100it [1:20:22, 6260.23it/s]\u001b[A\n",
      "1878333it [1:20:23, 7590.66it/s]\u001b[A\n",
      "1881486it [1:20:23, 8851.10it/s]\u001b[A\n",
      "1884587it [1:20:23, 9957.24it/s]\u001b[A\n",
      "1887747it [1:20:23, 11051.08it/s]\u001b[A\n",
      "1890799it [1:20:23, 11809.13it/s]\u001b[A\n",
      "1893902it [1:20:24, 12506.33it/s]\u001b[A\n",
      "1897045it [1:20:24, 13124.01it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd604e9f505b44beb845957d027d80ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "1897045it [1:20:42, 13124.01it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "19it [1:24:55, 287.26s/it]\n",
      "1900000it [1:24:55, 37.70it/s]   \u001b[A\n",
      "1900167it [1:24:55, 38.54it/s]\u001b[A\n",
      "1903236it [1:24:56, 61.45it/s]\u001b[A\n",
      "1906279it [1:24:58, 91.54it/s]\u001b[A\n",
      "1909409it [1:24:58, 137.71it/s]\u001b[A\n",
      "1912457it [1:24:59, 201.50it/s]\u001b[A\n",
      "1915540it [1:24:59, 292.66it/s]\u001b[A\n",
      "1918685it [1:24:59, 423.41it/s]\u001b[A\n",
      "1921759it [1:24:59, 601.82it/s]\u001b[A\n",
      "1924869it [1:24:59, 851.84it/s]\u001b[A\n",
      "1928004it [1:25:00, 1196.87it/s]\u001b[A\n",
      "1931149it [1:25:00, 1666.66it/s]\u001b[A\n",
      "1934275it [1:25:03, 1392.18it/s]\u001b[A\n",
      "1937380it [1:25:03, 1919.36it/s]\u001b[A\n",
      "1940505it [1:25:03, 2610.01it/s]\u001b[A\n",
      "1943614it [1:25:03, 3465.44it/s]\u001b[A\n",
      "1946718it [1:25:04, 4513.73it/s]\u001b[A\n",
      "1949727it [1:25:04, 5679.17it/s]\u001b[A\n",
      "1952783it [1:25:04, 6937.51it/s]\u001b[A\n",
      "1955811it [1:25:04, 8256.65it/s]\u001b[A\n",
      "1958899it [1:25:04, 9680.85it/s]\u001b[A\n",
      "1961998it [1:25:05, 10931.07it/s]\u001b[A\n",
      "1965095it [1:25:05, 12106.58it/s]\u001b[A\n",
      "1968168it [1:25:09, 2244.69it/s] \u001b[A\n",
      "1971215it [1:25:09, 3008.39it/s]\u001b[A\n",
      "1974245it [1:25:09, 3946.85it/s]\u001b[A\n",
      "1977365it [1:25:09, 5120.23it/s]\u001b[A\n",
      "1980420it [1:25:10, 6420.40it/s]\u001b[A\n",
      "1983463it [1:25:10, 7805.87it/s]\u001b[A\n",
      "1986484it [1:25:10, 9148.81it/s]\u001b[A\n",
      "1989454it [1:25:10, 10282.76it/s]\u001b[A\n",
      "1992542it [1:25:10, 11543.11it/s]\u001b[A\n",
      "1995637it [1:25:11, 12638.42it/s]\u001b[A\n",
      "1998736it [1:25:11, 13533.77it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00dec017d0d4f889b8aa2605b95939e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "1998736it [1:25:23, 13533.77it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "20it [1:29:57, 291.62s/it]\n",
      "2000000it [1:29:57, 29.40it/s]   \u001b[A\n",
      "2001872it [1:29:57, 38.69it/s]\u001b[A\n",
      "2004991it [1:29:57, 60.78it/s]\u001b[A\n",
      "2008105it [1:29:58, 92.19it/s]\u001b[A\n",
      "2011109it [1:29:58, 135.25it/s]\u001b[A\n",
      "2014142it [1:29:58, 196.97it/s]\u001b[A\n",
      "2017252it [1:29:58, 286.54it/s]\u001b[A\n",
      "2020283it [1:29:58, 409.52it/s]\u001b[A\n",
      "2023353it [1:29:59, 583.70it/s]\u001b[A\n",
      "2026385it [1:29:59, 822.84it/s]\u001b[A\n",
      "2029451it [1:29:59, 1155.96it/s]\u001b[A\n",
      "2032416it [1:29:59, 1590.22it/s]\u001b[A\n",
      "2035416it [1:29:59, 2173.58it/s]\u001b[A\n",
      "2038502it [1:30:00, 2953.97it/s]\u001b[A\n",
      "2041638it [1:30:00, 3951.37it/s]\u001b[A\n",
      "2044768it [1:30:05, 1424.02it/s]\u001b[A\n",
      "2047838it [1:30:05, 1961.13it/s]\u001b[A\n",
      "2050928it [1:30:06, 2667.79it/s]\u001b[A\n",
      "2054044it [1:30:06, 3572.14it/s]\u001b[A\n",
      "2057116it [1:30:06, 4625.73it/s]\u001b[A\n",
      "2060211it [1:30:06, 5882.92it/s]\u001b[A\n",
      "2063290it [1:30:06, 7260.00it/s]\u001b[A\n",
      "2066350it [1:30:07, 8666.16it/s]\u001b[A\n",
      "2069433it [1:30:07, 10069.91it/s]\u001b[A\n",
      "2072534it [1:30:07, 11427.71it/s]\u001b[A\n",
      "2075636it [1:30:07, 12606.46it/s]\u001b[A\n",
      "2078677it [1:30:07, 13442.34it/s]\u001b[A\n",
      "2081702it [1:30:07, 14232.73it/s]\u001b[A\n",
      "2084727it [1:30:08, 14843.65it/s]\u001b[A\n",
      "2087776it [1:30:08, 15208.23it/s]\u001b[A\n",
      "2090807it [1:30:08, 15398.54it/s]\u001b[A\n",
      "2093859it [1:30:08, 15579.23it/s]\u001b[A\n",
      "2096920it [1:30:08, 15784.94it/s]\u001b[A\n",
      "2099996it [1:30:09, 15377.60it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6d84df2f7d4c7cb9a5099768405905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "2099996it [1:30:25, 15377.60it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "21it [1:34:49, 291.64s/it]\n",
      "2100000it [1:34:49, 25.45it/s]   \u001b[A\n",
      "2103084it [1:34:49, 41.11it/s]\u001b[A\n",
      "2106144it [1:34:49, 63.26it/s]\u001b[A\n",
      "2109254it [1:34:49, 95.31it/s]\u001b[A\n",
      "2112372it [1:34:49, 141.01it/s]\u001b[A\n",
      "2115523it [1:34:52, 196.07it/s]\u001b[A\n",
      "2118703it [1:34:52, 284.95it/s]\u001b[A\n",
      "2121818it [1:34:53, 407.46it/s]\u001b[A\n",
      "2124896it [1:34:53, 576.83it/s]\u001b[A\n",
      "2128005it [1:34:53, 814.91it/s]\u001b[A\n",
      "2131143it [1:34:53, 1144.72it/s]\u001b[A\n",
      "2134245it [1:34:53, 1585.34it/s]\u001b[A\n",
      "2137307it [1:34:54, 2161.37it/s]\u001b[A\n",
      "2140416it [1:34:54, 2914.04it/s]\u001b[A\n",
      "2143482it [1:34:54, 3829.68it/s]\u001b[A\n",
      "2146547it [1:34:57, 1943.29it/s]\u001b[A\n",
      "2149611it [1:34:58, 2623.80it/s]\u001b[A\n",
      "2152688it [1:34:58, 3486.05it/s]\u001b[A\n",
      "2155816it [1:34:58, 4545.00it/s]\u001b[A\n",
      "2158942it [1:34:58, 5751.08it/s]\u001b[A\n",
      "2162004it [1:34:58, 7027.72it/s]\u001b[A\n",
      "2165104it [1:34:59, 8385.59it/s]\u001b[A\n",
      "2168225it [1:34:59, 9701.55it/s]\u001b[A\n",
      "2171313it [1:34:59, 10916.07it/s]\u001b[A\n",
      "2174397it [1:34:59, 11953.05it/s]\u001b[A\n",
      "2177505it [1:34:59, 12874.90it/s]\u001b[A\n",
      "2180624it [1:35:00, 13656.32it/s]\u001b[A\n",
      "2183766it [1:35:04, 2210.95it/s] \u001b[A\n",
      "2186941it [1:35:04, 2988.61it/s]\u001b[A\n",
      "2190017it [1:35:04, 3918.47it/s]\u001b[A\n",
      "2193119it [1:35:04, 5032.05it/s]\u001b[A\n",
      "2196183it [1:35:05, 6277.63it/s]\u001b[A\n",
      "2199303it [1:35:05, 7675.34it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00378539a03647dc94f16e324ba6430d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "2199303it [1:35:17, 7675.34it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "22it [1:39:37, 290.77s/it]\n",
      "2200000it [1:39:37, 29.03it/s]  \u001b[A\n",
      "2202413it [1:39:38, 41.58it/s]\u001b[A\n",
      "2205513it [1:39:38, 64.59it/s]\u001b[A\n",
      "2208578it [1:39:38, 96.96it/s]\u001b[A\n",
      "2211656it [1:39:38, 143.15it/s]\u001b[A\n",
      "2214745it [1:39:39, 208.89it/s]\u001b[A\n",
      "2217829it [1:39:43, 263.28it/s]\u001b[A\n",
      "2220998it [1:39:44, 380.90it/s]\u001b[A\n",
      "2224128it [1:39:44, 543.70it/s]\u001b[A\n",
      "2227309it [1:39:44, 774.19it/s]\u001b[A\n",
      "2230459it [1:39:44, 1087.25it/s]\u001b[A\n",
      "2233561it [1:39:45, 1505.49it/s]\u001b[A\n",
      "2236664it [1:39:45, 2062.34it/s]\u001b[A\n",
      "2239801it [1:39:45, 2793.31it/s]\u001b[A\n",
      "2242921it [1:39:45, 3698.68it/s]\u001b[A\n",
      "2246067it [1:39:45, 4794.82it/s]\u001b[A\n",
      "2249167it [1:39:46, 5973.14it/s]\u001b[A\n",
      "2252345it [1:39:46, 7368.80it/s]\u001b[A\n",
      "2255389it [1:39:46, 8687.60it/s]\u001b[A\n",
      "2258501it [1:39:46, 10020.80it/s]\u001b[A\n",
      "2261578it [1:39:46, 11184.90it/s]\u001b[A\n",
      "2264660it [1:39:47, 12163.64it/s]\u001b[A\n",
      "2267771it [1:39:47, 13030.33it/s]\u001b[A\n",
      "2270830it [1:39:47, 13604.05it/s]\u001b[A\n",
      "2273848it [1:39:53, 1535.60it/s] \u001b[A\n",
      "2276951it [1:39:53, 2103.02it/s]\u001b[A\n",
      "2280008it [1:39:54, 2825.22it/s]\u001b[A\n",
      "2283104it [1:39:54, 3750.89it/s]\u001b[A\n",
      "2286273it [1:39:54, 4884.80it/s]\u001b[A\n",
      "2289358it [1:39:54, 6115.05it/s]\u001b[A\n",
      "2292425it [1:39:54, 7424.09it/s]\u001b[A\n",
      "2295480it [1:39:55, 8769.21it/s]\u001b[A\n",
      "2298627it [1:39:55, 10116.02it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2173404cb214763b6b39360c75b191a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "2298627it [1:40:13, 10116.02it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "23it [1:44:34, 292.64s/it]\n",
      "2300000it [1:44:34, 30.68it/s]   \u001b[A\n",
      "2301740it [1:44:35, 39.51it/s]\u001b[A\n",
      "2304799it [1:44:35, 61.65it/s]\u001b[A\n",
      "2307932it [1:44:35, 93.94it/s]\u001b[A\n",
      "2311052it [1:44:35, 139.65it/s]\u001b[A\n",
      "2314077it [1:44:35, 202.50it/s]\u001b[A\n",
      "2317147it [1:44:36, 292.79it/s]\u001b[A\n",
      "2320278it [1:44:36, 422.30it/s]\u001b[A\n",
      "2323372it [1:44:36, 600.63it/s]\u001b[A\n",
      "2326482it [1:44:36, 848.58it/s]\u001b[A\n",
      "2329580it [1:44:37, 1184.03it/s]\u001b[A\n",
      "2332702it [1:44:40, 1113.20it/s]\u001b[A\n",
      "2335775it [1:44:40, 1532.82it/s]\u001b[A\n",
      "2338928it [1:44:40, 2101.65it/s]\u001b[A\n",
      "2342072it [1:44:40, 2824.47it/s]\u001b[A\n",
      "2345155it [1:44:41, 3704.64it/s]\u001b[A\n",
      "2348239it [1:44:41, 4764.21it/s]\u001b[A\n",
      "2351379it [1:44:41, 5982.68it/s]\u001b[A\n",
      "2354485it [1:44:41, 7254.76it/s]\u001b[A\n",
      "2357555it [1:44:42, 8478.42it/s]\u001b[A\n",
      "2360695it [1:44:42, 9728.73it/s]\u001b[A\n",
      "2363833it [1:44:42, 10883.13it/s]\u001b[A\n",
      "2366953it [1:44:46, 2301.79it/s] \u001b[A\n",
      "2370013it [1:44:46, 3054.85it/s]\u001b[A\n",
      "2373114it [1:44:46, 3990.97it/s]\u001b[A\n",
      "2376229it [1:44:46, 5085.31it/s]\u001b[A\n",
      "2379332it [1:44:47, 6342.27it/s]\u001b[A\n",
      "2382388it [1:44:47, 7608.98it/s]\u001b[A\n",
      "2385476it [1:44:47, 8854.93it/s]\u001b[A\n",
      "2388610it [1:44:47, 10053.95it/s]\u001b[A\n",
      "2391716it [1:44:48, 11018.98it/s]\u001b[A\n",
      "2394812it [1:44:48, 11975.74it/s]\u001b[A\n",
      "2397944it [1:44:48, 12753.11it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e24eef68c6450ba9cf393ee512a87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "2397944it [1:45:06, 12753.11it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "24it [1:49:14, 288.66s/it]\n",
      "2400000it [1:49:14, 34.95it/s]   \u001b[A\n",
      "2401060it [1:49:14, 40.59it/s]\u001b[A\n",
      "2404213it [1:49:14, 64.61it/s]\u001b[A\n",
      "2407357it [1:49:14, 98.68it/s]\u001b[A\n",
      "2410480it [1:49:15, 146.77it/s]\u001b[A\n",
      "2413576it [1:49:15, 214.32it/s]\u001b[A\n",
      "2416679it [1:49:15, 309.97it/s]\u001b[A\n",
      "2419782it [1:49:15, 444.60it/s]\u001b[A\n",
      "2422867it [1:49:16, 631.33it/s]\u001b[A\n",
      "2425952it [1:49:16, 890.44it/s]\u001b[A\n",
      "2429048it [1:49:16, 1245.01it/s]\u001b[A\n",
      "2432162it [1:49:16, 1726.52it/s]\u001b[A\n",
      "2435207it [1:49:16, 2342.05it/s]\u001b[A\n",
      "2438244it [1:49:17, 3124.41it/s]\u001b[A\n",
      "2441366it [1:49:17, 4115.10it/s]\u001b[A\n",
      "2444399it [1:49:22, 1434.57it/s]\u001b[A\n",
      "2447431it [1:49:22, 1958.86it/s]\u001b[A\n",
      "2450563it [1:49:23, 2665.18it/s]\u001b[A\n",
      "2453717it [1:49:23, 3555.93it/s]\u001b[A\n",
      "2456817it [1:49:23, 4595.24it/s]\u001b[A\n",
      "2459883it [1:49:23, 5754.81it/s]\u001b[A\n",
      "2462911it [1:49:23, 6970.71it/s]\u001b[A\n",
      "2465951it [1:49:24, 8195.63it/s]\u001b[A\n",
      "2469037it [1:49:24, 9371.56it/s]\u001b[A\n",
      "2472109it [1:49:24, 10424.84it/s]\u001b[A\n",
      "2475166it [1:49:24, 11362.59it/s]\u001b[A\n",
      "2478222it [1:49:24, 12171.27it/s]\u001b[A\n",
      "2481297it [1:49:25, 12797.72it/s]\u001b[A\n",
      "2484369it [1:49:25, 13250.77it/s]\u001b[A\n",
      "2487375it [1:49:25, 13401.62it/s]\u001b[A\n",
      "2490432it [1:49:25, 13612.32it/s]\u001b[A\n",
      "2493465it [1:49:26, 13953.50it/s]\u001b[A\n",
      "2496497it [1:49:26, 14234.17it/s]\u001b[A\n",
      "2499506it [1:49:26, 14307.26it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7551e322e94d7a957c08db51e66dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "2499506it [1:49:46, 14307.26it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "25it [1:53:54, 286.21s/it]\n",
      "2500000it [1:53:54, 28.15it/s]   \u001b[A\n",
      "2502549it [1:53:55, 41.65it/s]\u001b[A\n",
      "2505584it [1:53:55, 64.57it/s]\u001b[A\n",
      "2508611it [1:53:55, 97.12it/s]\u001b[A\n",
      "2511645it [1:53:55, 143.49it/s]\u001b[A\n",
      "2514743it [1:53:55, 210.68it/s]\u001b[A\n",
      "2517817it [1:53:55, 304.96it/s]\u001b[A\n",
      "2520854it [1:53:58, 389.29it/s]\u001b[A\n",
      "2523872it [1:53:59, 551.89it/s]\u001b[A\n",
      "2526945it [1:53:59, 781.97it/s]\u001b[A\n",
      "2529930it [1:53:59, 1088.30it/s]\u001b[A\n",
      "2533043it [1:53:59, 1520.63it/s]\u001b[A\n",
      "2536108it [1:53:59, 2081.34it/s]\u001b[A\n",
      "2539187it [1:54:00, 2808.90it/s]\u001b[A\n",
      "2542254it [1:54:00, 3699.44it/s]\u001b[A\n",
      "2545380it [1:54:00, 4808.15it/s]\u001b[A\n",
      "2548451it [1:54:00, 6065.50it/s]\u001b[A\n",
      "2551497it [1:54:04, 2138.52it/s]\u001b[A\n",
      "2554593it [1:54:04, 2875.47it/s]\u001b[A\n",
      "2557685it [1:54:04, 3810.96it/s]\u001b[A\n",
      "2560717it [1:54:05, 4905.74it/s]\u001b[A\n",
      "2563791it [1:54:05, 6204.58it/s]\u001b[A\n",
      "2566829it [1:54:05, 7558.27it/s]\u001b[A\n",
      "2569915it [1:54:05, 9002.53it/s]\u001b[A\n",
      "2572971it [1:54:05, 10341.70it/s]\u001b[A\n",
      "2576092it [1:54:05, 11592.67it/s]\u001b[A\n",
      "2579151it [1:54:06, 12602.04it/s]\u001b[A\n",
      "2582221it [1:54:06, 13416.20it/s]\u001b[A\n",
      "2585326it [1:54:06, 14051.13it/s]\u001b[A\n",
      "2588430it [1:54:06, 14575.02it/s]\u001b[A\n",
      "2591530it [1:54:11, 2106.76it/s] \u001b[A\n",
      "2594616it [1:54:11, 2842.90it/s]\u001b[A\n",
      "2597673it [1:54:11, 3754.27it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3940935c3b9c48c6a5164a4fe7fde8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "2597673it [1:54:31, 3754.27it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "26it [1:58:27, 281.99s/it]\n",
      "2600000it [1:58:27, 36.97it/s]  \u001b[A\n",
      "2600784it [1:58:27, 41.28it/s]\u001b[A\n",
      "2603899it [1:58:27, 65.85it/s]\u001b[A\n",
      "2607071it [1:58:27, 101.46it/s]\u001b[A\n",
      "2610232it [1:58:27, 151.91it/s]\u001b[A\n",
      "2613313it [1:58:27, 221.62it/s]\u001b[A\n",
      "2616379it [1:58:28, 319.61it/s]\u001b[A\n",
      "2619473it [1:58:28, 458.93it/s]\u001b[A\n",
      "2622572it [1:58:33, 498.79it/s]\u001b[A\n",
      "2625743it [1:58:33, 713.09it/s]\u001b[A\n",
      "2628844it [1:58:33, 1003.12it/s]\u001b[A\n",
      "2631930it [1:58:33, 1396.14it/s]\u001b[A\n",
      "2635022it [1:58:34, 1924.93it/s]\u001b[A\n",
      "2638110it [1:58:34, 2617.03it/s]\u001b[A\n",
      "2641253it [1:58:34, 3508.48it/s]\u001b[A\n",
      "2644313it [1:58:34, 4552.27it/s]\u001b[A\n",
      "2647386it [1:58:34, 5808.91it/s]\u001b[A\n",
      "2650490it [1:58:35, 7118.13it/s]\u001b[A\n",
      "2653599it [1:58:35, 8522.38it/s]\u001b[A\n",
      "2656796it [1:58:35, 9962.40it/s]\u001b[A\n",
      "2659877it [1:58:35, 11163.70it/s]\u001b[A\n",
      "2662878it [1:58:35, 12079.75it/s]\u001b[A\n",
      "2665954it [1:58:36, 12876.33it/s]\u001b[A\n",
      "2669072it [1:58:36, 13632.96it/s]\u001b[A\n",
      "2672165it [1:58:36, 14052.54it/s]\u001b[A\n",
      "2675233it [1:58:36, 14344.59it/s]\u001b[A\n",
      "2678263it [1:58:36, 14587.61it/s]\u001b[A\n",
      "2681317it [1:58:43, 1531.54it/s] \u001b[A\n",
      "2684364it [1:58:43, 2093.09it/s]\u001b[A\n",
      "2687476it [1:58:43, 2841.04it/s]\u001b[A\n",
      "2690593it [1:58:43, 3756.27it/s]\u001b[A\n",
      "2693701it [1:58:43, 4873.87it/s]\u001b[A\n",
      "2696767it [1:58:44, 6126.21it/s]\u001b[A\n",
      "2699841it [1:58:44, 7379.44it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d5acfe9cc348109e4faa7774415b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "2699841it [1:59:03, 7379.44it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "27it [2:03:08, 281.70s/it]\n",
      "2700000it [2:03:08, 27.77it/s]  \u001b[A\n",
      "2702954it [2:03:08, 43.67it/s]\u001b[A\n",
      "2706034it [2:03:08, 67.30it/s]\u001b[A\n",
      "2709106it [2:03:08, 100.86it/s]\u001b[A\n",
      "2712112it [2:03:08, 147.56it/s]\u001b[A\n",
      "2715140it [2:03:08, 214.36it/s]\u001b[A\n",
      "2718214it [2:03:09, 310.39it/s]\u001b[A\n",
      "2721313it [2:03:09, 446.18it/s]\u001b[A\n",
      "2724385it [2:03:09, 634.14it/s]\u001b[A\n",
      "2727409it [2:03:09, 891.00it/s]\u001b[A\n",
      "2730413it [2:03:09, 1237.96it/s]\u001b[A\n",
      "2733463it [2:03:10, 1712.85it/s]\u001b[A\n",
      "2736506it [2:03:10, 2333.92it/s]\u001b[A\n",
      "2739499it [2:03:13, 1612.85it/s]\u001b[A\n",
      "2742549it [2:03:13, 2213.97it/s]\u001b[A\n",
      "2745581it [2:03:13, 2975.33it/s]\u001b[A\n",
      "2748530it [2:03:14, 3878.12it/s]\u001b[A\n",
      "2751567it [2:03:14, 5031.93it/s]\u001b[A\n",
      "2754610it [2:03:14, 6324.60it/s]\u001b[A\n",
      "2757714it [2:03:14, 7713.95it/s]\u001b[A\n",
      "2760794it [2:03:14, 9061.78it/s]\u001b[A\n",
      "2763851it [2:03:15, 10272.61it/s]\u001b[A\n",
      "2766856it [2:03:15, 11309.60it/s]\u001b[A\n",
      "2769919it [2:03:15, 12232.47it/s]\u001b[A\n",
      "2772947it [2:03:19, 2231.38it/s] \u001b[A\n",
      "2776024it [2:03:19, 3006.96it/s]\u001b[A\n",
      "2779030it [2:03:19, 3938.50it/s]\u001b[A\n",
      "2782089it [2:03:20, 5068.52it/s]\u001b[A\n",
      "2785104it [2:03:20, 6311.58it/s]\u001b[A\n",
      "2788156it [2:03:20, 7644.02it/s]\u001b[A\n",
      "2791210it [2:03:20, 8960.14it/s]\u001b[A\n",
      "2794262it [2:03:20, 10156.42it/s]\u001b[A\n",
      "2797310it [2:03:21, 11206.70it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd204a3deee24c55a4378f33603a7938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "2797310it [2:03:33, 11206.70it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "28it [2:07:34, 277.24s/it]\n",
      "2800000it [2:07:34, 38.52it/s]   \u001b[A\n",
      "2800428it [2:07:35, 40.88it/s]\u001b[A\n",
      "2803486it [2:07:35, 65.27it/s]\u001b[A\n",
      "2806576it [2:07:35, 100.34it/s]\u001b[A\n",
      "2809641it [2:07:35, 149.74it/s]\u001b[A\n",
      "2812784it [2:07:35, 221.55it/s]\u001b[A\n",
      "2815948it [2:07:36, 323.63it/s]\u001b[A\n",
      "2819030it [2:07:36, 463.27it/s]\u001b[A\n",
      "2822085it [2:07:36, 656.40it/s]\u001b[A\n",
      "2825162it [2:07:36, 925.26it/s]\u001b[A\n",
      "2828213it [2:07:36, 1288.92it/s]\u001b[A\n",
      "2831276it [2:07:37, 1777.62it/s]\u001b[A\n",
      "2834358it [2:07:37, 2423.03it/s]\u001b[A\n",
      "2837432it [2:07:37, 3237.26it/s]\u001b[A\n",
      "2840553it [2:07:37, 4250.68it/s]\u001b[A\n",
      "2843599it [2:07:38, 5389.89it/s]\u001b[A\n",
      "2846641it [2:07:38, 6634.26it/s]\u001b[A\n",
      "2849659it [2:07:43, 1503.90it/s]\u001b[A\n",
      "2852687it [2:07:44, 2047.70it/s]\u001b[A\n",
      "2855709it [2:07:44, 2742.95it/s]\u001b[A\n",
      "2858771it [2:07:44, 3627.41it/s]\u001b[A\n",
      "2861854it [2:07:44, 4685.22it/s]\u001b[A\n",
      "2864954it [2:07:44, 5910.20it/s]\u001b[A\n",
      "2868067it [2:07:45, 7254.63it/s]\u001b[A\n",
      "2871198it [2:07:45, 8636.35it/s]\u001b[A\n",
      "2874252it [2:07:45, 9962.19it/s]\u001b[A\n",
      "2877346it [2:07:45, 11178.54it/s]\u001b[A\n",
      "2880356it [2:07:45, 12126.84it/s]\u001b[A\n",
      "2883380it [2:07:46, 12900.63it/s]\u001b[A\n",
      "2886418it [2:07:46, 13543.18it/s]\u001b[A\n",
      "2889431it [2:07:46, 14074.87it/s]\u001b[A\n",
      "2892462it [2:07:46, 14480.43it/s]\u001b[A\n",
      "2895407it [2:07:46, 14586.18it/s]\u001b[A\n",
      "2898343it [2:07:47, 14663.84it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ced769243f439587b6dc6269deb665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "2898343it [2:08:04, 14663.84it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "29it [2:12:09, 276.36s/it]\n",
      "2900000it [2:12:09, 32.86it/s]   \u001b[A\n",
      "2901342it [2:12:11, 39.65it/s]\u001b[A\n",
      "2904377it [2:12:11, 62.86it/s]\u001b[A\n",
      "2907469it [2:12:11, 96.52it/s]\u001b[A\n",
      "2910569it [2:12:12, 144.49it/s]\u001b[A\n",
      "2913602it [2:12:12, 211.08it/s]\u001b[A\n",
      "2916638it [2:12:12, 305.37it/s]\u001b[A\n",
      "2919658it [2:12:12, 437.56it/s]\u001b[A\n",
      "2922725it [2:12:12, 625.26it/s]\u001b[A\n",
      "2925729it [2:12:15, 707.86it/s]\u001b[A\n",
      "2928839it [2:12:15, 1003.87it/s]\u001b[A\n",
      "2931890it [2:12:16, 1396.72it/s]\u001b[A\n",
      "2934937it [2:12:16, 1922.77it/s]\u001b[A\n",
      "2937940it [2:12:16, 2601.36it/s]\u001b[A\n",
      "2940901it [2:12:16, 3444.39it/s]\u001b[A\n",
      "2943831it [2:12:16, 4460.08it/s]\u001b[A\n",
      "2946831it [2:12:17, 5665.52it/s]\u001b[A\n",
      "2949778it [2:12:17, 7009.34it/s]\u001b[A\n",
      "2952869it [2:12:17, 8545.71it/s]\u001b[A\n",
      "2955957it [2:12:17, 9966.40it/s]\u001b[A\n",
      "2958987it [2:12:21, 2307.05it/s]\u001b[A\n",
      "2962051it [2:12:21, 3121.42it/s]\u001b[A\n",
      "2965156it [2:12:21, 4142.77it/s]\u001b[A\n",
      "2968221it [2:12:21, 5356.96it/s]\u001b[A\n",
      "2971303it [2:12:22, 6735.27it/s]\u001b[A\n",
      "2974439it [2:12:22, 8263.99it/s]\u001b[A\n",
      "2977576it [2:12:22, 9710.94it/s]\u001b[A\n",
      "2980712it [2:12:22, 11071.59it/s]\u001b[A\n",
      "2983814it [2:12:22, 12065.37it/s]\u001b[A\n",
      "2986898it [2:12:23, 12938.94it/s]\u001b[A\n",
      "2989999it [2:12:23, 13606.36it/s]\u001b[A\n",
      "2993051it [2:12:23, 14216.14it/s]\u001b[A\n",
      "2996136it [2:12:23, 14513.42it/s]\u001b[A\n",
      "2999238it [2:12:23, 14741.43it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc927108d1ae4551b79dd6d603a90d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "2999238it [2:12:35, 14741.43it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "30it [2:16:39, 274.66s/it]\n",
      "3000000it [2:16:39, 31.09it/s]   \u001b[A\n",
      "3002383it [2:16:40, 44.32it/s]\u001b[A\n",
      "3005475it [2:16:40, 68.79it/s]\u001b[A\n",
      "3008568it [2:16:40, 103.63it/s]\u001b[A\n",
      "3011650it [2:16:40, 152.95it/s]\u001b[A\n",
      "3014732it [2:16:40, 222.85it/s]\u001b[A\n",
      "3017824it [2:16:41, 321.93it/s]\u001b[A\n",
      "3020957it [2:16:41, 463.16it/s]\u001b[A\n",
      "3024058it [2:16:41, 658.43it/s]\u001b[A\n",
      "3027211it [2:16:41, 933.73it/s]\u001b[A\n",
      "3030287it [2:16:41, 1300.88it/s]\u001b[A\n",
      "3033469it [2:16:42, 1810.43it/s]\u001b[A\n",
      "3036617it [2:16:42, 2469.53it/s]\u001b[A\n",
      "3039731it [2:16:47, 1247.34it/s]\u001b[A\n",
      "3042904it [2:16:47, 1729.42it/s]\u001b[A\n",
      "3046027it [2:16:48, 2352.88it/s]\u001b[A\n",
      "3049198it [2:16:48, 3172.18it/s]\u001b[A\n",
      "3052323it [2:16:48, 4165.64it/s]\u001b[A\n",
      "3055468it [2:16:48, 5339.73it/s]\u001b[A\n",
      "3058635it [2:16:48, 6681.84it/s]\u001b[A\n",
      "3061815it [2:16:49, 8110.06it/s]\u001b[A\n",
      "3064938it [2:16:49, 9465.46it/s]\u001b[A\n",
      "3068022it [2:16:49, 10727.50it/s]\u001b[A\n",
      "3071124it [2:16:49, 11790.11it/s]\u001b[A\n",
      "3074239it [2:16:49, 12762.61it/s]\u001b[A\n",
      "3077311it [2:16:50, 13464.40it/s]\u001b[A\n",
      "3080390it [2:16:50, 14066.30it/s]\u001b[A\n",
      "3083471it [2:16:50, 14518.62it/s]\u001b[A\n",
      "3086578it [2:16:50, 14816.14it/s]\u001b[A\n",
      "3089790it [2:16:50, 15110.38it/s]\u001b[A\n",
      "3092921it [2:16:51, 15362.34it/s]\u001b[A\n",
      "3096054it [2:16:51, 15484.60it/s]\u001b[A\n",
      "3099157it [2:16:51, 15414.10it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ab5d5fd0e6498d8fd1fb35503880e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "3099157it [2:17:09, 15414.10it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "31it [2:21:17, 275.54s/it]\n",
      "3100000it [2:21:17, 30.51it/s]   \u001b[A\n",
      "3102261it [2:21:17, 42.58it/s]\u001b[A\n",
      "3105365it [2:21:17, 66.23it/s]\u001b[A\n",
      "3108488it [2:21:20, 97.54it/s]\u001b[A\n",
      "3111581it [2:21:20, 144.00it/s]\u001b[A\n",
      "3114723it [2:21:20, 210.96it/s]\u001b[A\n",
      "3117829it [2:21:21, 304.56it/s]\u001b[A\n",
      "3120817it [2:21:21, 431.17it/s]\u001b[A\n",
      "3123916it [2:21:21, 614.14it/s]\u001b[A\n",
      "3126920it [2:21:21, 858.97it/s]\u001b[A\n",
      "3129992it [2:21:21, 1201.52it/s]\u001b[A\n",
      "3133067it [2:21:22, 1661.30it/s]\u001b[A\n",
      "3136142it [2:21:25, 1361.66it/s]\u001b[A\n",
      "3139159it [2:21:25, 1860.12it/s]\u001b[A\n",
      "3142172it [2:21:25, 2504.58it/s]\u001b[A\n",
      "3145148it [2:21:25, 3302.50it/s]\u001b[A\n",
      "3148143it [2:21:26, 4275.60it/s]\u001b[A\n",
      "3151218it [2:21:26, 5439.28it/s]\u001b[A\n",
      "3154262it [2:21:26, 6669.15it/s]\u001b[A\n",
      "3157334it [2:21:26, 7963.50it/s]\u001b[A\n",
      "3160388it [2:21:27, 9171.26it/s]\u001b[A\n",
      "3163504it [2:21:27, 10314.48it/s]\u001b[A\n",
      "3166687it [2:21:27, 11365.67it/s]\u001b[A\n",
      "3169774it [2:21:27, 12132.73it/s]\u001b[A\n",
      "3172976it [2:21:31, 2271.67it/s] \u001b[A\n",
      "3176131it [2:21:31, 3047.07it/s]\u001b[A\n",
      "3179279it [2:21:32, 3999.63it/s]\u001b[A\n",
      "3182450it [2:21:32, 5125.88it/s]\u001b[A\n",
      "3185603it [2:21:32, 6367.72it/s]\u001b[A\n",
      "3188724it [2:21:32, 7670.53it/s]\u001b[A\n",
      "3191824it [2:21:32, 8928.28it/s]\u001b[A\n",
      "3194907it [2:21:33, 10048.18it/s]\u001b[A\n",
      "3198019it [2:21:33, 11068.49it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eeec698ea9e460e81f7fa7f5bcbf6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "3198019it [2:21:51, 11068.49it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "32it [2:25:42, 272.45s/it]\n",
      "3200000it [2:25:42, 37.00it/s]   \u001b[A\n",
      "3201171it [2:25:42, 43.64it/s]\u001b[A\n",
      "3204351it [2:25:47, 67.00it/s]\u001b[A\n",
      "3207440it [2:25:47, 101.42it/s]\u001b[A\n",
      "3210605it [2:25:48, 151.51it/s]\u001b[A\n",
      "3213718it [2:25:48, 221.31it/s]\u001b[A\n",
      "3216822it [2:25:48, 319.67it/s]\u001b[A\n",
      "3219961it [2:25:48, 459.48it/s]\u001b[A\n",
      "3223133it [2:25:48, 656.89it/s]\u001b[A\n",
      "3226248it [2:25:49, 924.81it/s]\u001b[A\n",
      "3229337it [2:25:49, 1286.97it/s]\u001b[A\n",
      "3232440it [2:25:49, 1776.33it/s]\u001b[A\n",
      "3235623it [2:25:49, 2434.60it/s]\u001b[A\n",
      "3238796it [2:25:49, 3273.84it/s]\u001b[A\n",
      "3241939it [2:25:50, 4285.48it/s]\u001b[A\n",
      "3245121it [2:25:50, 5493.39it/s]\u001b[A\n",
      "3248270it [2:25:50, 6802.97it/s]\u001b[A\n",
      "3251435it [2:25:50, 8168.07it/s]\u001b[A\n",
      "3254589it [2:25:50, 9495.88it/s]\u001b[A\n",
      "3257752it [2:25:51, 10777.05it/s]\u001b[A\n",
      "3260921it [2:25:56, 1630.11it/s] \u001b[A\n",
      "3264012it [2:25:57, 2211.65it/s]\u001b[A\n",
      "3267182it [2:25:57, 2976.40it/s]\u001b[A\n",
      "3270282it [2:25:57, 3911.94it/s]\u001b[A\n",
      "3273494it [2:25:57, 5069.74it/s]\u001b[A\n",
      "3276702it [2:25:57, 6369.51it/s]\u001b[A\n",
      "3279880it [2:25:58, 7737.91it/s]\u001b[A\n",
      "3283064it [2:25:58, 9090.51it/s]\u001b[A\n",
      "3286215it [2:25:58, 10337.05it/s]\u001b[A\n",
      "3289367it [2:25:58, 11352.38it/s]\u001b[A\n",
      "3292518it [2:25:58, 12195.19it/s]\u001b[A\n",
      "3295582it [2:25:59, 12854.69it/s]\u001b[A\n",
      "3298695it [2:25:59, 13385.13it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c91746ac5641e0ae98657b2205bf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "3298695it [2:26:16, 13385.13it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "33it [2:30:26, 275.96s/it]\n",
      "3300000it [2:30:26, 32.08it/s]   \u001b[A\n",
      "3301847it [2:30:27, 41.89it/s]\u001b[A\n",
      "3305016it [2:30:27, 65.90it/s]\u001b[A\n",
      "3308119it [2:30:27, 99.37it/s]\u001b[A\n",
      "3311311it [2:30:30, 142.97it/s]\u001b[A\n",
      "3314488it [2:30:30, 209.60it/s]\u001b[A\n",
      "3317660it [2:30:30, 303.67it/s]\u001b[A\n",
      "3320810it [2:30:30, 435.24it/s]\u001b[A\n",
      "3324006it [2:30:30, 621.59it/s]\u001b[A\n",
      "3327227it [2:30:31, 881.00it/s]\u001b[A\n",
      "3330422it [2:30:31, 1232.22it/s]\u001b[A\n",
      "3333623it [2:30:31, 1705.02it/s]\u001b[A\n",
      "3336822it [2:30:31, 2324.10it/s]\u001b[A\n",
      "3340018it [2:30:34, 1641.23it/s]\u001b[A\n",
      "3343236it [2:30:35, 2244.63it/s]\u001b[A\n",
      "3346416it [2:30:35, 3004.40it/s]\u001b[A\n",
      "3349636it [2:30:35, 3963.97it/s]\u001b[A\n",
      "3352869it [2:30:35, 5101.45it/s]\u001b[A\n",
      "3356097it [2:30:36, 6353.56it/s]\u001b[A\n",
      "3359288it [2:30:36, 7687.51it/s]\u001b[A\n",
      "3362550it [2:30:36, 9033.38it/s]\u001b[A\n",
      "3365769it [2:30:36, 10270.67it/s]\u001b[A\n",
      "3368926it [2:30:36, 11275.33it/s]\u001b[A\n",
      "3372120it [2:30:37, 12090.94it/s]\u001b[A\n",
      "3375275it [2:30:37, 12801.12it/s]\u001b[A\n",
      "3378496it [2:30:41, 2359.75it/s] \u001b[A\n",
      "3381765it [2:30:41, 3172.86it/s]\u001b[A\n",
      "3384963it [2:30:41, 4148.25it/s]\u001b[A\n",
      "3388143it [2:30:41, 5282.21it/s]\u001b[A\n",
      "3391341it [2:30:42, 6540.53it/s]\u001b[A\n",
      "3394553it [2:30:42, 7869.77it/s]\u001b[A\n",
      "3397800it [2:30:42, 9261.62it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c1b8df139843b7bfb20e574c574710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "3397800it [2:30:56, 9261.62it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "34it [2:34:58, 274.56s/it]\n",
      "3400000it [2:34:58, 37.86it/s]  \u001b[A\n",
      "3401020it [2:34:58, 43.50it/s]\u001b[A\n",
      "3404255it [2:34:58, 69.09it/s]\u001b[A\n",
      "3407458it [2:34:58, 105.16it/s]\u001b[A\n",
      "3410633it [2:35:03, 145.79it/s]\u001b[A\n",
      "3413822it [2:35:03, 213.45it/s]\u001b[A\n",
      "3417064it [2:35:03, 310.72it/s]\u001b[A\n",
      "3420312it [2:35:03, 447.92it/s]\u001b[A\n",
      "3423562it [2:35:04, 639.92it/s]\u001b[A\n",
      "3426752it [2:35:04, 901.00it/s]\u001b[A\n",
      "3429961it [2:35:04, 1261.42it/s]\u001b[A\n",
      "3433183it [2:35:04, 1749.57it/s]\u001b[A\n",
      "3436331it [2:35:04, 2373.96it/s]\u001b[A\n",
      "3439536it [2:35:05, 3191.34it/s]\u001b[A\n",
      "3442736it [2:35:05, 4191.77it/s]\u001b[A\n",
      "3445967it [2:35:05, 5403.54it/s]\u001b[A\n",
      "3449157it [2:35:05, 6731.14it/s]\u001b[A\n",
      "3452369it [2:35:05, 8107.81it/s]\u001b[A\n",
      "3455588it [2:35:06, 9542.39it/s]\u001b[A\n",
      "3458832it [2:35:06, 10892.91it/s]\u001b[A\n",
      "3462034it [2:35:06, 12108.48it/s]\u001b[A\n",
      "3465189it [2:35:12, 1702.15it/s] \u001b[A\n",
      "3468348it [2:35:12, 2316.61it/s]\u001b[A\n",
      "3471559it [2:35:12, 3127.26it/s]\u001b[A\n",
      "3474780it [2:35:12, 4137.42it/s]\u001b[A\n",
      "3478000it [2:35:12, 5342.19it/s]\u001b[A\n",
      "3481213it [2:35:13, 6721.91it/s]\u001b[A\n",
      "3484447it [2:35:13, 8145.54it/s]\u001b[A\n",
      "3487675it [2:35:13, 9603.16it/s]\u001b[A\n",
      "3490912it [2:35:13, 11064.37it/s]\u001b[A\n",
      "3494164it [2:35:13, 12269.91it/s]\u001b[A\n",
      "3497414it [2:35:14, 13239.28it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805961eae9aa47fe967cda7c75581263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "3497414it [2:35:32, 13239.28it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "35it [2:39:36, 275.62s/it]\n",
      "3500000it [2:39:36, 38.61it/s]   \u001b[A\n",
      "3500683it [2:39:36, 42.29it/s]\u001b[A\n",
      "3503913it [2:39:36, 67.26it/s]\u001b[A\n",
      "3507178it [2:39:36, 103.19it/s]\u001b[A\n",
      "3510437it [2:39:36, 154.18it/s]\u001b[A\n",
      "3513664it [2:39:37, 225.74it/s]\u001b[A\n",
      "3516951it [2:39:39, 304.80it/s]\u001b[A\n",
      "3520221it [2:39:40, 438.80it/s]\u001b[A\n",
      "3523539it [2:39:40, 628.75it/s]\u001b[A\n",
      "3526837it [2:39:40, 890.11it/s]\u001b[A\n",
      "3530082it [2:39:40, 1241.14it/s]\u001b[A\n",
      "3533332it [2:39:40, 1715.00it/s]\u001b[A\n",
      "3536596it [2:39:41, 2344.03it/s]\u001b[A\n",
      "3539854it [2:39:41, 3145.76it/s]\u001b[A\n",
      "3543078it [2:39:41, 4117.57it/s]\u001b[A\n",
      "3546303it [2:39:44, 2079.20it/s]\u001b[A\n",
      "3549528it [2:39:45, 2798.77it/s]\u001b[A\n",
      "3552739it [2:39:45, 3700.55it/s]\u001b[A\n",
      "3555931it [2:39:45, 4772.47it/s]\u001b[A\n",
      "3559171it [2:39:45, 6009.81it/s]\u001b[A\n",
      "3562412it [2:39:45, 7368.80it/s]\u001b[A\n",
      "3565639it [2:39:46, 8710.78it/s]\u001b[A\n",
      "3568842it [2:39:46, 9960.53it/s]\u001b[A\n",
      "3572014it [2:39:46, 11066.28it/s]\u001b[A\n",
      "3575152it [2:39:46, 11944.12it/s]\u001b[A\n",
      "3578330it [2:39:47, 12688.69it/s]\u001b[A\n",
      "3581507it [2:39:47, 13265.97it/s]\u001b[A\n",
      "3584656it [2:39:51, 2266.71it/s] \u001b[A\n",
      "3587764it [2:39:51, 3021.39it/s]\u001b[A\n",
      "3590933it [2:39:51, 3974.06it/s]\u001b[A\n",
      "3594092it [2:39:51, 5092.64it/s]\u001b[A\n",
      "3597283it [2:39:52, 6365.91it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76627dbdb38b455fae4f285be7e5d4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "3597283it [2:40:04, 6365.91it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "36it [2:44:15, 276.68s/it]\n",
      "3600000it [2:44:15, 38.24it/s]  \u001b[A\n",
      "3600432it [2:44:15, 40.53it/s]\u001b[A\n",
      "3603711it [2:44:15, 65.72it/s]\u001b[A\n",
      "3606937it [2:44:15, 100.99it/s]\u001b[A\n",
      "3610127it [2:44:16, 150.55it/s]\u001b[A\n",
      "3613331it [2:44:16, 221.14it/s]\u001b[A\n",
      "3616514it [2:44:21, 280.66it/s]\u001b[A\n",
      "3619729it [2:44:21, 404.49it/s]\u001b[A\n",
      "3622951it [2:44:21, 578.61it/s]\u001b[A\n",
      "3626101it [2:44:21, 815.31it/s]\u001b[A\n",
      "3629332it [2:44:21, 1149.89it/s]\u001b[A\n",
      "3632510it [2:44:22, 1595.33it/s]\u001b[A\n",
      "3635692it [2:44:22, 2188.70it/s]\u001b[A\n",
      "3638919it [2:44:22, 2965.59it/s]\u001b[A\n",
      "3642121it [2:44:22, 3934.09it/s]\u001b[A\n",
      "3645310it [2:44:22, 5093.35it/s]\u001b[A\n",
      "3648525it [2:44:23, 6380.31it/s]\u001b[A\n",
      "3651676it [2:44:23, 7724.10it/s]\u001b[A\n",
      "3654848it [2:44:23, 9101.39it/s]\u001b[A\n",
      "3658010it [2:44:23, 10389.57it/s]\u001b[A\n",
      "3661210it [2:44:23, 11613.16it/s]\u001b[A\n",
      "3664444it [2:44:24, 12637.42it/s]\u001b[A\n",
      "3667580it [2:44:24, 13508.10it/s]\u001b[A\n",
      "3670747it [2:44:24, 14216.90it/s]\u001b[A\n",
      "3673900it [2:44:30, 1672.57it/s] \u001b[A\n",
      "3677071it [2:44:30, 2288.11it/s]\u001b[A\n",
      "3680309it [2:44:30, 3102.41it/s]\u001b[A\n",
      "3683519it [2:44:30, 4102.22it/s]\u001b[A\n",
      "3686673it [2:44:31, 5264.81it/s]\u001b[A\n",
      "3689881it [2:44:31, 6580.14it/s]\u001b[A\n",
      "3693062it [2:44:31, 7997.57it/s]\u001b[A\n",
      "3696250it [2:44:31, 9434.18it/s]\u001b[A\n",
      "3699434it [2:44:31, 10802.56it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb16ab9af7364f93b78a082a2fed39cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "3699434it [2:44:50, 10802.56it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "37it [2:48:51, 276.55s/it]\n",
      "3700000it [2:48:51, 30.71it/s]   \u001b[A\n",
      "3702616it [2:48:51, 45.01it/s]\u001b[A\n",
      "3705786it [2:48:52, 69.71it/s]\u001b[A\n",
      "3709012it [2:48:52, 105.50it/s]\u001b[A\n",
      "3712171it [2:48:52, 155.30it/s]\u001b[A\n",
      "3715330it [2:48:52, 225.96it/s]\u001b[A\n",
      "3718495it [2:48:52, 326.05it/s]\u001b[A\n",
      "3721643it [2:48:52, 466.37it/s]\u001b[A\n",
      "3724806it [2:48:53, 663.27it/s]\u001b[A\n",
      "3727959it [2:48:56, 749.54it/s]\u001b[A\n",
      "3731154it [2:48:56, 1054.39it/s]\u001b[A\n",
      "3734354it [2:48:56, 1468.72it/s]\u001b[A\n",
      "3737506it [2:48:56, 2008.91it/s]\u001b[A\n",
      "3740611it [2:48:56, 2695.11it/s]\u001b[A\n",
      "3743714it [2:48:57, 3549.57it/s]\u001b[A\n",
      "3746839it [2:48:57, 4590.72it/s]\u001b[A\n",
      "3749986it [2:48:57, 5784.85it/s]\u001b[A\n",
      "3753145it [2:48:57, 7078.17it/s]\u001b[A\n",
      "3756284it [2:48:58, 8366.47it/s]\u001b[A\n",
      "3759411it [2:48:58, 9609.98it/s]\u001b[A\n",
      "3762513it [2:49:01, 2355.19it/s]\u001b[A\n",
      "3765652it [2:49:02, 3157.35it/s]\u001b[A\n",
      "3768789it [2:49:02, 4155.18it/s]\u001b[A\n",
      "3771885it [2:49:02, 5306.87it/s]\u001b[A\n",
      "3775018it [2:49:02, 6614.39it/s]\u001b[A\n",
      "3778166it [2:49:02, 8000.68it/s]\u001b[A\n",
      "3781281it [2:49:03, 9332.02it/s]\u001b[A\n",
      "3784399it [2:49:03, 10602.44it/s]\u001b[A\n",
      "3787561it [2:49:03, 11694.31it/s]\u001b[A\n",
      "3790538it [2:49:03, 12287.58it/s]\u001b[A\n",
      "3793674it [2:49:03, 12897.44it/s]\u001b[A\n",
      "3796779it [2:49:04, 13581.33it/s]\u001b[A\n",
      "3799839it [2:49:04, 14033.48it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab186e9168841c9b1283efb12309663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "3799839it [2:49:21, 14033.48it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "38it [2:53:39, 279.90s/it]\n",
      "3800000it [2:53:39, 26.76it/s]   \u001b[A\n",
      "3802960it [2:53:39, 42.06it/s]\u001b[A\n",
      "3806110it [2:53:39, 65.27it/s]\u001b[A\n",
      "3809261it [2:53:39, 98.31it/s]\u001b[A\n",
      "3812349it [2:53:40, 144.31it/s]\u001b[A\n",
      "3815474it [2:53:40, 210.31it/s]\u001b[A\n",
      "3818590it [2:53:40, 303.31it/s]\u001b[A\n",
      "3821710it [2:53:40, 434.35it/s]\u001b[A\n",
      "3824776it [2:53:41, 614.21it/s]\u001b[A\n",
      "3827904it [2:53:41, 868.53it/s]\u001b[A\n",
      "3830975it [2:53:41, 1210.19it/s]\u001b[A\n",
      "3834119it [2:53:41, 1681.72it/s]\u001b[A\n",
      "3837209it [2:53:41, 2288.04it/s]\u001b[A\n",
      "3840318it [2:53:47, 1217.05it/s]\u001b[A\n",
      "3843391it [2:53:47, 1674.31it/s]\u001b[A\n",
      "3846548it [2:53:47, 2295.32it/s]\u001b[A\n",
      "3849744it [2:53:47, 3097.74it/s]\u001b[A\n",
      "3852866it [2:53:48, 4034.93it/s]\u001b[A\n",
      "3855955it [2:53:48, 5152.22it/s]\u001b[A\n",
      "3859148it [2:53:48, 6452.65it/s]\u001b[A\n",
      "3862332it [2:53:48, 7836.95it/s]\u001b[A\n",
      "3865439it [2:53:48, 9142.70it/s]\u001b[A\n",
      "3868585it [2:53:49, 10392.58it/s]\u001b[A\n",
      "3871757it [2:53:49, 11534.85it/s]\u001b[A\n",
      "3874923it [2:53:49, 12441.50it/s]\u001b[A\n",
      "3878133it [2:53:49, 13218.12it/s]\u001b[A\n",
      "3881345it [2:53:49, 13801.23it/s]\u001b[A\n",
      "3884574it [2:53:50, 14216.77it/s]\u001b[A\n",
      "3887790it [2:53:50, 14639.67it/s]\u001b[A\n",
      "3891044it [2:53:50, 14852.11it/s]\u001b[A\n",
      "3894224it [2:53:50, 14952.31it/s]\u001b[A\n",
      "3897411it [2:53:50, 15076.78it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc34fc799de427389a8d4e98f05ef84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3897411it [2:54:02, 15076.78it/s]\u001b[AThe following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "39it [2:58:09, 277.05s/it]\n",
      "3900000it [2:58:09, 38.79it/s]   \u001b[A\n",
      "3900592it [2:58:09, 42.01it/s]\u001b[A\n",
      "3903818it [2:58:10, 67.28it/s]\u001b[A\n",
      "3907016it [2:58:12, 100.36it/s]\u001b[A\n",
      "3910243it [2:58:12, 150.23it/s]\u001b[A\n",
      "3913467it [2:58:12, 220.95it/s]\u001b[A\n",
      "3916682it [2:58:13, 320.61it/s]\u001b[A\n",
      "3919971it [2:58:13, 464.27it/s]\u001b[A\n",
      "3923234it [2:58:13, 664.01it/s]\u001b[A\n",
      "3926457it [2:58:13, 936.47it/s]\u001b[A\n",
      "3929733it [2:58:13, 1316.02it/s]\u001b[A\n",
      "3932971it [2:58:14, 1818.90it/s]\u001b[A\n",
      "3936162it [2:58:17, 1492.01it/s]\u001b[A\n",
      "3939313it [2:58:17, 2034.62it/s]\u001b[A\n",
      "3942498it [2:58:17, 2754.20it/s]\u001b[A\n",
      "3945672it [2:58:17, 3657.39it/s]\u001b[A\n",
      "3948881it [2:58:17, 4770.27it/s]\u001b[A\n",
      "3952090it [2:58:18, 6065.67it/s]\u001b[A\n",
      "3955328it [2:58:18, 7480.60it/s]\u001b[A\n",
      "3958521it [2:58:18, 8903.30it/s]\u001b[A\n",
      "3961729it [2:58:18, 10306.94it/s]\u001b[A\n",
      "3964902it [2:58:18, 11511.27it/s]\u001b[A\n",
      "3968111it [2:58:19, 12574.52it/s]\u001b[A\n",
      "3971321it [2:58:23, 2414.76it/s] \u001b[A\n",
      "3974587it [2:58:23, 3258.04it/s]\u001b[A\n",
      "3977815it [2:58:23, 4289.25it/s]\u001b[A\n",
      "3981052it [2:58:23, 5506.54it/s]\u001b[A\n",
      "3984296it [2:58:23, 6855.60it/s]\u001b[A\n",
      "3987500it [2:58:24, 8226.73it/s]\u001b[A\n",
      "3990770it [2:58:24, 9674.95it/s]\u001b[A\n",
      "3994036it [2:58:24, 11021.01it/s]\u001b[A\n",
      "3997257it [2:58:24, 12103.52it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6405fab5fa03423b85c361a50338d7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "3997257it [2:58:42, 12103.52it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "40it [3:02:38, 274.67s/it]\n",
      "4000000it [3:02:38, 40.41it/s]   \u001b[A\n",
      "4000507it [3:02:43, 42.21it/s]\u001b[A\n",
      "4003785it [3:02:43, 67.71it/s]\u001b[A\n",
      "4007060it [3:02:43, 103.97it/s]\u001b[A\n",
      "4010324it [3:02:43, 155.30it/s]\u001b[A\n",
      "4013625it [3:02:44, 228.90it/s]\u001b[A\n",
      "4016923it [3:02:44, 332.72it/s]\u001b[A\n",
      "4020265it [3:02:44, 480.55it/s]\u001b[A\n",
      "4023641it [3:02:44, 689.40it/s]\u001b[A\n",
      "4027055it [3:02:44, 982.04it/s]\u001b[A\n",
      "4030487it [3:02:45, 1383.27it/s]\u001b[A\n",
      "4033852it [3:02:45, 1912.24it/s]\u001b[A\n",
      "4037210it [3:02:45, 2605.65it/s]\u001b[A\n",
      "4040474it [3:02:45, 3464.62it/s]\u001b[A\n",
      "4043749it [3:02:45, 4526.50it/s]\u001b[A\n",
      "4047124it [3:02:46, 5790.61it/s]\u001b[A\n",
      "4050507it [3:02:46, 7225.96it/s]\u001b[A\n",
      "4053876it [3:02:51, 1681.58it/s]\u001b[A\n",
      "4057149it [3:02:52, 2282.66it/s]\u001b[A\n",
      "4060504it [3:02:52, 3080.72it/s]\u001b[A\n",
      "4063804it [3:02:52, 4053.21it/s]\u001b[A\n",
      "4067099it [3:02:52, 5200.17it/s]\u001b[A\n",
      "4070407it [3:02:52, 6519.11it/s]\u001b[A\n",
      "4073709it [3:02:53, 7867.96it/s]\u001b[A\n",
      "4077119it [3:02:53, 9345.60it/s]\u001b[A\n",
      "4080545it [3:02:53, 10705.83it/s]\u001b[A\n",
      "4083855it [3:02:53, 11814.80it/s]\u001b[A\n",
      "4087110it [3:02:54, 12783.06it/s]\u001b[A\n",
      "4090491it [3:02:54, 13723.83it/s]\u001b[A\n",
      "4093863it [3:02:54, 14371.95it/s]\u001b[A\n",
      "4097147it [3:02:54, 14786.16it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e5e0ccca554ab0a1e8704282b91a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "4097147it [3:03:13, 14786.16it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "41it [3:07:27, 278.88s/it]\n",
      "4100000it [3:07:27, 38.84it/s]   \u001b[A\n",
      "4100481it [3:07:27, 41.31it/s]\u001b[A\n",
      "4103766it [3:07:30, 64.65it/s]\u001b[A\n",
      "4107017it [3:07:30, 98.47it/s]\u001b[A\n",
      "4110312it [3:07:30, 147.20it/s]\u001b[A\n",
      "4113618it [3:07:30, 216.57it/s]\u001b[A\n",
      "4116914it [3:07:30, 314.42it/s]\u001b[A\n",
      "4120247it [3:07:31, 453.80it/s]\u001b[A\n",
      "4123575it [3:07:31, 648.29it/s]\u001b[A\n",
      "4126980it [3:07:31, 923.18it/s]\u001b[A\n",
      "4130428it [3:07:31, 1303.53it/s]\u001b[A\n",
      "4133935it [3:07:34, 1259.83it/s]\u001b[A\n",
      "4137411it [3:07:34, 1751.22it/s]\u001b[A\n",
      "4140782it [3:07:35, 2377.45it/s]\u001b[A\n",
      "4144246it [3:07:35, 3206.99it/s]\u001b[A\n",
      "4147793it [3:07:35, 4262.03it/s]\u001b[A\n",
      "4151345it [3:07:35, 5497.99it/s]\u001b[A\n",
      "4154928it [3:07:36, 6892.84it/s]\u001b[A\n",
      "4158472it [3:07:36, 8325.26it/s]\u001b[A\n",
      "4162026it [3:07:36, 9735.67it/s]\u001b[A\n",
      "4165647it [3:07:36, 11124.89it/s]\u001b[A\n",
      "4169247it [3:07:40, 2664.76it/s] \u001b[A\n",
      "4172734it [3:07:40, 3526.71it/s]\u001b[A\n",
      "4176098it [3:07:40, 4525.27it/s]\u001b[A\n",
      "4179579it [3:07:41, 5764.03it/s]\u001b[A\n",
      "4183183it [3:07:41, 7197.74it/s]\u001b[A\n",
      "4186777it [3:07:41, 8681.97it/s]\u001b[A\n",
      "4190244it [3:07:41, 10025.05it/s]\u001b[A\n",
      "4193560it [3:07:42, 11113.21it/s]\u001b[A\n",
      "4196868it [3:07:42, 12055.04it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d6fa2ed4c5430e8f81843511452b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "4196868it [3:07:54, 12055.04it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "42it [3:12:00, 277.06s/it]\n",
      "4200000it [3:12:00, 42.88it/s]   \u001b[A\n",
      "4200160it [3:12:00, 43.72it/s]\u001b[A\n",
      "4203528it [3:12:00, 70.12it/s]\u001b[A\n",
      "4206888it [3:12:01, 107.60it/s]\u001b[A\n",
      "4210324it [3:12:01, 162.05it/s]\u001b[A\n",
      "4213759it [3:12:01, 239.18it/s]\u001b[A\n",
      "4217302it [3:12:01, 351.57it/s]\u001b[A\n",
      "4220896it [3:12:01, 511.74it/s]\u001b[A\n",
      "4224539it [3:12:02, 738.23it/s]\u001b[A\n",
      "4228130it [3:12:02, 1047.05it/s]\u001b[A\n",
      "4231535it [3:12:02, 1446.02it/s]\u001b[A\n",
      "4234929it [3:12:02, 1979.78it/s]\u001b[A\n",
      "4238432it [3:12:02, 2703.47it/s]\u001b[A\n",
      "4241882it [3:12:03, 3610.00it/s]\u001b[A\n",
      "4245325it [3:12:03, 4723.64it/s]\u001b[A\n",
      "4248755it [3:12:08, 1676.13it/s]\u001b[A\n",
      "4252251it [3:12:08, 2305.12it/s]\u001b[A\n",
      "4255768it [3:12:08, 3128.96it/s]\u001b[A\n",
      "4259278it [3:12:09, 4148.49it/s]\u001b[A\n",
      "4262833it [3:12:09, 5404.56it/s]\u001b[A\n",
      "4266353it [3:12:09, 6809.23it/s]\u001b[A\n",
      "4269868it [3:12:09, 8347.09it/s]\u001b[A\n",
      "4273342it [3:12:09, 9896.48it/s]\u001b[A\n",
      "4276798it [3:12:10, 11321.26it/s]\u001b[A\n",
      "4280310it [3:12:10, 12722.63it/s]\u001b[A\n",
      "4283692it [3:12:10, 13743.20it/s]\u001b[A\n",
      "4287165it [3:12:10, 14630.05it/s]\u001b[A\n",
      "4290607it [3:12:10, 15321.67it/s]\u001b[A\n",
      "4294190it [3:12:11, 15999.08it/s]\u001b[A\n",
      "4297708it [3:12:11, 16536.87it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea26c442af54c1ab6cac4e05ba8723d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "4297708it [3:12:28, 16536.87it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "43it [3:16:28, 274.32s/it]\n",
      "4300000it [3:16:28, 40.63it/s]   \u001b[A\n",
      "4301263it [3:16:28, 47.59it/s]\u001b[A\n",
      "4304854it [3:16:28, 75.90it/s]\u001b[A\n",
      "4308472it [3:16:28, 116.51it/s]\u001b[A\n",
      "4312137it [3:16:29, 174.92it/s]\u001b[A\n",
      "4315769it [3:16:29, 257.05it/s]\u001b[A\n",
      "4319438it [3:16:29, 374.35it/s]\u001b[A\n",
      "4323145it [3:16:29, 540.91it/s]\u001b[A\n",
      "4326625it [3:16:32, 651.49it/s]\u001b[A\n",
      "4329844it [3:16:32, 890.91it/s]\u001b[A\n",
      "4333100it [3:16:32, 1223.66it/s]\u001b[A\n",
      "4336293it [3:16:33, 1663.09it/s]\u001b[A\n",
      "4339447it [3:16:33, 2237.10it/s]\u001b[A\n",
      "4342655it [3:16:33, 2990.65it/s]\u001b[A\n",
      "4345836it [3:16:33, 3913.62it/s]\u001b[A\n",
      "4349157it [3:16:33, 5076.74it/s]\u001b[A\n",
      "4352410it [3:16:34, 6328.46it/s]\u001b[A\n",
      "4355649it [3:16:37, 2343.28it/s]\u001b[A\n",
      "4358894it [3:16:37, 3121.29it/s]\u001b[A\n",
      "4362137it [3:16:38, 4094.16it/s]\u001b[A\n",
      "4365349it [3:16:38, 5227.89it/s]\u001b[A\n",
      "4368585it [3:16:38, 6512.33it/s]\u001b[A\n",
      "4371846it [3:16:38, 7898.69it/s]\u001b[A\n",
      "4375107it [3:16:38, 9251.15it/s]\u001b[A\n",
      "4378394it [3:16:39, 10489.83it/s]\u001b[A\n",
      "4381685it [3:16:39, 11629.77it/s]\u001b[A\n",
      "4384967it [3:16:39, 12508.23it/s]\u001b[A\n",
      "4388304it [3:16:39, 13089.17it/s]\u001b[A\n",
      "4391569it [3:16:39, 13523.99it/s]\u001b[A\n",
      "4394789it [3:16:40, 13937.83it/s]\u001b[A\n",
      "4398030it [3:16:44, 2288.34it/s] \u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c8a90fedbe41b6aedba3e81eeb35a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "4398030it [3:16:58, 2288.34it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "44it [3:21:00, 273.82s/it]\n",
      "4400000it [3:21:00, 36.83it/s]  \u001b[A\n",
      "4401254it [3:21:01, 43.67it/s]\u001b[A\n",
      "4404510it [3:21:01, 69.10it/s]\u001b[A\n",
      "4407714it [3:21:01, 104.71it/s]\u001b[A\n",
      "4410933it [3:21:01, 155.55it/s]\u001b[A\n",
      "4414181it [3:21:01, 228.28it/s]\u001b[A\n",
      "4417457it [3:21:02, 331.94it/s]\u001b[A\n",
      "4420764it [3:21:02, 479.17it/s]\u001b[A\n",
      "4424046it [3:21:02, 682.95it/s]\u001b[A\n",
      "4427331it [3:21:02, 965.75it/s]\u001b[A\n",
      "4430573it [3:21:02, 1346.81it/s]\u001b[A\n",
      "4433760it [3:21:07, 1020.92it/s]\u001b[A\n",
      "4437009it [3:21:08, 1419.12it/s]\u001b[A\n",
      "4440316it [3:21:08, 1960.21it/s]\u001b[A\n",
      "4443505it [3:21:08, 2640.11it/s]\u001b[A\n",
      "4446699it [3:21:08, 3501.78it/s]\u001b[A\n",
      "4449867it [3:21:08, 4534.46it/s]\u001b[A\n",
      "4452951it [3:21:09, 5677.21it/s]\u001b[A\n",
      "4455994it [3:21:09, 6828.77it/s]\u001b[A\n",
      "4459071it [3:21:09, 8105.57it/s]\u001b[A\n",
      "4462183it [3:21:09, 9313.56it/s]\u001b[A\n",
      "4465256it [3:21:10, 10258.05it/s]\u001b[A\n",
      "4468333it [3:21:10, 11213.15it/s]\u001b[A\n",
      "4471424it [3:21:10, 12151.11it/s]\u001b[A\n",
      "4474521it [3:21:10, 12859.85it/s]\u001b[A\n",
      "4477620it [3:21:10, 13354.46it/s]\u001b[A\n",
      "4480675it [3:21:11, 13743.47it/s]\u001b[A\n",
      "4483825it [3:21:11, 14055.33it/s]\u001b[A\n",
      "4486991it [3:21:11, 14330.81it/s]\u001b[A\n",
      "4490130it [3:21:17, 1647.10it/s] \u001b[A\n",
      "4493235it [3:21:17, 2238.27it/s]\u001b[A\n",
      "4496381it [3:21:17, 3019.49it/s]\u001b[A\n",
      "4499496it [3:21:17, 3986.55it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6822dd87bf4741b9e4f3f5d668da7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "4499496it [3:21:28, 3986.55it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "45it [3:25:46, 277.34s/it]\n",
      "4500000it [3:25:46, 28.83it/s]  \u001b[A\n",
      "4502638it [3:25:46, 42.72it/s]\u001b[A\n",
      "4505784it [3:25:46, 66.33it/s]\u001b[A\n",
      "4508963it [3:25:47, 100.31it/s]\u001b[A\n",
      "4512119it [3:25:47, 148.26it/s]\u001b[A\n",
      "4515249it [3:25:47, 215.72it/s]\u001b[A\n",
      "4518425it [3:25:47, 312.55it/s]\u001b[A\n",
      "4521593it [3:25:47, 448.17it/s]\u001b[A\n",
      "4524753it [3:25:48, 637.13it/s]\u001b[A\n",
      "4527923it [3:25:48, 899.40it/s]\u001b[A\n",
      "4531163it [3:25:48, 1266.45it/s]\u001b[A\n",
      "4534397it [3:25:48, 1753.23it/s]\u001b[A\n",
      "4537630it [3:25:48, 2385.58it/s]\u001b[A\n",
      "4540760it [3:25:49, 3167.43it/s]\u001b[A\n",
      "4543986it [3:25:52, 1887.41it/s]\u001b[A\n",
      "4547136it [3:25:52, 2544.50it/s]\u001b[A\n",
      "4550270it [3:25:52, 3374.02it/s]\u001b[A\n",
      "4553408it [3:25:53, 4383.87it/s]\u001b[A\n",
      "4556577it [3:25:53, 5570.23it/s]\u001b[A\n",
      "4559738it [3:25:53, 6873.88it/s]\u001b[A\n",
      "4562864it [3:25:53, 8192.91it/s]\u001b[A\n",
      "4565979it [3:25:53, 9466.02it/s]\u001b[A\n",
      "4569121it [3:25:54, 10676.39it/s]\u001b[A\n",
      "4572269it [3:25:54, 11543.39it/s]\u001b[A\n",
      "4575389it [3:25:54, 12301.38it/s]\u001b[A\n",
      "4578368it [3:25:54, 12767.74it/s]\u001b[A\n",
      "4581366it [3:25:58, 2176.10it/s] \u001b[A\n",
      "4584600it [3:25:59, 2968.58it/s]\u001b[A\n",
      "4587828it [3:25:59, 3949.22it/s]\u001b[A\n",
      "4591015it [3:25:59, 5094.37it/s]\u001b[A\n",
      "4594203it [3:25:59, 6390.41it/s]\u001b[A\n",
      "4597326it [3:26:00, 7719.84it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c6476f930a4e3598ba5888865340fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "4597326it [3:26:18, 7719.84it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "46it [3:30:12, 273.84s/it]\n",
      "4600000it [3:30:12, 39.64it/s]  \u001b[A\n",
      "4600478it [3:30:12, 42.29it/s]\u001b[A\n",
      "4603667it [3:30:12, 67.85it/s]\u001b[A\n",
      "4606762it [3:30:12, 103.11it/s]\u001b[A\n",
      "4609819it [3:30:13, 152.59it/s]\u001b[A\n",
      "4612916it [3:30:13, 223.64it/s]\u001b[A\n",
      "4616030it [3:30:18, 281.56it/s]\u001b[A\n",
      "4619142it [3:30:18, 404.85it/s]\u001b[A\n",
      "4622190it [3:30:18, 573.87it/s]\u001b[A\n",
      "4625276it [3:30:18, 811.37it/s]\u001b[A\n",
      "4628406it [3:30:18, 1140.71it/s]\u001b[A\n",
      "4631550it [3:30:19, 1582.74it/s]\u001b[A\n",
      "4634681it [3:30:19, 2172.30it/s]\u001b[A\n",
      "4637777it [3:30:19, 2913.66it/s]\u001b[A\n",
      "4640884it [3:30:19, 3810.82it/s]\u001b[A\n",
      "4644000it [3:30:20, 4899.23it/s]\u001b[A\n",
      "4647148it [3:30:20, 6139.90it/s]\u001b[A\n",
      "4650313it [3:30:20, 7499.51it/s]\u001b[A\n",
      "4653443it [3:30:20, 8770.87it/s]\u001b[A\n",
      "4656571it [3:30:20, 10043.70it/s]\u001b[A\n",
      "4659725it [3:30:21, 11189.39it/s]\u001b[A\n",
      "4662853it [3:30:21, 12084.55it/s]\u001b[A\n",
      "4666031it [3:30:21, 12843.21it/s]\u001b[A\n",
      "4669156it [3:30:21, 13108.37it/s]\u001b[A\n",
      "4672353it [3:30:27, 1603.22it/s] \u001b[A\n",
      "4675487it [3:30:27, 2182.90it/s]\u001b[A\n",
      "4678595it [3:30:28, 2924.28it/s]\u001b[A\n",
      "4681675it [3:30:28, 3809.74it/s]\u001b[A\n",
      "4684737it [3:30:28, 4865.00it/s]\u001b[A\n",
      "4687838it [3:30:28, 6071.78it/s]\u001b[A\n",
      "4690943it [3:30:29, 7394.78it/s]\u001b[A\n",
      "4694023it [3:30:29, 8657.24it/s]\u001b[A\n",
      "4696977it [3:30:29, 9490.77it/s]\u001b[A\n",
      "4699922it [3:30:29, 10295.66it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1544686c1c084455b08ff7e30b91a015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "4699922it [3:30:48, 10295.66it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "47it [3:34:48, 274.71s/it]\n",
      "4700000it [3:34:48, 27.43it/s]   \u001b[A\n",
      "4702803it [3:34:49, 42.79it/s]\u001b[A\n",
      "4705626it [3:34:49, 64.84it/s]\u001b[A\n",
      "4708377it [3:34:49, 95.42it/s]\u001b[A\n",
      "4711096it [3:34:49, 138.37it/s]\u001b[A\n",
      "4713731it [3:34:49, 197.39it/s]\u001b[A\n",
      "4716310it [3:34:50, 279.01it/s]\u001b[A\n",
      "4719153it [3:34:50, 405.99it/s]\u001b[A\n",
      "4722174it [3:34:50, 594.35it/s]\u001b[A\n",
      "4725134it [3:34:53, 678.53it/s]\u001b[A\n",
      "4728161it [3:34:53, 969.00it/s]\u001b[A\n",
      "4731168it [3:34:53, 1359.90it/s]\u001b[A\n",
      "4734222it [3:34:54, 1883.67it/s]\u001b[A\n",
      "4737221it [3:34:54, 2552.98it/s]\u001b[A\n",
      "4740185it [3:34:54, 3376.60it/s]\u001b[A\n",
      "4743183it [3:34:54, 4365.72it/s]\u001b[A\n",
      "4746288it [3:34:54, 5583.98it/s]\u001b[A\n",
      "4749367it [3:34:55, 6902.52it/s]\u001b[A\n",
      "4752493it [3:34:55, 8225.42it/s]\u001b[A\n",
      "4755524it [3:34:58, 2283.55it/s]\u001b[A\n",
      "4758577it [3:34:59, 3063.23it/s]\u001b[A\n",
      "4761603it [3:34:59, 4004.90it/s]\u001b[A\n",
      "4764559it [3:34:59, 5042.41it/s]\u001b[A\n",
      "4767577it [3:34:59, 6199.11it/s]\u001b[A\n",
      "4770547it [3:35:00, 7415.95it/s]\u001b[A\n",
      "4773589it [3:35:00, 8749.72it/s]\u001b[A\n",
      "4776574it [3:35:00, 9936.92it/s]\u001b[A\n",
      "4779693it [3:35:00, 11213.59it/s]\u001b[A\n",
      "4782765it [3:35:00, 12196.19it/s]\u001b[A\n",
      "4785834it [3:35:01, 12990.41it/s]\u001b[A\n",
      "4788941it [3:35:01, 13615.20it/s]\u001b[A\n",
      "4791996it [3:35:01, 14051.33it/s]\u001b[A\n",
      "4795067it [3:35:01, 14052.67it/s]\u001b[A\n",
      "4798196it [3:35:06, 2041.12it/s] \u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6e439683c9414e82ff12e7c72b3917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "4798196it [3:35:18, 2041.12it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "48it [3:39:23, 274.79s/it]\n",
      "4800000it [3:39:23, 34.47it/s]  \u001b[A\n",
      "4801276it [3:39:24, 41.40it/s]\u001b[A\n",
      "4804347it [3:39:24, 65.26it/s]\u001b[A\n",
      "4807391it [3:39:24, 98.91it/s]\u001b[A\n",
      "4810448it [3:39:24, 146.93it/s]\u001b[A\n",
      "4813572it [3:39:24, 216.47it/s]\u001b[A\n",
      "4816744it [3:39:25, 316.25it/s]\u001b[A\n",
      "4819880it [3:39:25, 455.16it/s]\u001b[A\n",
      "4823005it [3:39:25, 648.85it/s]\u001b[A\n",
      "4826085it [3:39:25, 913.00it/s]\u001b[A\n",
      "4829120it [3:39:30, 788.54it/s]\u001b[A\n",
      "4832197it [3:39:31, 1104.06it/s]\u001b[A\n",
      "4835336it [3:39:31, 1541.84it/s]\u001b[A\n",
      "4838421it [3:39:31, 2113.69it/s]\u001b[A\n",
      "4841465it [3:39:31, 2838.07it/s]\u001b[A\n",
      "4844601it [3:39:31, 3768.09it/s]\u001b[A\n",
      "4847633it [3:39:32, 4846.93it/s]\u001b[A\n",
      "4850626it [3:39:32, 6054.82it/s]\u001b[A\n",
      "4853661it [3:39:32, 7387.23it/s]\u001b[A\n",
      "4856710it [3:39:32, 8656.94it/s]\u001b[A\n",
      "4859801it [3:39:32, 9810.78it/s]\u001b[A\n",
      "4862871it [3:39:33, 10945.70it/s]\u001b[A\n",
      "4865982it [3:39:33, 11858.37it/s]\u001b[A\n",
      "4869076it [3:39:33, 12805.00it/s]\u001b[A\n",
      "4872212it [3:39:33, 13561.33it/s]\u001b[A\n",
      "4875316it [3:39:33, 14092.74it/s]\u001b[A\n",
      "4878431it [3:39:34, 14549.46it/s]\u001b[A\n",
      "4881581it [3:39:34, 15007.56it/s]\u001b[A\n",
      "4884729it [3:39:34, 15394.98it/s]\u001b[A\n",
      "4887807it [3:39:40, 1544.60it/s] \u001b[A\n",
      "4890930it [3:39:40, 2118.70it/s]\u001b[A\n",
      "4894056it [3:39:41, 2860.97it/s]\u001b[A\n",
      "4897173it [3:39:41, 3780.06it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef007a95901450d8cb53bce49969d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "4897173it [3:40:00, 3780.06it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "49it [3:44:14, 279.40s/it]\n",
      "4900000it [3:44:14, 36.78it/s]  \u001b[A\n",
      "4900330it [3:44:14, 38.46it/s]\u001b[A\n",
      "4903481it [3:44:14, 61.75it/s]\u001b[A\n",
      "4906608it [3:44:14, 94.67it/s]\u001b[A\n",
      "4909735it [3:44:14, 141.46it/s]\u001b[A\n",
      "4912862it [3:44:15, 207.86it/s]\u001b[A\n",
      "4915997it [3:44:15, 302.05it/s]\u001b[A\n",
      "4919130it [3:44:15, 434.79it/s]\u001b[A\n",
      "4922243it [3:44:15, 618.99it/s]\u001b[A\n",
      "4925396it [3:44:15, 878.05it/s]\u001b[A\n",
      "4928511it [3:44:15, 1226.10it/s]\u001b[A\n",
      "4931702it [3:44:16, 1705.39it/s]\u001b[A\n",
      "4934853it [3:44:16, 2314.58it/s]\u001b[A\n",
      "4938041it [3:44:16, 3109.11it/s]\u001b[A\n",
      "4941188it [3:44:16, 4067.07it/s]\u001b[A\n",
      "4944214it [3:44:17, 5085.15it/s]\u001b[A\n",
      "4947323it [3:44:17, 6291.32it/s]\u001b[A\n",
      "4950487it [3:44:20, 2295.96it/s]\u001b[A\n",
      "4953621it [3:44:20, 3071.10it/s]\u001b[A\n",
      "4956736it [3:44:21, 4032.69it/s]\u001b[A\n",
      "4959887it [3:44:21, 5185.66it/s]\u001b[A\n",
      "4963030it [3:44:21, 6466.80it/s]\u001b[A\n",
      "4966225it [3:44:21, 7818.07it/s]\u001b[A\n",
      "4969361it [3:44:22, 8938.12it/s]\u001b[A\n",
      "4972494it [3:44:22, 10122.35it/s]\u001b[A\n",
      "4975574it [3:44:22, 11200.03it/s]\u001b[A\n",
      "4978681it [3:44:22, 12198.47it/s]\u001b[A\n",
      "4981846it [3:44:22, 13059.67it/s]\u001b[A\n",
      "4984956it [3:44:23, 13690.93it/s]\u001b[A\n",
      "4988049it [3:44:27, 2208.11it/s] \u001b[A\n",
      "4991141it [3:44:27, 2969.38it/s]\u001b[A\n",
      "4994233it [3:44:27, 3921.39it/s]\u001b[A\n",
      "4997316it [3:44:27, 5008.73it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdd2a6f75494eccb12bc74350537f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "4997316it [3:44:40, 5008.73it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "50it [3:48:52, 279.05s/it]\n",
      "5000000it [3:48:52, 37.27it/s]  \u001b[A\n",
      "5000425it [3:48:52, 39.51it/s]\u001b[A\n",
      "5003565it [3:48:52, 63.48it/s]\u001b[A\n",
      "5006698it [3:48:52, 97.51it/s]\u001b[A\n",
      "5009861it [3:48:53, 146.27it/s]\u001b[A\n",
      "5013056it [3:48:53, 216.08it/s]\u001b[A\n",
      "5016214it [3:48:53, 313.23it/s]\u001b[A\n",
      "5019390it [3:48:58, 373.38it/s]\u001b[A\n",
      "5022532it [3:48:58, 531.22it/s]\u001b[A\n",
      "5025670it [3:48:58, 750.62it/s]\u001b[A\n",
      "5028791it [3:48:59, 1049.21it/s]\u001b[A\n",
      "5031932it [3:48:59, 1458.06it/s]\u001b[A\n",
      "5035054it [3:48:59, 1992.76it/s]\u001b[A\n",
      "5038194it [3:48:59, 2696.33it/s]\u001b[A\n",
      "5041280it [3:49:00, 3545.72it/s]\u001b[A\n",
      "5044388it [3:49:00, 4569.34it/s]\u001b[A\n",
      "5047500it [3:49:00, 5729.61it/s]\u001b[A\n",
      "5050585it [3:49:00, 6972.68it/s]\u001b[A\n",
      "5053686it [3:49:00, 8259.03it/s]\u001b[A\n",
      "5056736it [3:49:01, 9452.63it/s]\u001b[A\n",
      "5059815it [3:49:01, 10492.23it/s]\u001b[A\n",
      "5062862it [3:49:01, 11100.39it/s]\u001b[A\n",
      "5065943it [3:49:01, 11614.91it/s]\u001b[A\n",
      "5069146it [3:49:02, 12204.65it/s]\u001b[A\n",
      "5072199it [3:49:02, 12699.34it/s]\u001b[A\n",
      "5075267it [3:49:02, 13063.84it/s]\u001b[A\n",
      "5078362it [3:49:08, 1575.32it/s] \u001b[A\n",
      "5081354it [3:49:08, 2134.15it/s]\u001b[A\n",
      "5084432it [3:49:08, 2882.52it/s]\u001b[A\n",
      "5087502it [3:49:09, 3802.19it/s]\u001b[A\n",
      "5090605it [3:49:09, 4874.19it/s]\u001b[A\n",
      "5093639it [3:49:09, 6046.71it/s]\u001b[A\n",
      "5096697it [3:49:09, 7256.03it/s]\u001b[A\n",
      "5099842it [3:49:10, 8484.73it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550f8ec69b05425f866995f2e0188c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "5099842it [3:49:21, 8484.73it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "51it [3:53:45, 283.41s/it]\n",
      "5100000it [3:53:45, 26.61it/s]  \u001b[A\n",
      "5102963it [3:53:46, 41.86it/s]\u001b[A\n",
      "5105992it [3:53:46, 64.09it/s]\u001b[A\n",
      "5109072it [3:53:46, 96.25it/s]\u001b[A\n",
      "5112189it [3:53:46, 142.55it/s]\u001b[A\n",
      "5115341it [3:53:46, 208.98it/s]\u001b[A\n",
      "5118387it [3:53:47, 299.66it/s]\u001b[A\n",
      "5121441it [3:53:47, 427.61it/s]\u001b[A\n",
      "5124533it [3:53:47, 609.53it/s]\u001b[A\n",
      "5127663it [3:53:47, 864.69it/s]\u001b[A\n",
      "5130735it [3:53:50, 905.12it/s]\u001b[A\n",
      "5133810it [3:53:50, 1261.26it/s]\u001b[A\n",
      "5136906it [3:53:51, 1740.83it/s]\u001b[A\n",
      "5139991it [3:53:51, 2368.96it/s]\u001b[A\n",
      "5143043it [3:53:51, 3157.30it/s]\u001b[A\n",
      "5146196it [3:53:51, 4159.39it/s]\u001b[A\n",
      "5149287it [3:53:51, 5222.62it/s]\u001b[A\n",
      "5152412it [3:53:52, 6399.84it/s]\u001b[A\n",
      "5155516it [3:53:52, 7566.86it/s]\u001b[A\n",
      "5158644it [3:53:52, 8850.44it/s]\u001b[A\n",
      "5161765it [3:53:52, 9898.44it/s]\u001b[A\n",
      "5164893it [3:53:56, 2278.18it/s]\u001b[A\n",
      "5167880it [3:53:56, 3011.97it/s]\u001b[A\n",
      "5170949it [3:53:57, 3949.76it/s]\u001b[A\n",
      "5174062it [3:53:57, 5051.50it/s]\u001b[A\n",
      "5177141it [3:53:57, 6213.08it/s]\u001b[A\n",
      "5180188it [3:53:57, 7362.47it/s]\u001b[A\n",
      "5183289it [3:53:58, 8658.51it/s]\u001b[A\n",
      "5186384it [3:53:58, 9957.06it/s]\u001b[A\n",
      "5189470it [3:53:58, 11057.34it/s]\u001b[A\n",
      "5192515it [3:53:58, 11796.76it/s]\u001b[A\n",
      "5195556it [3:53:58, 12556.07it/s]\u001b[A\n",
      "5198600it [3:53:59, 12988.36it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f51cc14a0e94e4fa23c4a3e2123cc48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "5198600it [3:54:11, 12988.36it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "52it [3:58:34, 284.91s/it]\n",
      "5200000it [3:58:34, 30.95it/s]   \u001b[A\n",
      "5201696it [3:58:34, 39.69it/s]\u001b[A\n",
      "5204753it [3:58:34, 62.19it/s]\u001b[A\n",
      "5207774it [3:58:34, 93.82it/s]\u001b[A\n",
      "5210789it [3:58:35, 138.69it/s]\u001b[A\n",
      "5213798it [3:58:35, 202.21it/s]\u001b[A\n",
      "5216835it [3:58:35, 292.89it/s]\u001b[A\n",
      "5219908it [3:58:35, 421.90it/s]\u001b[A\n",
      "5223021it [3:58:35, 604.99it/s]\u001b[A\n",
      "5226096it [3:58:36, 855.64it/s]\u001b[A\n",
      "5229136it [3:58:36, 1192.18it/s]\u001b[A\n",
      "5232225it [3:58:36, 1650.10it/s]\u001b[A\n",
      "5235294it [3:58:36, 2244.18it/s]\u001b[A\n",
      "5238299it [3:58:37, 2980.86it/s]\u001b[A\n",
      "5241220it [3:58:37, 3884.54it/s]\u001b[A\n",
      "5244215it [3:58:42, 1376.01it/s]\u001b[A\n",
      "5247288it [3:58:42, 1904.09it/s]\u001b[A\n",
      "5250401it [3:58:43, 2602.84it/s]\u001b[A\n",
      "5253517it [3:58:43, 3476.80it/s]\u001b[A\n",
      "5256548it [3:58:43, 4509.52it/s]\u001b[A\n",
      "5259617it [3:58:43, 5730.70it/s]\u001b[A\n",
      "5262628it [3:58:43, 7018.99it/s]\u001b[A\n",
      "5265672it [3:58:44, 8367.02it/s]\u001b[A\n",
      "5268654it [3:58:44, 9677.08it/s]\u001b[A\n",
      "5271772it [3:58:44, 10815.59it/s]\u001b[A\n",
      "5274825it [3:58:44, 12075.24it/s]\u001b[A\n",
      "5277876it [3:58:44, 13199.26it/s]\u001b[A\n",
      "5280934it [3:58:45, 13836.10it/s]\u001b[A\n",
      "5283947it [3:58:45, 13751.41it/s]\u001b[A\n",
      "5287050it [3:58:45, 13901.16it/s]\u001b[A\n",
      "5290079it [3:58:45, 14512.59it/s]\u001b[A\n",
      "5293133it [3:58:45, 15040.41it/s]\u001b[A\n",
      "5296112it [3:58:46, 14789.05it/s]\u001b[A\n",
      "5299068it [3:58:46, 14829.86it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da46c68bdcd34a098c61204cfc37c9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "5299068it [3:59:02, 14829.86it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "53it [4:03:01, 279.71s/it]\n",
      "5300000it [4:03:01, 31.06it/s]   \u001b[A\n",
      "5302074it [4:03:02, 42.58it/s]\u001b[A\n",
      "5305110it [4:03:02, 66.66it/s]\u001b[A\n",
      "5308214it [4:03:02, 101.69it/s]\u001b[A\n",
      "5311288it [4:03:02, 150.94it/s]\u001b[A\n",
      "5314476it [4:03:02, 223.27it/s]\u001b[A\n",
      "5317568it [4:03:05, 296.45it/s]\u001b[A\n",
      "5320693it [4:03:05, 426.47it/s]\u001b[A\n",
      "5323826it [4:03:06, 608.86it/s]\u001b[A\n",
      "5326885it [4:03:06, 856.01it/s]\u001b[A\n",
      "5329994it [4:03:06, 1198.23it/s]\u001b[A\n",
      "5333096it [4:03:06, 1652.04it/s]\u001b[A\n",
      "5336212it [4:03:07, 2262.78it/s]\u001b[A\n",
      "5339312it [4:03:07, 3034.64it/s]\u001b[A\n",
      "5342354it [4:03:07, 3957.52it/s]\u001b[A\n",
      "5345445it [4:03:07, 5002.52it/s]\u001b[A\n",
      "5348616it [4:03:07, 6280.95it/s]\u001b[A\n",
      "5351799it [4:03:11, 2207.99it/s]\u001b[A\n",
      "5354935it [4:03:11, 2964.24it/s]\u001b[A\n",
      "5358061it [4:03:11, 3885.37it/s]\u001b[A\n",
      "5361174it [4:03:12, 4968.45it/s]\u001b[A\n",
      "5364237it [4:03:12, 6059.37it/s]\u001b[A\n",
      "5367398it [4:03:12, 7327.12it/s]\u001b[A\n",
      "5370531it [4:03:12, 8638.87it/s]\u001b[A\n",
      "5373652it [4:03:13, 9847.89it/s]\u001b[A\n",
      "5376786it [4:03:13, 10950.20it/s]\u001b[A\n",
      "5379935it [4:03:13, 11841.98it/s]\u001b[A\n",
      "5383059it [4:03:13, 12503.89it/s]\u001b[A\n",
      "5386154it [4:03:13, 12926.89it/s]\u001b[A\n",
      "5389258it [4:03:14, 13099.42it/s]\u001b[A\n",
      "5392371it [4:03:18, 2091.29it/s] \u001b[A\n",
      "5395438it [4:03:18, 2783.86it/s]\u001b[A\n",
      "5398556it [4:03:18, 3662.70it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8e13dba37f45c791d638ec4cf297a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "5398556it [4:03:32, 3662.70it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "54it [4:07:38, 278.85s/it]\n",
      "5400000it [4:07:38, 33.21it/s]  \u001b[A\n",
      "5401643it [4:07:38, 42.13it/s]\u001b[A\n",
      "5404734it [4:07:39, 66.10it/s]\u001b[A\n",
      "5407856it [4:07:39, 100.56it/s]\u001b[A\n",
      "5410973it [4:07:39, 149.41it/s]\u001b[A\n",
      "5414107it [4:07:39, 218.89it/s]\u001b[A\n",
      "5417284it [4:07:39, 318.54it/s]\u001b[A\n",
      "5420390it [4:07:45, 373.74it/s]\u001b[A\n",
      "5423500it [4:07:45, 532.17it/s]\u001b[A\n",
      "5426602it [4:07:45, 751.71it/s]\u001b[A\n",
      "5429760it [4:07:45, 1056.84it/s]\u001b[A\n",
      "5432887it [4:07:45, 1468.06it/s]\u001b[A\n",
      "5436042it [4:07:46, 2022.31it/s]\u001b[A\n",
      "5439237it [4:07:46, 2741.00it/s]\u001b[A\n",
      "5442374it [4:07:46, 3632.15it/s]\u001b[A\n",
      "5445521it [4:07:46, 4711.03it/s]\u001b[A\n",
      "5448687it [4:07:46, 5953.41it/s]\u001b[A\n",
      "5451831it [4:07:47, 7299.08it/s]\u001b[A\n",
      "5454971it [4:07:47, 8632.62it/s]\u001b[A\n",
      "5458086it [4:07:47, 9847.51it/s]\u001b[A\n",
      "5461191it [4:07:47, 10930.41it/s]\u001b[A\n",
      "5464314it [4:07:48, 11789.25it/s]\u001b[A\n",
      "5467435it [4:07:48, 12454.35it/s]\u001b[A\n",
      "5470579it [4:07:48, 13062.17it/s]\u001b[A\n",
      "5473756it [4:07:48, 13527.54it/s]\u001b[A\n",
      "5476884it [4:07:55, 1516.07it/s] \u001b[A\n",
      "5480010it [4:07:55, 2070.21it/s]\u001b[A\n",
      "5483080it [4:07:55, 2770.84it/s]\u001b[A\n",
      "5486222it [4:07:55, 3663.93it/s]\u001b[A\n",
      "5489339it [4:07:55, 4726.51it/s]\u001b[A\n",
      "5492523it [4:07:56, 5897.60it/s]\u001b[A\n",
      "5495688it [4:07:56, 7135.05it/s]\u001b[A\n",
      "5498859it [4:07:56, 8353.38it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d405f544ea6b44bc8b752734e9b55fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "5498859it [4:08:15, 8353.38it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "55it [4:12:26, 281.55s/it]\n",
      "5500000it [4:12:26, 31.39it/s]  \u001b[A\n",
      "5501999it [4:12:26, 41.89it/s]\u001b[A\n",
      "5505183it [4:12:26, 65.76it/s]\u001b[A\n",
      "5508296it [4:12:27, 98.98it/s]\u001b[A\n",
      "5511389it [4:12:27, 145.89it/s]\u001b[A\n",
      "5514502it [4:12:27, 212.76it/s]\u001b[A\n",
      "5517654it [4:12:27, 308.65it/s]\u001b[A\n",
      "5520789it [4:12:27, 442.94it/s]\u001b[A\n",
      "5523862it [4:12:28, 627.19it/s]\u001b[A\n",
      "5526984it [4:12:28, 886.87it/s]\u001b[A\n",
      "5530099it [4:12:28, 1236.95it/s]\u001b[A\n",
      "5533183it [4:12:28, 1703.76it/s]\u001b[A\n",
      "5536321it [4:12:31, 1391.40it/s]\u001b[A\n",
      "5539398it [4:12:32, 1898.97it/s]\u001b[A\n",
      "5542523it [4:12:32, 2578.48it/s]\u001b[A\n",
      "5545691it [4:12:32, 3442.61it/s]\u001b[A\n",
      "5548901it [4:12:32, 4483.46it/s]\u001b[A\n",
      "5552107it [4:12:33, 5659.87it/s]\u001b[A\n",
      "5555262it [4:12:33, 6860.17it/s]\u001b[A\n",
      "5558384it [4:12:33, 8041.45it/s]\u001b[A\n",
      "5561456it [4:12:33, 9092.21it/s]\u001b[A\n",
      "5564560it [4:12:33, 10091.44it/s]\u001b[A\n",
      "5567672it [4:12:34, 11039.24it/s]\u001b[A\n",
      "5570825it [4:12:38, 2273.99it/s] \u001b[A\n",
      "5573935it [4:12:38, 3031.91it/s]\u001b[A\n",
      "5576979it [4:12:38, 3937.17it/s]\u001b[A\n",
      "5580033it [4:12:38, 5002.38it/s]\u001b[A\n",
      "5583117it [4:12:39, 6175.15it/s]\u001b[A\n",
      "5586177it [4:12:39, 7345.05it/s]\u001b[A\n",
      "5589174it [4:12:39, 8465.47it/s]\u001b[A\n",
      "5592219it [4:12:39, 9581.98it/s]\u001b[A\n",
      "5595291it [4:12:39, 10559.36it/s]\u001b[A\n",
      "5598394it [4:12:40, 11305.92it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4fd5c7f06249a3be22c31c39c6cd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "5598394it [4:12:58, 11305.92it/s]\u001b[A/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "56it [4:17:06, 281.06s/it]\n",
      "5600000it [4:17:06, 32.86it/s]   \u001b[A\n",
      "5601536it [4:17:06, 41.03it/s]\u001b[A\n",
      "5604672it [4:17:06, 64.87it/s]\u001b[A\n",
      "5607817it [4:17:07, 98.90it/s]\u001b[A\n",
      "5610987it [4:17:07, 147.63it/s]\u001b[A\n",
      "5614167it [4:17:07, 216.84it/s]\u001b[A\n",
      "5617294it [4:17:07, 312.95it/s]\u001b[A\n",
      "5620332it [4:17:07, 444.49it/s]\u001b[A\n",
      "5623466it [4:17:08, 634.06it/s]\u001b[A\n",
      "5626551it [4:17:08, 892.16it/s]\u001b[A\n",
      "5629606it [4:17:08, 1241.40it/s]\u001b[A\n",
      "5632663it [4:17:08, 1710.34it/s]\u001b[A\n",
      "5635678it [4:17:08, 2322.33it/s]\u001b[A\n",
      "5638631it [4:17:09, 3072.09it/s]\u001b[A\n",
      "5641614it [4:17:09, 3987.96it/s]\u001b[A\n",
      "5644597it [4:17:14, 1405.06it/s]\u001b[A\n",
      "5647648it [4:17:14, 1941.70it/s]\u001b[A\n",
      "5650749it [4:17:15, 2653.03it/s]\u001b[A\n",
      "5653779it [4:17:15, 3494.14it/s]\u001b[A\n",
      "5656839it [4:17:15, 4534.22it/s]\u001b[A\n",
      "5659853it [4:17:15, 5645.86it/s]\u001b[A\n",
      "5662869it [4:17:16, 6869.16it/s]\u001b[A\n",
      "5665915it [4:17:16, 8074.03it/s]\u001b[A\n",
      "5668913it [4:17:16, 9382.61it/s]\u001b[A\n",
      "5671987it [4:17:16, 10472.96it/s]\u001b[A\n",
      "5675068it [4:17:16, 11598.65it/s]\u001b[A\n",
      "5678196it [4:17:17, 12659.50it/s]\u001b[A\n",
      "5681304it [4:17:17, 12981.68it/s]\u001b[A\n",
      "5684366it [4:17:17, 13352.59it/s]\u001b[A\n",
      "5687424it [4:17:17, 13874.02it/s]\u001b[A\n",
      "5690531it [4:17:17, 14337.27it/s]\u001b[A\n",
      "5693516it [4:17:18, 14606.43it/s]\u001b[A\n",
      "5696591it [4:17:18, 14619.28it/s]\u001b[A\n",
      "5699686it [4:17:18, 14556.87it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c351d927a414e65961fa4db804146bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100000\n",
      "  Batch size = 128\n",
      "\n",
      "5699686it [4:17:34, 14556.87it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "n=100000\n",
    "target_col = \"clean_tweet\"\n",
    "for idx, chunk in tqdm(enumerate(split_list(tweet_cursor, n))):\n",
    "        df = pd.DataFrame(chunk)\n",
    "        if not len(df):\n",
    "            break\n",
    "        pred_df = df[[target_col]].dropna()\n",
    "        pred_data = df.dropna(subset=[target_col])\n",
    "        pred_dataset = Dataset.from_pandas(pred_df)\n",
    "        pred_dataset = pred_dataset.rename_column(target_col, \"text\")\n",
    "        tokenized_datasets = pred_dataset.map(tokenize_function, batched=True)\n",
    "        predictions_logits = trainer.predict(tokenized_datasets)\n",
    "        preds = np.argmax(predictions_logits.predictions, axis = 1)\n",
    "        save_df = pred_data[[\"_id\", \"clean_tweet\"]]\n",
    "        save_df[\"condemnation_prediction\"] = preds\n",
    "        save_df[\"condemnation_logit_0\"] = predictions_logits.predictions[:, 0]\n",
    "        save_df[\"condemnation_logit_1\"] = predictions_logits.predictions[:, 1]\n",
    "        del tokenized_datasets\n",
    "        del pred_dataset\n",
    "        for idx, row in tqdm(save_df.iterrows()):\n",
    "            update_tweet_in_db(row.to_dict())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40f9963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pred_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694777e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c364703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "548a14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_tweet_in_db(row.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf50cc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;TWEET&gt;: Olivia Munn is promoting 'Predator' e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;TWEET&gt;: Continua la polmica con la pelcula ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;TWEET&gt;: Olivia Munn says 'Predator' cast shun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;TWEET&gt;: It would appear that society allows m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;TWEET&gt;: 'The Predator': Shane Black Apologize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>&lt;TWEET&gt;: La compaa lleg a esta conclusin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>&lt;TWEET&gt;: .@20thcenturyfox quit una escena con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>&lt;TWEET&gt;: Just hours before the premiere of \"Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>&lt;TWEET&gt;: .@20thcenturyfox quit una escena con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>&lt;TWEET&gt;: Horas antes del estreno de \"The Preda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_tweet\n",
       "0   <TWEET>: Olivia Munn is promoting 'Predator' e...\n",
       "1   <TWEET>: Continua la polmica con la pelcula ...\n",
       "2   <TWEET>: Olivia Munn says 'Predator' cast shun...\n",
       "3   <TWEET>: It would appear that society allows m...\n",
       "4   <TWEET>: 'The Predator': Shane Black Apologize...\n",
       "..                                                ...\n",
       "95  <TWEET>: La compaa lleg a esta conclusin, ...\n",
       "96  <TWEET>: .@20thcenturyfox quit una escena con...\n",
       "97  <TWEET>: Just hours before the premiere of \"Th...\n",
       "98  <TWEET>: .@20thcenturyfox quit una escena con...\n",
       "99  <TWEET>: Horas antes del estreno de \"The Preda...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd280831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60cd581c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67638907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a481daa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', '__index_level_0__'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05eb3dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a612ec9cc7f46cbac794272471cd253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2250f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c6c163b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file models/hf/hf_fold_{}_model./config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"models/hf/hf_fold_{}_model./\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file models/hf/hf_fold_{}_model./pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at models/hf/hf_fold_{}_model./.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2aff1c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100\n",
      "  Batch size = 128\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd922e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/geev/Research/Transgression/tenv/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79751a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>condemnation_prediction</th>\n",
       "      <th>condemnation_logit_0</th>\n",
       "      <th>condemnation_logit_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6383e2adfa2b796ff3841c9d</td>\n",
       "      <td>&lt;TWEET&gt;: Olivia Munn is promoting 'Predator' e...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.078831</td>\n",
       "      <td>1.067021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6383e2adfa2b796ff3841c9e</td>\n",
       "      <td>&lt;TWEET&gt;: Continua la polmica con la pelcula ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857920</td>\n",
       "      <td>-0.953911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6383e2adfa2b796ff3841c9f</td>\n",
       "      <td>&lt;TWEET&gt;: Olivia Munn says 'Predator' cast shun...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.124301</td>\n",
       "      <td>-0.101442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6383e2adfa2b796ff3841ca0</td>\n",
       "      <td>&lt;TWEET&gt;: It would appear that society allows m...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.949958</td>\n",
       "      <td>0.924150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6383e2adfa2b796ff3841ca1</td>\n",
       "      <td>&lt;TWEET&gt;: 'The Predator': Shane Black Apologize...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.188017</td>\n",
       "      <td>-0.208660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6383e2adfa2b796ff3841cfc</td>\n",
       "      <td>&lt;TWEET&gt;: La compaa lleg a esta conclusin, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.618347</td>\n",
       "      <td>-1.706561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6383e2adfa2b796ff3841cfd</td>\n",
       "      <td>&lt;TWEET&gt;: .@20thcenturyfox quit una escena con...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.414179</td>\n",
       "      <td>-1.495095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6383e2adfa2b796ff3841cfe</td>\n",
       "      <td>&lt;TWEET&gt;: Just hours before the premiere of \"Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418434</td>\n",
       "      <td>-0.595623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6383e2adfa2b796ff3841cff</td>\n",
       "      <td>&lt;TWEET&gt;: .@20thcenturyfox quit una escena con...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.414179</td>\n",
       "      <td>-1.495095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6383e2adfa2b796ff3841d00</td>\n",
       "      <td>&lt;TWEET&gt;: Horas antes del estreno de \"The Preda...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.787196</td>\n",
       "      <td>-0.831630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         _id  \\\n",
       "0   6383e2adfa2b796ff3841c9d   \n",
       "1   6383e2adfa2b796ff3841c9e   \n",
       "2   6383e2adfa2b796ff3841c9f   \n",
       "3   6383e2adfa2b796ff3841ca0   \n",
       "4   6383e2adfa2b796ff3841ca1   \n",
       "..                       ...   \n",
       "95  6383e2adfa2b796ff3841cfc   \n",
       "96  6383e2adfa2b796ff3841cfd   \n",
       "97  6383e2adfa2b796ff3841cfe   \n",
       "98  6383e2adfa2b796ff3841cff   \n",
       "99  6383e2adfa2b796ff3841d00   \n",
       "\n",
       "                                          clean_tweet  \\\n",
       "0   <TWEET>: Olivia Munn is promoting 'Predator' e...   \n",
       "1   <TWEET>: Continua la polmica con la pelcula ...   \n",
       "2   <TWEET>: Olivia Munn says 'Predator' cast shun...   \n",
       "3   <TWEET>: It would appear that society allows m...   \n",
       "4   <TWEET>: 'The Predator': Shane Black Apologize...   \n",
       "..                                                ...   \n",
       "95  <TWEET>: La compaa lleg a esta conclusin, ...   \n",
       "96  <TWEET>: .@20thcenturyfox quit una escena con...   \n",
       "97  <TWEET>: Just hours before the premiere of \"Th...   \n",
       "98  <TWEET>: .@20thcenturyfox quit una escena con...   \n",
       "99  <TWEET>: Horas antes del estreno de \"The Preda...   \n",
       "\n",
       "    condemnation_prediction  condemnation_logit_0  condemnation_logit_1  \n",
       "0                         1             -1.078831              1.067021  \n",
       "1                         0              0.857920             -0.953911  \n",
       "2                         1             -0.124301             -0.101442  \n",
       "3                         1             -0.949958              0.924150  \n",
       "4                         0              0.188017             -0.208660  \n",
       "..                      ...                   ...                   ...  \n",
       "95                        0              1.618347             -1.706561  \n",
       "96                        0              1.414179             -1.495095  \n",
       "97                        0              0.418434             -0.595623  \n",
       "98                        0              1.414179             -1.495095  \n",
       "99                        0              0.787196             -0.831630  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c27d7e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 1374.38it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff504557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<TWEET>: Teen in Steven Wilder Striegel's 2010 sex abuse case comes forward to 'reclaim my identity'\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c65a481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/fold_1_model.p\"\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "# model.to(\"cuda:0\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41158537",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweet_cursor:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18fc2672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<TWEET>: Teen in Steven Wilder Striegel's 2010 sex abuse case comes forward to 'reclaim my identity'\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet[\"clean_tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d224877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bef62d96",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-39b073f64442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clean_tweet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/transformers/pipelines/text_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_all_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0msuch\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mper\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;31m# This pipeline is odd, and return a list when single item is run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/transformers/pipelines/text_classification.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_to_apply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1552\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m         )\n\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m         )\n\u001b[1;32m    996\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Transgression/tenv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "pipe(tweet[\"clean_tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fee821aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-22fdfe34e954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clean_tweet_masked\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for tweet in tqdm(tweet_cursor):\n",
    "#     print(tweet)\n",
    "    if \"clean_tweet_masked\" not in tweet:\n",
    "        continue\n",
    "    else:\n",
    "        pipe(tweet[\"clean_tweet_masked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f63481dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<TWEET>: RT @rorrobracho: Osea, segn este diario \"se nos cay el dolo\" porque <TARGET 1> sali del closet y no porque le acusaron de acoso a un'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet[\"clean_tweet_masked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23aaf72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet[\"favoritesCount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6b8595c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet[\"retweetCount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12fe3433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spacey': {'valid': True,\n",
       "  'public_date': datetime.datetime(2017, 10, 29, 0, 0)}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet[\"time_check\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff63d123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 10, 31, 17, 2, 35)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet[\"postedTime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e45bdcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'body', 'postedTime', 'retweetCount', 'favoritesCount', 'quoted_status_id', 'quoted_status_user_id', 'quoted_status_body', 'quoted_status_user_postedTime', 'gnip_url_title', 'gnip_url_description', 'is_RT', 'RT_body', 'RT_user_id', 'RT_id', 'tweet_id', 'user_id', 'RT_target_mentions', 'body_target_mentions', 'body_target_mentions_validated', 'body_target_mentions_validated_true', 'gnip_url_title_mentions', 'lang_pred', 'lang_pred_prob', 'quoted_status_target_mentions', 'clean_targets_n', 'clean_tweet', 'clean_tweet_masked', 'mask_map', 'modified_quote_tweet', 'time_check'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e27815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.005583  ,  0.9191936 ],\n",
       "       [-0.9339803 ,  0.862211  ],\n",
       "       [-1.4016373 ,  1.344614  ],\n",
       "       ...,\n",
       "       [-0.13647401,  0.00870189],\n",
       "       [-1.9797113 ,  1.8827175 ],\n",
       "       [-0.26315764,  0.21105824]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('./condemnation_predictions.p', 'rb')\n",
    "preds = pickle.load(file)\n",
    "file.close()\n",
    "preds.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e13ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../../data/5_mil_7days_metoo.p', 'rb')\n",
    "pred_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78f2cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet_masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;TWEET&gt;:  I do love you. . I love you, &lt;TARG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;TWEET&gt;: &lt;TARGET 1&gt; apologizes for 'aggressive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;TWEET&gt;: No one should have to endure this kin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;TWEET&gt;: \"New &lt;TARGET 1&gt; sexual assault accusa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;TWEET&gt;: Yes this. &lt;TARGET 1&gt;, this clown, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683897</th>\n",
       "      <td>&lt;TWEET&gt;: On the one year anniversary of the Ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683898</th>\n",
       "      <td>&lt;TWEET&gt;: &lt;TARGET 1&gt;'s photobombing. The ladies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683900</th>\n",
       "      <td>&lt;TWEET&gt;: But but but dude you're a rapist HOW ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683901</th>\n",
       "      <td>&lt;TWEET&gt;: Lisa Bloom, Lawyer Advising &lt;TARGET 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683902</th>\n",
       "      <td>&lt;TWEET&gt;: Don Jr. trolls silent Hillary over &lt;T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2797605 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        clean_tweet_masked\n",
       "0        <TWEET>:  I do love you. . I love you, <TARG...\n",
       "4        <TWEET>: <TARGET 1> apologizes for 'aggressive...\n",
       "5        <TWEET>: No one should have to endure this kin...\n",
       "6        <TWEET>: \"New <TARGET 1> sexual assault accusa...\n",
       "8        <TWEET>: Yes this. <TARGET 1>, this clown, the...\n",
       "...                                                    ...\n",
       "4683897  <TWEET>: On the one year anniversary of the Ac...\n",
       "4683898  <TWEET>: <TARGET 1>'s photobombing. The ladies...\n",
       "4683900  <TWEET>: But but but dude you're a rapist HOW ...\n",
       "4683901  <TWEET>: Lisa Bloom, Lawyer Advising <TARGET 1...\n",
       "4683902  <TWEET>: Don Jr. trolls silent Hillary over <T...\n",
       "\n",
       "[2797605 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pred_data[[\"clean_tweet_masked\"]].dropna()\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550241fb",
   "metadata": {},
   "source": [
    "# Trying Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25e0d6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"./models/fold_1_model.p\"\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "# model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c1ec042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "282a4d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a45a54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1026, 1056, 28394, 2102, 1028, 1024, 19387, 1030, 20996, 18933, 10024, 9905, 1024, 9808, 5243, 1010, 7367, 12734, 28517, 22939, 9488, 1000, 7367, 16839, 6187, 7677, 3449, 10282, 2080, 1000, 18499, 4226, 1026, 4539, 1015, 1028, 16183, 3695, 3972, 9346, 1061, 2053, 18499, 4226, 3393, 9353, 10383, 4948, 2139, 9353, 19137, 1037, 4895, 1529, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(tweet[\"clean_tweet_masked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b686e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6a09b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f004f483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 0.9484457969665527},\n",
       "  {'label': 'LABEL_1', 'score': 0.051554203033447266}]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(tweet[\"clean_tweet_masked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b45007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af93ae1725f4fc78f655af2ddf34f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Value\n",
    "pred_dataset = Dataset.from_pandas(pred_df)\n",
    "pred_dataset = pred_dataset.rename_column(\"clean_tweet_masked\", \"text\")\n",
    "new_features = pred_dataset.features.copy()\n",
    "# new_features[\"text\"] = Value('string')\n",
    "pred_dataset = pred_dataset.cast(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8733d5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de5a481175d431190aabdd2c85b7152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2798 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = pred_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a19fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9189e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"exp/bart/results\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    eval_accumulation_steps=1,\n",
    ")\n",
    "training_args = TrainingArguments(\"test-trainer\")\n",
    "training_args.eval_accumulation_steps=1 #pushes predictions out of GPU to mitigate GPU out of memory\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f92fae5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 5\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5fc8348f29e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2106\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m         output = eval_loop(\n\u001b[0;32m-> 2108\u001b[0;31m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2109\u001b[0m         )\n\u001b[1;32m   2110\u001b[0m         \u001b[0mtotal_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_batch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2195\u001b[0m         \u001b[0mobserved_num_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m         \u001b[0;31m# Main evaluation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2197\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2198\u001b[0m             \u001b[0;31m# Update the observed num examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m             \u001b[0mobserved_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54886de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./condemnation_predictions', 'wb') as f:\n",
    "    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a33fb",
   "metadata": {},
   "source": [
    "# Trying Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "796b48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.base import *\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3c9673d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f22355",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55fa012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer,  device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a4f2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df.dropna(subset=[\"clean_tweet_masked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20db50db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet_masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;TWEET&gt;:  I do love you. . I love you, &lt;TARG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;TWEET&gt;: &lt;TARGET 1&gt; apologizes for 'aggressive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;TWEET&gt;: No one should have to endure this kin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;TWEET&gt;: \"New &lt;TARGET 1&gt; sexual assault accusa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;TWEET&gt;: Yes this. &lt;TARGET 1&gt;, this clown, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683897</th>\n",
       "      <td>&lt;TWEET&gt;: On the one year anniversary of the Ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683898</th>\n",
       "      <td>&lt;TWEET&gt;: &lt;TARGET 1&gt;'s photobombing. The ladies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683900</th>\n",
       "      <td>&lt;TWEET&gt;: But but but dude you're a rapist HOW ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683901</th>\n",
       "      <td>&lt;TWEET&gt;: Lisa Bloom, Lawyer Advising &lt;TARGET 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683902</th>\n",
       "      <td>&lt;TWEET&gt;: Don Jr. trolls silent Hillary over &lt;T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2797605 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        clean_tweet_masked\n",
       "0        <TWEET>:  I do love you. . I love you, <TARG...\n",
       "4        <TWEET>: <TARGET 1> apologizes for 'aggressive...\n",
       "5        <TWEET>: No one should have to endure this kin...\n",
       "6        <TWEET>: \"New <TARGET 1> sexual assault accusa...\n",
       "8        <TWEET>: Yes this. <TARGET 1>, this clown, the...\n",
       "...                                                    ...\n",
       "4683897  <TWEET>: On the one year anniversary of the Ac...\n",
       "4683898  <TWEET>: <TARGET 1>'s photobombing. The ladies...\n",
       "4683900  <TWEET>: But but but dude you're a rapist HOW ...\n",
       "4683901  <TWEET>: Lisa Bloom, Lawyer Advising <TARGET 1...\n",
       "4683902  <TWEET>: Don Jr. trolls silent Hillary over <T...\n",
       "\n",
       "[2797605 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1aef2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e90b49e2ee41b7a29d794aa6846b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Value\n",
    "pred_dataset = Dataset.from_pandas(pred_df)\n",
    "pred_dataset = pred_dataset.rename_column(\"clean_tweet_masked\", \"text\")\n",
    "new_features = pred_dataset.features.copy()\n",
    "# new_features[\"text\"] = Value('string')\n",
    "pred_dataset = pred_dataset.cast(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9421a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred_dataset[\"text\"][:10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "for out in tqdm(pipe(pred_dataset[\"text\"]), total=len(pred_dataset)):\n",
    "    print(out)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba309f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dbadfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunker(pred_dataset[\"text\"],):\n",
    "    print(type(chunk))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd855a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53ac34fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d149c4fb436b4112a9848f7fe0b8c0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c9b2cef3ca89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     torch.cuda.empty_cache()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/pipelines/text_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_all_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0msuch\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mper\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_and_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, inputs, return_tensors)\u001b[0m\n\u001b[1;32m    780\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m         )\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         )\n\u001b[1;32m   1003\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         )\n\u001b[1;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         )\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "i = 1\n",
    "for chunk in tqdm(chunker(pred_dataset[\"text\"],1)):\n",
    "    labels.extend(pipe(chunk))\n",
    "#     torch.cuda.empty_cache()\n",
    "    i+=1\n",
    "    if i%100:\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27ef4cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.8726699948310852},\n",
       " {'label': 'LABEL_1', 'score': 0.8576847314834595},\n",
       " {'label': 'LABEL_1', 'score': 0.9397012591362},\n",
       " {'label': 'LABEL_0', 'score': 0.9323407411575317},\n",
       " {'label': 'LABEL_1', 'score': 0.966101348400116},\n",
       " {'label': 'LABEL_1', 'score': 0.5745621919631958},\n",
       " {'label': 'LABEL_1', 'score': 0.5133087038993835},\n",
       " {'label': 'LABEL_1', 'score': 0.5648785829544067},\n",
       " {'label': 'LABEL_1', 'score': 0.9608886241912842},\n",
       " {'label': 'LABEL_1', 'score': 0.9589126110076904},\n",
       " {'label': 'LABEL_1', 'score': 0.9688040018081665},\n",
       " {'label': 'LABEL_1', 'score': 0.96010822057724},\n",
       " {'label': 'LABEL_0', 'score': 0.789070725440979},\n",
       " {'label': 'LABEL_1', 'score': 0.8477528691291809},\n",
       " {'label': 'LABEL_0', 'score': 0.5989922285079956},\n",
       " {'label': 'LABEL_1', 'score': 0.5745621919631958},\n",
       " {'label': 'LABEL_1', 'score': 0.971645712852478},\n",
       " {'label': 'LABEL_1', 'score': 0.9548541903495789},\n",
       " {'label': 'LABEL_1', 'score': 0.9701395034790039},\n",
       " {'label': 'LABEL_0', 'score': 0.9643896222114563},\n",
       " {'label': 'LABEL_1', 'score': 0.869938850402832},\n",
       " {'label': 'LABEL_1', 'score': 0.9240084886550903},\n",
       " {'label': 'LABEL_1', 'score': 0.8830118179321289},\n",
       " {'label': 'LABEL_1', 'score': 0.9309524297714233},\n",
       " {'label': 'LABEL_1', 'score': 0.9276540875434875},\n",
       " {'label': 'LABEL_1', 'score': 0.8145416378974915},\n",
       " {'label': 'LABEL_1', 'score': 0.9509024620056152},\n",
       " {'label': 'LABEL_1', 'score': 0.7421102523803711},\n",
       " {'label': 'LABEL_1', 'score': 0.9597100019454956},\n",
       " {'label': 'LABEL_1', 'score': 0.9589502811431885},\n",
       " {'label': 'LABEL_1', 'score': 0.9705483913421631},\n",
       " {'label': 'LABEL_1', 'score': 0.9537642002105713}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(pred_dataset[\"text\"][:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69645896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<TWEET>:  I do love you. . I love you, <TARGET 1>. .',\n",
       " \"<TWEET>: <TARGET 1> apologizes for 'aggressive and crude' behavior toward women URL bench #Lifestyle\",\n",
       " '<TWEET>: No one should have to endure this kind of torture... Incredibly brave of @AnnabellSciorra to share her story of <TARGET 1>s abuse URL\\n\\n<QUOTED TWEET>: Sciorra was still living in fear of <TARGET 1>, she said, and slept with a baseball bat by her bed. URL',\n",
       " '<TWEET>: \"New <TARGET 1> sexual assault accusations emerge\" via FOX NEWS URL URL',\n",
       " '<TWEET>: Yes this. <TARGET 1>, this clown, the entire frat house at Fox. How could we expect first female presidential candidate to get a fair shake?',\n",
       " '<TWEET>: Over 300 Claims Against <TARGET 1>! URL',\n",
       " '<TWEET>: Over 300 Claims Against <TARGET 1>! URL URL',\n",
       " '<TWEET>: Rose McGowan accuses <TARGET 1> of Rape - News Today - Breaking News URL via @YouTube',\n",
       " '<TWEET>: <TARGET 1>, Hefner and the Poor Excuse that Explains a Lot via @NYTimes URL',\n",
       " '<TWEET>: Ellen sexual harassing did she learn that from <TARGET 1>',\n",
       " \"<TWEET>: If you're a Law &amp; Order: Criminal Intent fan, this just got personal #<TARGET 2><TARGET 2> #HimThough #MeToo\\n\\n<URL TITLE>: Weighing the Costs of Speaking Out About <TARGET 2>\\n<URL DESCRIPTION>: Annabella Sciorra, Daryl Hannah, and other women explain their struggles with going public.\",\n",
       " \"<TWEET>: <TARGET 1> admits 'aggressive and crude' behavior toward women URL\",\n",
       " '<TWEET>: <TARGET 1> accused of sexual assault by two more women URL URL',\n",
       " \"<TWEET>: George Clooney, Matt Damon Speak Out Against <TARGET 1> On 'GMA' URL\",\n",
       " '<TWEET>: Lisa Bloom investigated <TARGET 1> victims Rose McGowan, Ambra URL',\n",
       " '<TWEET>: Over 300 Claims Against <TARGET 1>! URL',\n",
       " '<TWEET>: More Women Accuse <TARGET 1> of Harassment... URL',\n",
       " '<TWEET>: Another shitty thing is a bumper ad in between the fake trailers that says \"Brought to you by your friends at The <TARGET 1> Company!\" Blegh.',\n",
       " '<TWEET>: More Women Accuse <TARGET 1> of Harassment... URL URL',\n",
       " '<TWEET>: Final: Burlington-Edison beats <TARGET 1> by 34 points. View box score:URL',\n",
       " '<TWEET>: Chazz Palminteri and <TARGET 1> brought that together like a puzzle at the end. Directing was Oscar-worthy.',\n",
       " \"<TWEET>: <TARGET 1> isn't the fucking president! How did this comparison actually occupy your brain?\",\n",
       " '<TWEET>: Bannon Declares War On \"Phony Culture Brokers\" In Hollywood Who \"Turned A Blind Eye\" To <TARGET 1> | Zero Hedge URL',\n",
       " '<TWEET>: Erin Burnett: So Trump Wants Us to Believe Clinton, <TARGET 1> Accusers, But Not His? URL via @mediaite',\n",
       " '<TWEET>: Men like <TARGET 1> are in every industry &amp; profession, and wield incredible power. I hope weve reached a turning point, but sadly doubt it.',\n",
       " '<TWEET>: Remember When he said, \"I know <TARGET 1> A Long Time\", I Said Then No Surprise There. Rich &amp; Priveledge, And Ur Famous U Can Do Anything\". URL',\n",
       " \"<TWEET>: But, you're defending @CNN trying to distract from <TARGET 1> and the rest of Hollywood. O'Reilly had his moment of shame.\",\n",
       " '<TWEET>: A piece I wrote in 2014 about gender, the New Republic &amp; <TARGET 1>: URL',\n",
       " '<TWEET>: I find it funny that you and other celebs bitch &amp; moan about elected officials, but you and many others stayed quiet on <TARGET 1>.',\n",
       " '<TWEET>: Pervert politicians: why the <TARGET 1> effect could hit Westminster hardest URL',\n",
       " '<TWEET>: Is it bad that I derive satisfaction from imagining <TARGET 1>, Trump and other sexual predators stuck in prison cells with much larger men? URL',\n",
       " '<TWEET>: Cielo (<TARGET 1>): Esta noche full time bebe\\n\\n<URL TITLE>: Escort <TARGET 1> - divinas<TARGET 1>.com - Escorts ( call girls ) in <TARGET 1>, Argentina\\n<URL DESCRIPTION>: Divinas <TARGET 1> el Portal interactivo de servicios escorts y de acompaantes mas completo de Argentina | Welcome to <TARGET 1>, Argentina the best escorts are here! Divinas <TARGET 1> is a wide directory of Independent Escorts (call girls) in <TARGET 1>, Argentina. Containing one of the largest selection of ladies escorts Argentinaan and foreign in this city.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dataset[\"text\"][:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c467e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02515e328fe4662a76ba1dd1e7a78b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 7.80 GiB total capacity; 597.34 MiB already allocated; 9.56 MiB free; 660.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-83cc7d828b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/pipelines/text_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_all_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0msuch\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mper\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_and_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, inputs, return_tensors)\u001b[0m\n\u001b[1;32m    780\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m         )\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         )\n\u001b[1;32m   1003\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         )\n\u001b[1;32m    513\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 7.80 GiB total capacity; 597.34 MiB already allocated; 9.56 MiB free; 660.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a1a9e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3be4a76ff5f45e59e0e7515a3a139ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e84ed134014cfd8e80be38dad2413b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /home/geev/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e4228c82ac4c1691f1bbe81d0b5b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb downloaded and prepared to /home/geev/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"imdb\", name=\"plain_text\", split=\"unsupervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a32aa82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<TWEET>:  I do love you. . I love you, <TARGET 1>. .',\n",
       " \"<TWEET>: <TARGET 1> apologizes for 'aggressive and crude' behavior toward women URL bench #Lifestyle\",\n",
       " '<TWEET>: No one should have to endure this kind of torture... Incredibly brave of @AnnabellSciorra to share her story of <TARGET 1>s abuse URL\\n\\n<QUOTED TWEET>: Sciorra was still living in fear of <TARGET 1>, she said, and slept with a baseball bat by her bed. URL',\n",
       " '<TWEET>: \"New <TARGET 1> sexual assault accusations emerge\" via FOX NEWS URL URL',\n",
       " '<TWEET>: Yes this. <TARGET 1>, this clown, the entire frat house at Fox. How could we expect first female presidential candidate to get a fair shake?',\n",
       " '<TWEET>: Over 300 Claims Against <TARGET 1>! URL',\n",
       " '<TWEET>: Over 300 Claims Against <TARGET 1>! URL URL',\n",
       " '<TWEET>: Rose McGowan accuses <TARGET 1> of Rape - News Today - Breaking News URL via @YouTube',\n",
       " '<TWEET>: <TARGET 1>, Hefner and the Poor Excuse that Explains a Lot via @NYTimes URL',\n",
       " '<TWEET>: Ellen sexual harassing did she learn that from <TARGET 1>',\n",
       " \"<TWEET>: If you're a Law &amp; Order: Criminal Intent fan, this just got personal #<TARGET 2><TARGET 2> #HimThough #MeToo\\n\\n<URL TITLE>: Weighing the Costs of Speaking Out About <TARGET 2>\\n<URL DESCRIPTION>: Annabella Sciorra, Daryl Hannah, and other women explain their struggles with going public.\",\n",
       " \"<TWEET>: <TARGET 1> admits 'aggressive and crude' behavior toward women URL\",\n",
       " '<TWEET>: <TARGET 1> accused of sexual assault by two more women URL URL',\n",
       " \"<TWEET>: George Clooney, Matt Damon Speak Out Against <TARGET 1> On 'GMA' URL\",\n",
       " '<TWEET>: Lisa Bloom investigated <TARGET 1> victims Rose McGowan, Ambra URL',\n",
       " '<TWEET>: Over 300 Claims Against <TARGET 1>! URL',\n",
       " '<TWEET>: More Women Accuse <TARGET 1> of Harassment... URL',\n",
       " '<TWEET>: Another shitty thing is a bumper ad in between the fake trailers that says \"Brought to you by your friends at The <TARGET 1> Company!\" Blegh.',\n",
       " '<TWEET>: More Women Accuse <TARGET 1> of Harassment... URL URL',\n",
       " '<TWEET>: Final: Burlington-Edison beats <TARGET 1> by 34 points. View box score:URL',\n",
       " '<TWEET>: Chazz Palminteri and <TARGET 1> brought that together like a puzzle at the end. Directing was Oscar-worthy.',\n",
       " \"<TWEET>: <TARGET 1> isn't the fucking president! How did this comparison actually occupy your brain?\",\n",
       " '<TWEET>: Bannon Declares War On \"Phony Culture Brokers\" In Hollywood Who \"Turned A Blind Eye\" To <TARGET 1> | Zero Hedge URL',\n",
       " '<TWEET>: Erin Burnett: So Trump Wants Us to Believe Clinton, <TARGET 1> Accusers, But Not His? URL via @mediaite',\n",
       " '<TWEET>: Men like <TARGET 1> are in every industry &amp; profession, and wield incredible power. I hope weve reached a turning point, but sadly doubt it.',\n",
       " '<TWEET>: Remember When he said, \"I know <TARGET 1> A Long Time\", I Said Then No Surprise There. Rich &amp; Priveledge, And Ur Famous U Can Do Anything\". URL',\n",
       " \"<TWEET>: But, you're defending @CNN trying to distract from <TARGET 1> and the rest of Hollywood. O'Reilly had his moment of shame.\",\n",
       " '<TWEET>: A piece I wrote in 2014 about gender, the New Republic &amp; <TARGET 1>: URL',\n",
       " '<TWEET>: I find it funny that you and other celebs bitch &amp; moan about elected officials, but you and many others stayed quiet on <TARGET 1>.',\n",
       " '<TWEET>: Pervert politicians: why the <TARGET 1> effect could hit Westminster hardest URL',\n",
       " '<TWEET>: Is it bad that I derive satisfaction from imagining <TARGET 1>, Trump and other sexual predators stuck in prison cells with much larger men? URL',\n",
       " '<TWEET>: Cielo (<TARGET 1>): Esta noche full time bebe\\n\\n<URL TITLE>: Escort <TARGET 1> - divinas<TARGET 1>.com - Escorts ( call girls ) in <TARGET 1>, Argentina\\n<URL DESCRIPTION>: Divinas <TARGET 1> el Portal interactivo de servicios escorts y de acompaantes mas completo de Argentina | Welcome to <TARGET 1>, Argentina the best escorts are here! Divinas <TARGET 1> is a wide directory of Independent Escorts (call girls) in <TARGET 1>, Argentina. Containing one of the largest selection of ladies escorts Argentinaan and foreign in this city.',\n",
       " '<TWEET>: WOW <TARGET 1> TRENDING 2ND SPOT WTF NOICE',\n",
       " '<TWEET>: <TARGET 1> much? URL',\n",
       " '<TWEET>: LOL - epstein- <TARGET 1>-<TARGET 2>-podesta-uh huh- she is \"shocked\" or dismayed- yeah we believe that shit URL',\n",
       " '<TWEET>: Statute of Limitations re <TARGET 1> in Global Common Law has \"labouring under specific disability\" particularly for this type of cult abuse.',\n",
       " '<TWEET>: She helped protect <TARGET 1>',\n",
       " '<TWEET>: Bet tonight was the first time the words have No <TARGET 1> no cash have been said',\n",
       " '<TWEET>: From the famed NYT movie critic, on <TARGET 1>  thread: URL\\n\\n<QUOTED TWEET>: 1) Change of pace: he made anonymous death threats to me. By phone. Vincent Canby overheard him. Threats timed to review of \"Fingers.\"',\n",
       " '<TWEET>: <TARGET 1> wasnt and isnt president so false equivalency',\n",
       " '<TWEET>: #USA New <TARGET 1> sexual assault accusations emerge: New allegations from at least two actresses URL #agency URL',\n",
       " '<TWEET>: Actress Annabella Sciorra Claims <TARGET 1> Raped Her as Daryl Hannah Recalls Scary URL URL',\n",
       " '<TWEET>: <TARGET 1> Is Now Suing His Own Company URL',\n",
       " '<TWEET>: Making the director famous enough for me now to have heard of him. #<TARGET 1> #dirtbag URL',\n",
       " '<TWEET>: Why <TARGET 1> is not in jail yet? @TheJusticeDept @CNN URL',\n",
       " '<TWEET>: thanks <TARGET 1> thanks for always being here for me! love you so so much URL',\n",
       " '<TWEET>: <TARGET 1> scandal: Gold Coast actor reveals experience - URL URL',\n",
       " '<TWEET>: URL #News Daryl Hannah and Annabella Sciorra join <TARGET 1> accusers URL',\n",
       " '<TWEET>: Annabella Sciorra says <TARGET 1> burst into home, raped her URL',\n",
       " '<TWEET>: Be <TARGET 1> again',\n",
       " '<TWEET>: <TARGET 1> doesnt look so bad now, huh? Too soon?',\n",
       " '<TWEET>:  creasing as gaze casts downwards. Most times, he was strong; Lucifer could never be hurt, right? Not unless it was around <TARGET 1>. ',\n",
       " '<TWEET>: Four more women accuse <TARGET 1> of harassment, bringing total to at least a dozen URL URL',\n",
       " '<TWEET>: Nike SB Highlights <TARGET 1> Baker in New Profile Video via @HYPEBEAST URL',\n",
       " '<TWEET>: Its horrible how companies are trying to benefit from the sexual harassment case of Mr. <TARGET 1> URL\\n\\n<QUOTED TWEET>: Low-profile, low-wage industries would benefit from a <TARGET 1> Effect, @annielowrey writes URL',\n",
       " \"<TWEET>: Rose McGowan's First Public Speech Since <TARGET 1> Scandal URL\",\n",
       " '<TWEET>: Spicy quote for a man that endorsed <TARGET 1>. URL\\n\\n<QUOTED TWEET>: URL',\n",
       " \"<TWEET>: There is no way to spin <TARGET 1> into an acceptable Halloween costume. This is your warning. Don't.\",\n",
       " \"<TWEET>: I feel for you Rose. Hope you mean Hillary, Bill, Podesta, Lynch, Comey, Shultz &amp; associates (AKA <TARGET 1>'s buddies) are getting indicted\",\n",
       " '<TWEET>: <TARGET 1>, Landon Clements Advisor On Southern Charm Fired For Sexual Harassment URL',\n",
       " '<TWEET>: 100% hes a liberal?!? #flush the toilet with these scum! #podesta #clinton #<TARGET 2> #<TARGET 1> #to many to count good vs evil ',\n",
       " '<TWEET>: Same media that covered for <TARGET 1> and pedophilia in Hollywood. Not so surprising.',\n",
       " '<TWEET>: Icymi. For the last 25 years Hollywood position <TARGET 1> innocent. Hmmmmmm glass house much bitch.',\n",
       " '<TWEET>: Weighing the Costs of Speaking Out About <TARGET 1> URL',\n",
       " \"<TWEET>: After Parting Ways With <TARGET 1>, Tarantino's Manson Family Movie Becomes Subject Of A URL\",\n",
       " \"<TWEET>: I'll never see <TARGET 1> again w/o visualizing him pressing his penis on young unwilling women. Disgusting. @Morning_Joe @JoeNBC\",\n",
       " '<TWEET>: More Women Accuse <TARGET 1> of Harassment... URL',\n",
       " '<TWEET>: I dont want to sit on your lap, she thought. But, she alleges, <TARGET 1> insisted. URL via @BFT_Podcast',\n",
       " '<TWEET>: I think <TARGET 1>. If Im not mistake , he was in or with Fort Minor',\n",
       " '<TWEET>: When Trump misbehaved on the tapes you and Mika were very critical, but your silence of <TARGET 1> is astonishing!!!',\n",
       " '<TWEET>: \"New <TARGET 1> sexual assault accusations emerge\" via FOX NEWS #timbeta #betaajudabeta #timbetalab',\n",
       " '<TWEET>: The New Yorker: Weighing the Costs of Speaking Out About <TARGET 1>. URL great writing !!',\n",
       " '<TWEET>: As soon as we stop tolerating your sexist and pedophilia...as bad as <TARGET 1>...',\n",
       " \"<TWEET>: Here's what Kurt Cobain would have thought of Donald Trump and <TARGET 1> URL\",\n",
       " \"<TWEET>: Trump accusers clearly lies. <TARGET 1> accusers heroes for coming forward. URL\\n\\n<QUOTED TWEET>: Fox News has spent 21 minutes covering O'Reilly and 12.5 hours on <TARGET 1>. URL\",\n",
       " '<TWEET>: My <TARGET 1> panties looked like they had a string  I was so annoyed',\n",
       " \"<TWEET>: <TARGET 1> does not belong in this country and this time. I don't even think the cavemen would have tolerated it.\",\n",
       " '<TWEET>: Its Time for Donald Trump to be <TARGET 1>ed | National Review URL',\n",
       " \"<TWEET>: This woman is an embarrassment to all females. I feel like if I pulled her hair, she'd be <TARGET 1> in a SHH mask. You SUCK, @PressSec URL\\n\\n<QUOTED TWEET>: White House says all women who have accused Trump of sexual misconduct are lying Spoiler Alert: Trumps the liar URL\",\n",
       " '<TWEET>: #MeToo @rosemcgowan @DollyKyleWriter @atensnut @kathleenwilley @ThePaulaJones URL\\n\\n<QUOTED TWEET>: More women have come forward with claims of what <TARGET 2> did to them, @RonanFarrow reports. URL',\n",
       " '<TWEET>: New <TARGET 1> sexual assault accusations emerge URL URL',\n",
       " '<TWEET>: New <TARGET 1> sexual assault accusations emerge via the @FoxNews App URL',\n",
       " '<TWEET>: Actress Annabella Sciorra Accuses <TARGET 1> of Rape in New New Yorker Report on the Disgraced Producer URL',\n",
       " '<TWEET>: Who advised #<TARGET 2><TARGET 2> on his overly contrived #apology. Seems likely to invite pre-and-post #ABC #MeToo victims?\\n\\n<URL TITLE>: <TARGET 2> admits \\'aggressive and crude\\' behavior toward women\\n<URL DESCRIPTION>: \"I am profoundly sorry for the pain and anguish I have cause by my past actions. I apologize sincerely to the women I mistreated,\" <TARGET 2> wrote.',\n",
       " \"<TWEET>: You have no soul. These people went through hell. All they want is a little joy, and you're going to deprive them that? Go enable <TARGET 1>.\",\n",
       " '<TWEET>: I know that Robert Redford and <TARGET 1> are actors, but if they could reunite to help Mueller seal the deal thatd be neat',\n",
       " '<TWEET>: Actress Annabella Sciorra Claims <TARGET 1> Raped Her as Daryl Hannah Recalls Scary Incidents in New Expos URL ',\n",
       " '<TWEET>: URL --<TARGET 4>, <TARGET 3>, <TARGET 2>, <TARGET 1>, <TARGET 5>, Bill Cosby, they have little in common except their gender.',\n",
       " '<TWEET>: <TARGET 1> Apologizes to Women He Mistreated URL #NYT #Business',\n",
       " '<TWEET>: Obviously. All of the conspiracies about Clinton and <TARGET 1> accusers are all to be taken as truth. Anything against trumpy is fake news ',\n",
       " '<TWEET>: New <TARGET 1> sexual assault accusations emerge - URL URL',\n",
       " '<TWEET>: News post: \"<TARGET 1> apologizes for aggressive\\x92 behavior: I feel profound guilt and responsibility\" URL',\n",
       " '<TWEET>: Over 300 Claims Against <TARGET 1>! URL',\n",
       " '<TWEET>: <TARGET 1> Targeted College Girls Too #NewsGrit URL',\n",
       " '<TWEET>: New <TARGET 1> sexual assault accusations emerge URL',\n",
       " '<TWEET>: Im one of the women accusing <TARGET 1> of sexual harassment. Hes part of a much bigger problem. - URL',\n",
       " '<TWEET>: Flipped around earlier, all networks talking about charges and @foxnews talking about <TARGET 1> and whether Hillary knew about dossier ',\n",
       " \"<TWEET>: Here's a photo of Melania, Trump, Mrs. <TARGET 1>, and <TARGET 1>. Birds of a feather! Both are sexual predators too! URL\",\n",
       " '<TWEET>: \"Annabella Sciorra\" #<TARGET 1> was a predator using his position to molest and rape star stuck young actresses speak up ladies',\n",
       " '<TWEET>: <TARGET 1> sues for emails he says may exonerate him URL Via @smh',\n",
       " '<TWEET>: <TARGET 1> Sues <TARGET 1> Company, Demanding Access to Records - URL',\n",
       " '<TWEET>: dj pitty <TARGET 1> lets go dancing 98 shumager frmula 1 URL',\n",
       " '<TWEET>: More Women Accuse <TARGET 1> of Harassment URL URL',\n",
       " '<TWEET>: Hollywood patently an open plan cult compound w/ <TARGET 1> like abuse &amp; transgenerational grooming. Statute of Limitations, a weak argument',\n",
       " '<TWEET>: Over 300 Claims Against <TARGET 1>! URL URL',\n",
       " '<TWEET>: Actress Annabella Sciorra Claims <TARGET 1> Raped Her as Daryl Hannah Recalls Scary Incidents in New Expos URL',\n",
       " '<TWEET>: Final Score #Burlington-Edison 47 #<TARGET 1> 13. #wafbscores',\n",
       " '<TWEET>: **<TARGET 1> buys wheelchair and loads up on old man make up **',\n",
       " '<TWEET>: Morning Joe and Mika: Our Hearts Break for Disgraced <TARGET 1> - Breitbart URL sick couple',\n",
       " '<TWEET>: Rather than critiquing #<TARGET 1> statement, how about giving serious strategic points? URL #CrisisPR',\n",
       " '<TWEET>: You do know that <TARGET 1> was a Trump supporter right?',\n",
       " '<TWEET>: yes: <TARGET 1>...',\n",
       " '<TWEET>: ENT: <TARGET 1> issued profane denial when asked about sexual misconduct allegations URL #entertainment URL',\n",
       " '<TWEET>: <TARGET 1> accused of sexual assault by two more women URL',\n",
       " \"<TWEET>: They'll be crashing on <TARGET 1>'s couch.\",\n",
       " '<TWEET>: need the 1-5 hitters to get above the <TARGET 1> line for that to happen',\n",
       " \"<TWEET>: Still waiting on the Anti-<TARGET 1> March. URL\\n\\n<QUOTED TWEET>: U.S. women gather in Detroit to build on anti-Trump Women's March URL URL\",\n",
       " '<TWEET>: Selma Blair: <TARGET 1> threatened to kill me after sexual harassment URL',\n",
       " '<TWEET>: SHE IS THE PHENOMENAL STAR MAINE <TARGET 1>. URL\\n\\n<QUOTED TWEET>: May sobrang happy @mainedcm . Full support di lng ng fans . Kundi pati family mo  sobrang bless mo bebe girl. Mahal ka nmin sobra  URL',\n",
       " '<TWEET>: No, <TARGET 1>, ..... No. Wait is that right? No.',\n",
       " '<TWEET>: Congrats to my #shero @melsil: Talk of <TARGET 1> Dominates Womens Ceremony in a Hollywood Unmoored URL',\n",
       " '<TWEET>: No but, what if Fievel Goes West had be directed by <TARGET 1>.',\n",
       " \"<TWEET>: Once again, I'm going to say that <TARGET 1> should be in prison. For life. URL\",\n",
       " \"<TWEET>: Let's call <TARGET 1> what he is - a serial rapist. Shame on every single person who covered up his crimes URL\",\n",
       " '<TWEET>: Ew whoever voted for <TARGET 1> is ',\n",
       " '<TWEET>: And what about your perverted friends? #<TARGET 2> #<TARGET 3> #<TARGET 1> #BillCosby to name a few...',\n",
       " '<TWEET>: Weighing the Costs of Speaking Out About <TARGET 1> URL',\n",
       " '<TWEET>: A great day @UW for the Biomaterials Showcase &amp; <TARGET 1> symposium. Felt nice to be amongst my people  #womeninSTEM #biomaterials URL',\n",
       " '<TWEET>: Women accusing #Trump of sexual harassment are lying, If so all those against #<TARGET 1> are too! @realDonaldTrump URL',\n",
       " '<TWEET>: Annabella Sciorra-Daryl Hannah Discuss Weighing the Costs of Speaking Out About <TARGET 2> #MeToo @atensnut\\n\\n<URL TITLE>: Weighing the Costs of Speaking Out About <TARGET 2>\\n<URL DESCRIPTION>: Annabella Sciorra, Daryl Hannah, and other women explain their struggles with going public.',\n",
       " '<TWEET>: Now that <TARGET 1> is gone, MAYBE they can speak truth',\n",
       " '<TWEET>: Selma Blair &amp; Rachel McAdams Accuse <TARGET 1> of Sexual Harassment URL URL',\n",
       " '<TWEET>: Over 300 Claims Against <TARGET 1>! URL',\n",
       " '<TWEET>: 9 <TARGET 1> tapos nasa biyahe pa rin ako rn :(((((',\n",
       " \"<TWEET>: I think there's still a chance he's in JL. His helmet in the new pic is more damaged than in <TARGET 1>'s video. Wonder how it got that way....\",\n",
       " '<TWEET>: More Women Accuse <TARGET 1> of Harassment... URL',\n",
       " '<TWEET>: <TARGET 1> of NBC was fired for sexual harassment!',\n",
       " '<TWEET>: <TARGET 1> had to be stopped. It took too long.',\n",
       " '<TWEET>: E! News host <TARGET 1> accused of sexual harassment by former employees URL via @HuffPostEnt',\n",
       " '<TWEET>: Annabella Sciorra Says She Was Violently Raped by <TARGET 1> URL',\n",
       " '<TWEET>: Hand that rocked the cradle star says <TARGET 1> raped her before stalking her for years, while dary: URL via',\n",
       " '<TWEET>: Weighing the Costs of Speaking Out About <TARGET 1> URL',\n",
       " '<TWEET>: \"straight-to-gif\"! George Foreman fighting <TARGET 1> in Vegas? Its the least we deserve URL',\n",
       " \"<TWEET>: Biocad, JSC v. F. <TARGET 1>-La-Roche, Ltd.: Locus of Russian Drug Maker's Claims Make Them Outside Reach of U.S. URL\",\n",
       " \"<TWEET>: What Henry Cavill's Justice League Mustache Was Really Like, According To <TARGET 1> URL\",\n",
       " '<TWEET>: Meet today at <TARGET 1>!! come out and support ',\n",
       " \"<TWEET>: God it's a hard watch, but such a sweet film. Up there with <TARGET 1>'s best performances IMO.\",\n",
       " '<TWEET>: <TARGET 1> of course',\n",
       " \"<TWEET>: <TARGET 1> is a REPUBLICAN. R's passed a $4.2 trillion budget, sets up tax cuts for rich &amp; guts Medicare, Medicaid URL\",\n",
       " \"<TWEET>: <TARGET 1>'s Melancholia was beautiful :'(\",\n",
       " '<TWEET>: Id pay good money to watch you beat the stupid out of <TARGET 1>. Plz make this happen!',\n",
       " '<TWEET>: A4. I think it was llama in <TARGET 1>, Argentina #luxtravelchat',\n",
       " '<TWEET>: Maine <TARGET 1> #SalamatMaine URL',\n",
       " '<TWEET>: You like <TARGET 1>? You will love batshit crazy dumb as a rock willing to say absolutely anything Blackburn. God help what is left USA.',\n",
       " '<TWEET>: Today, Maine <TARGET 1> has broken that illusion that all celebrites are living the life. Hi maine, I know they gave you career but gurl...',\n",
       " '<TWEET>: <TARGET 1> Lawyers Up for Bombshell New York Times, New Yorker Stories URL',\n",
       " '<TWEET>: Now Playing <TARGET 1> Smith Big Blue Eyes (And Little White Lies) URL',\n",
       " '<TWEET>: WHY IS HOLLYWOOD SUCH A CESSPIT OF ABUSE AND MISOGYNY? <TARGET 1> Lawyers Battling N.Y. Times URL',\n",
       " '<TWEET>: Beautiful line drawing from <TARGET 1>, 5th gr. #ArtsEd #drawing #ErieExcellence URL',\n",
       " '<TWEET>: Stop by our <TARGET 1> location this fall, 8:00AM - 1:00PM, for Sports Injury Saturday and receive an assessment! #immediatecare #sports URL',\n",
       " \"<TWEET>: maine <TARGET 1> mocha #sgbsbodyguard world teachers #kathnielllskasangga happy teacher's day #askdonny #fakenews URL\",\n",
       " \"<TWEET>: maine <TARGET 1>, you're doing amazing sweetie URL\\n\\n<QUOTED TWEET>: Here are Joey De Leon's disgusting and dangerous comments about depression on Eat Bulaga today + Maine <TARGET 1> taking a stand. URL\",\n",
       " '<TWEET>: Been doing Zeta and <TARGET 1> <TARGET 1> movies + Shooter atm, so noooooo.',\n",
       " '<TWEET>: Super Leftists Sex Predator? <TARGET 1> lawyers up ahead of bombshell articles @NYDailyNews #tcot #tlot #ccot URL',\n",
       " \"<TWEET>: Apparently George has offered Steven a fight, he will box and <TARGET 1> can use whatever . Real talk. I think he's accepted too. \",\n",
       " '<TWEET>: Check It - Preview URL via @YouTube #HPEB627 Awesome documntry w/ an intersectional pov, accessible thanks to <TARGET 1>',\n",
       " '<TWEET>: Is it crazy that i ship him with <TARGET 1> ? I mean just imagine them together being adorable boyfriends',\n",
       " '<TWEET>: And Oktoberfest both days! Seeing the <TARGET 1> dogs race seems like the perfect cure rn URL',\n",
       " '<TWEET>: SC concerned about social media trolls- SC has become-Totally Jobless-There is Block button-Will an SC judge read each tweet-<TARGET 1>:)RT',\n",
       " '<TWEET>: This an excellent article about the prejudiced and disgraced judge, <TARGET 1>. Vote for Doug Jones! #DougJonesforSenate URL\\n\\n<QUOTED TWEET>: \"We have an opportunity to show the Alabamafication of Amer. can be something very different, even something good.\" URL',\n",
       " '<TWEET>: If <TARGET 1> made this joke, no one would care. Yes, it was distasteful but grow the fuck up. URL',\n",
       " '<TWEET>: in my life full of Joey De Leon, there is always Maine <TARGET 1> to fight back. THANK YOU !',\n",
       " \"<TWEET>: <TARGET 1> is a REPUBLICAN. R's passed a $4.2 trillion budget, sets up tax cuts for rich &amp; guts Medicare, Medicaid URL\",\n",
       " '<TWEET>: Have #home and #business on the same property with great Hwy frontage. Text <TARGET 1> Sanders at 417-294-2662. URL URL',\n",
       " '<TWEET>: keep it up maine girl. the bella that only speak on her blog now has a voice louder than a roar #Maine<TARGET 1> URL\\n\\n<QUOTED TWEET>: Joey de Leon and Maine <TARGET 1> on depression URL URL',\n",
       " \"<TWEET>: I'm sure it has its own tanning booth. Very small, tiny. Really, infinitesimal. #sad #little #<TARGET 1>\",\n",
       " '<TWEET>: <TARGET 1> has hired Lisa Bloom to prepare for two stories about \"sexual allegations\" against him URL',\n",
       " '<TWEET>: Thank you Lord for the existence of people like maine <TARGET 1> URL\\n\\n<QUOTED TWEET>: Joey de Leon and Maine <TARGET 1> on depression URL URL',\n",
       " '<TWEET>: George Foreman fighting <TARGET 1> in Vegas? Its the least we deserve URL',\n",
       " \"<TWEET>: Love the actor on the left but don't know his name.\",\n",
       " '<TWEET>: At MarTech conference, tech evangelist <TARGET 1> envisions how AR and VR will transform ... URL #AR #AugmentedReal',\n",
       " '<TWEET>: Find someone like a Maine <TARGET 1> in a world full of Joey De Leon.',\n",
       " '<TWEET>: Yes! Tea should be with milk, like Cagney and <TARGET 1>, or bacon sandwich and brown sauce',\n",
       " '<TWEET>: Patiently waiting for <TARGET 1> to peep my snap',\n",
       " '<TWEET>: George Foreman fighting <TARGET 1> in Vegas? Its the least we deserve URL',\n",
       " '<TWEET>: #Model #<TARGET 1>Hernandez URL\\n\\n<QUOTED TWEET>: #Follow #<TARGET 1>Hernandez #Fitness #Sports #Surf #Model #Athlete #Sexy #Hot #Bikini #Goddess on #Instagram--&gt; URL URL',\n",
       " '<TWEET>: \"Three 5 Year Olds\" track from \"Word - Live at Carnegie Hall\" album by <TARGET 1> #nowplaying URL',\n",
       " '<TWEET>: Rocket Pioneer Robert H. <TARGET 1> (1882-1945) was born #RobertH.<TARGET 1> #BornToday URL',\n",
       " \"<TWEET>: Yup, she's that girl - Maine <TARGET 1>.  #DepressionIsReal #SalamatMaine URL\\n\\n<QUOTED TWEET>: Joey de Leon and Maine <TARGET 1> on depression URL URL\",\n",
       " '<TWEET>: Keri na ang December <TARGET 1>. Hehe',\n",
       " \"<TWEET>: I don't think Bale would've worked in the current Justice League universe, but neither does <TARGET 1>. URL\\n\\n<QUOTED TWEET>: The Best one is christian Bale\",\n",
       " '<TWEET>: Thank you, Hillary Clinton, for Anthony <TARGET 1>. #HillaryThankYouNotes',\n",
       " \"<TWEET>: I'm at <TARGET 1> Elementary School in Chicago, IL URL URL\",\n",
       " '<TWEET>: George Foreman fighting <TARGET 1> in Vegas? Its the least we deserve URL',\n",
       " '<TWEET>: <TARGET 1> Continues to Seek Treatment for Alcohol Addiction URL via @UsWeekly',\n",
       " \"<TWEET>: I found this in The Northern Light Newspaper <TARGET 1>'s local paper might get a laugh or two out someone.... URL\",\n",
       " '<TWEET>: Have courage and be kind A modern day Cinderella and soo much more.. That is Maine <TARGET 1>..  #ALDUBBigHearts',\n",
       " '<TWEET>: <TARGET 1> Teases A Baby Driver Sequel After Crashing Edgar Wrights Q&amp;A URL via @ThePlaylist',\n",
       " '<TWEET>: Napanuod ko yung kanina and yeah, was amazed with Maine <TARGET 1>! Naoff lang talaga ko kay Joey De Leon over his comment!',\n",
       " \"<TWEET>: Actually starting at 3pm too Moonlight in Vermont! Its a <TARGET 1> Saturday! Lets have a <TARGET 1> aweekend #marathon URL\\n\\n<QUOTED TWEET>: 2 days to go! Excited for Saturday's #doublefeature #AllOfMyHeartInnLove on @hallmarkchannel #Brennies @AllOfMyHeartTV URL\",\n",
       " '<TWEET>: Liberal Darling <TARGET 1> Accused Of  Wait For It  Sexual AssaultURL URL',\n",
       " \"<TWEET>: That's sad af <TARGET 1> is apart of this smh man URL\\n\\n<QUOTED TWEET>: since this story aired a week ago, at least half a dozen more men have been accused of sexual harassment: <TARGET 1> (5) <TARGET 2> (5) Benjamin Genocchio (5) <TARGET 4> (4) David Guillod (4) <TARGET 3> (2) Jeff Hoover (1) URL URL\",\n",
       " '<TWEET>: <TARGET 1> denies allegation that he groped male model in 1980s URL',\n",
       " \"<TWEET>: Must-read. <TARGET 1>'s statement was well-crafted, carefully worded, and so far from an actual apology to his victims and void of true acceptance and understanding of his wrongdoing. URL\\n\\n<QUOTED TWEET>: Why <TARGET 1>s Statement is Worse Than You Think URL\",\n",
       " '<TWEET>: Jesus Parents and <TARGET 1>s Gall via @NYTimes URL',\n",
       " '<TWEET>: <TARGET 2>, <TARGET 1> respond in harassment scandal URL URL',\n",
       " '<TWEET>: EXCLUSIVE  Mother of <TARGET 1> Accuser Contradicts Key Detail of Daughters Sexual Misconduct Story Revealed: False Reporting in Washpost Bombshell  URL',\n",
       " '<TWEET>: Perspective | I did a stand-up set about <TARGET 1>s offenses. It wasnt enough. URL',\n",
       " '<TWEET>: White liberal celebs like Donna Karan (Haiti) , <TARGET 1> (Trayvon)or bono (Africa) love to use poor black people to burnish their rep when their in trouble. Its gross URL',\n",
       " '<TWEET>: <TARGET 1> was ACCUSED of rape and nothing has been proven  URL',\n",
       " '<TWEET>: RT nytimes \"At least 20 high-profile men have been accused of sexual misconduct since the <TARGET 1> scandal broke. URL\"',\n",
       " '<TWEET>: Gotta ask: Do women want to watch men masturbate? <TARGET 1> admits sexual misconduct allegations URL #JustAsking',\n",
       " '<TWEET>: Wonder Woman vs. <TARGET 1>? I like those odds. ',\n",
       " \"<TWEET>: Ellen Page accuses X-Men director <TARGET 1> of sexual harassment and 'outing her': URL URL\",\n",
       " '<TWEET>: I Love You, Daddy Review: <TARGET 1>s Cancelled Movie Reeks of Impunity | The New Yorker URL',\n",
       " \"<TWEET>: Yo let me move to Alabama and take <TARGET 1>'s place yall got some good shrimp and crawfish\",\n",
       " '<TWEET>: Gotta ask: Do women want to watch men masturbate? <TARGET 1> admits sexual misconduct allegations URL #JustAsking',\n",
       " '<TWEET>: You might want to pay attention to your scandals. <TARGET 2>, <TARGET 3>, <TARGET 1> and all the others.',\n",
       " '<TWEET>: Isnt this <TARGET 1> land where people like to molest children? There seems to be an acceptance of this behaviour in Alabama which is disgusting!',\n",
       " '<TWEET>: <TARGET 1> issues statement admitting to sexual abuse: These stories are true - URL #GoogleAlerts',\n",
       " \"<TWEET>: Gal Gadot Says She Won't Do Another 'Wonder Woman' Movie If <TARGET 1> Is Involved: Brett URL\",\n",
       " '<TWEET>: URL (LV.9) After <TARGET 1>: A List of Men Accused of Sexual Misconduct and the Fallout for Each - The New York Times URL',\n",
       " '<TWEET>: <TARGET 1> memes are not funny anymore',\n",
       " \"<TWEET>: How 'Saturday Night Live' Joked About <TARGET 1> - The Hollywood Reporter URL\",\n",
       " \"<TWEET>: Funny the GOP didn't issue same caution when <TARGET 1> accusations first came out.\",\n",
       " '<TWEET>: Please stop applauding <TARGET 1> for doing the bare minimum URL URL',\n",
       " '<TWEET>: I though we were on 2. Damn. 15 <TARGET 1>!? 15!?',\n",
       " \"<TWEET>: #GuyStuff Gal Gadot Says She Won't Do Another 'Wonder Woman' Movie If <TARGET 1> Is Involved URL #DerangedRadio URL\",\n",
       " \"<TWEET>: <TARGET 1> is like character in 'Lolita.' great reporting! URL\",\n",
       " \"<TWEET>: So somehow bc the accuser was at GT's house makes it 0% chance of misconduct happened... have any of you heard of Bill Cosby or <TARGET 1>?\",\n",
       " \"<TWEET>: I cant go to the police. Hes destroying my career re: speaking out abt <TARGET 2>'s sexual violence #MeToo\\n\\n<URL TITLE>: Weighing the Costs of Speaking Out About <TARGET 2>\\n<URL DESCRIPTION>: Annabella Sciorra, Daryl Hannah, and other women explain their struggles with going public.\",\n",
       " \"<TWEET>: Footage of <TARGET 1> at a male model shoot in the 80's URL\",\n",
       " '<TWEET>: Its not these bad men. Or that dirty industry. Its this inhumane economic system of which we are all a part #MeToo\\n\\n<URL TITLE>: <TARGET 2> and the Economics of Consent\\n<URL DESCRIPTION>: The blunt power of the gatekeeper is the ability to enforce not just artistic, but also financial, exile.',\n",
       " '<TWEET>: I SUPPORT <TARGET 1>...it takez $ 2 make $, if u Whorez hd a prob thn u shlda spke up soonR....#TrampStamp',\n",
       " '<TWEET>: <TARGET 1> allegations got me fucked up',\n",
       " '<TWEET>: From the current boss of staffer who said Senator <TARGET 1> brought her to a hotel room for drinks when she was 19: URL\\n\\n<QUOTED TWEET>: My perspective on tonight\\'s Sacramento Bee article \"Second woman alleges misconduct by state Sen. <TARGET 1>\": URL',\n",
       " '<TWEET>: DC Comics Has Suspended Editor <TARGET 1> Amidst Allegations of Sexual Harassment URL URL',\n",
       " '<TWEET>: Could <TARGET 1> face charges for accusations of sexual harassment? Criminal defense attorney Janet Johnson explains. URL',\n",
       " \"<TWEET>: I've taken three showers since Thursday and I still haven't been able to wash off the stink of loving <TARGET 1> for years.\",\n",
       " \"<TWEET>: So I wonder who's next...#<TARGET 1> #<TARGET 2> #billcosby.....how about Hollywood's pedophiles.\",\n",
       " '<TWEET>: no mention of <TARGET 1> or disgusting widespread epidemic throughout Hollywood.',\n",
       " \"<TWEET>: If you're still scrambling to find a way to make the #<TARGET 1> news make sense in your head because ugh yes we're supposed to believe victims but jeez it just really sucks when the accused is someone you like, a) rethink your entire life; and b) URL\",\n",
       " \"<TWEET>: Trump is destroying the nation, the 1% is destroying the nation. The partisanship in response to the accusations is revealing. From all sides of the political and cultural spectrum. Are you aware of <TARGET 1>'s past behaviour patterns?\",\n",
       " '<TWEET>: <TARGET 2> took to Twitter to deny groping a male model and <TARGET 1> said he never exposed himself to a female writer helping him with a TV script, both back in the 1980s URL',\n",
       " '<TWEET>: If <TARGET 2> came out and said exactly what <TARGET 1> said in his statement youd see that as an actual apology?',\n",
       " '<TWEET>: <TARGET 1> is accused of exposing himself to writer URL',\n",
       " \"<TWEET>: This dude got a <TARGET 1> vibe the way he says 'Tommy' #tcmparty #TheWindow run Tommy run. URL\",\n",
       " \"<TWEET>: Wait so <TARGET 1> wielded his power (no euphemism intended), but isn't that what every rock, movie, sport star does with groupies? Why go to his hotel room and why stay watching him partake in his strange sexual fetish #<TARGET 1>\",\n",
       " '<TWEET>: Saturday Night Live drags <TARGET 2>, lets <TARGET 1> off the hook URL',\n",
       " '<TWEET>: Panicking GOP Might Postpone Alabama Senate Election As <TARGET 1> Crumbles via @politicususa URL',\n",
       " \"<TWEET>: Okay but <TARGET 2> has at least 4 different accusers with corroborating testimonies. He definitely did it. With only one, a chance <TARGET 1>'s accuser is lying. Not saying he is, just being realistic.\",\n",
       " '<TWEET>: Former congressman Anthony <TARGET 1>...democrat pedophile babeeeee!',\n",
       " '<TWEET>: <TARGET 1> liked and retweeted my tweet from yesterday  sjsksbd',\n",
       " '<TWEET>: This sums up the situation quite well for me. URL\\n\\n<QUOTED TWEET>: The comments sections in <TARGET 1>\\'s response is the most complete example of why victims do not come forward in these situations. Being a former cop, individuals who said \"It\\'s a He Said/(S)he Said\" reveled in those words knowing their guilt could never be proven &amp; said it with glee',\n",
       " \"<TWEET>: Theme park designer <TARGET 1>'s spokesperson is denying actor Anthony Edward's abuse accusation. URL\",\n",
       " '<TWEET>: All the SJW men outraged by <TARGET 1> should prolly stop rubbing one out to random girls profile pics on Twitter.. just saying',\n",
       " '<TWEET>: Not <TARGET 1>. Nooo. Come on, man.',\n",
       " '<TWEET>: Abra - 93.3 (12/15/15) - <TARGET 1> Estates. 10:33:11am (29m 56s). URL',\n",
       " '<TWEET>: \"How dare she stray away and have independent thought..\" that being said, she only called for the accused having a chance when it was <TARGET 1>, someone she liked. A lefty activist.',\n",
       " '<TWEET>: OH ok, NOW sexual assault is funny: SNL jokes about Moore (still waiting for the <TARGET 1> skit) URL',\n",
       " '<TWEET>: yall had me dying with the <TARGET 1> and balls omg hahah love u guys already URL',\n",
       " '<TWEET>: At least 20 high-profile men have been accused of sexual misconduct since the <TARGET 1> scandal broke. Our list: URL',\n",
       " \"<TWEET>: Judy Gold: You think you know <TARGET 1> You don't @CNN URL\",\n",
       " '<TWEET>: <TARGET 1>, Alabama Senate Candidate Under Siege, Tries to Discredit Accusers URL, @nytimes',\n",
       " '<TWEET>: <TARGET 1> will be treated fairly by Maine Ammo Company because we are Americans &amp; we believe in justice for all, that includes conservatives. Dump @Keurig @washingtonpost #fakenews #fakecoffeekeurig URL\\n\\n<QUOTED TWEET>: BANG BANG HES NOT DEAD: Send a message to the professional hit-men at the @washingtonpost URL',\n",
       " '<TWEET>: Do you believe the women who accused <TARGET 1>?',\n",
       " '<TWEET>: I think you were listening to the recording of <TARGET 1> on Howard Stern.',\n",
       " '<TWEET>: Rabid Anti-Trumper <TARGET 1> Accused of Sexual Assault  Truthfeed URL',\n",
       " '<TWEET>: <TARGET 2> accused of groping model, <TARGET 1> accused of exposing himself to writer URL',\n",
       " '<TWEET>: The Moral Cowardice of Saying Allegations Against <TARGET 1> Are Horrible if True URL',\n",
       " \"<TWEET>: #<TARGET 1> #<TARGET 2> masturbation is something you do when you're alone.\",\n",
       " '<TWEET>: As I sit here and switch between NFL countdown and Meet the Press I wonder what does the most powerful man in the state of Alabama think of all this <TARGET 1> stuff.. Nick Saban',\n",
       " '<TWEET>: Pass on watching Streep in ANYTHING... since her GOD is <TARGET 1>!',\n",
       " '<TWEET>: A complicated question amid the <TARGET 1> allegations: Do we miss Gawker? URL #WonkPorn URL',\n",
       " '<TWEET>: <TARGET 1> is #Notliketheotherkids URL',\n",
       " '<TWEET>: Wow. Whoever this @JudgeJeanine lady is, she\\'s doing a lot of apology work for #ChildPedarist #<TARGET 1>. She should wait for the facts. URL\\n\\n<QUOTED TWEET>: <TARGET 1> is a big old sign around the GOP \\'s neck that reads: \"child molesters\\' URL',\n",
       " '<TWEET>: Its not these bad men. Or that dirty industry. Its this inhumane economic system of which we are all a part #MeToo\\n\\n<URL TITLE>: <TARGET 2> and the Economics of Consent\\n<URL DESCRIPTION>: The blunt power of the gatekeeper is the ability to enforce not just artistic, but also financial, exile.',\n",
       " \"<TWEET>: That is a good one, the <TARGET 1> memes are great :')\",\n",
       " '<TWEET>: Do you believe the women who accused <TARGET 1>?',\n",
       " '<TWEET>: Oh man <TARGET 1> too? Aka leader of the #Resistance? Brutal. Who is next. Chelsea Manning?',\n",
       " '<TWEET>: Gotta ask: Do women want to watch men masturbate? <TARGET 1> admits sexual misconduct allegations URL #JustAsking',\n",
       " \"<TWEET>: Again, you support <TARGET 1>, <TARGET 2>, Charlie Sheen, and Liberal Hollywood Elite Pedo Rings, and you won't denounce them. But you expect people to denounce Sean Hannity? Your Hypocrisy is proving your stupidity. Man Up, You won't or can't, or both. #IStandWithHannity URL\\n\\n<QUOTED TWEET>: aaaawwww the snowflake is angry.....so easy to trigger. I am a total libtard....been working on libtard issues my entire life!!!!! i am a total left wing loon who spends all my time working against conservatives and repubicans.....bwahahahahahahahahaha\",\n",
       " '<TWEET>: Justice League (2017) <TARGET 1>, Jason Momoa &amp; Ray Fisher talk about the movie URL',\n",
       " '<TWEET>: On Weekend Update, Michael Che called <TARGET 1> a well-dressed skin tag, and Colin Jost said <TARGET 1> should be in prison.',\n",
       " '<TWEET>: This <TARGET 1>, GOP candidate for the a Senate seat of Alabama is complaining that 14 year old is speaking up after 40 years. He forgets he was a powerful person judge in Alabama, not good for <TARGET 1>....',\n",
       " '<TWEET>: #BREAKING #NEWS: At least 20 high-profile men have been accused of sexual misconduct since the <TARGET 1> scandal broke. Our list: ',\n",
       " \"<TWEET>: Gal Gadot will only be 'Wonder Woman' again if <TARGET 1> is out URL #wonderwoman #forreal\",\n",
       " \"<TWEET>: Funny how Trump voters believe all of <TARGET 1>'s victims but none of Moore's, even with corroborating witnesses.\",\n",
       " '<TWEET>: <TARGET 1> accused of telling actress to sit on his face in 1991 URL',\n",
       " '<TWEET>: ahahahahahahaahahh! Ventura come <TARGET 1>',\n",
       " '<TWEET>: So why does Hannity not say that? Why does he instead defend what Moore did? (Instead of saying he didnt do it) Never mind that theres as much (or more) proof for Moore than with <TARGET 1> and and others. Yet you choose to defend one and not the other - why?',\n",
       " '<TWEET>: Oh, please, the left wld have praised this movie if the allegations had not come out! <TARGET 1> was sick b4 this movie &amp; sick after it! Middle America always knew it but we r mocked 4 our values. U people r a joke!',\n",
       " '<TWEET>: <TARGET 1>s statement deeply, unnervingly misunderstands the concept of consent: URL via @doublexmag',\n",
       " '<TWEET>: New <TARGET 1> accuser claims attack was certainly more than a grope URL',\n",
       " '<TWEET>: <TARGET 1> not only is a total pig, but victim shamed the women he pleasured himself in front of. According to him, he asked first &amp; they didnt say no. The fact that he got away w/ it so long shows you peoples priorities. Willing to endure smut to have a career. Sad...',\n",
       " '<TWEET>: Not talking about sexual abuse that is completely different <TARGET 1> said he had been drinking, again that is different than someone who is an alcoholic',\n",
       " '<TWEET>: oh man, so many trekkies defending <TARGET 1> for aggressively grabbing cocks',\n",
       " \"<TWEET>: Brand New's <TARGET 1> Responds Following Claims He Solicited Nudes From A Minor -- #Bran... URL URL\",\n",
       " '<TWEET>: Not to defend him, but there r actual photos of <TARGET 1>, only allegations of Moore. We have become a guilty till proven innocent society',\n",
       " '<TWEET>: Lol, this seems quite appropriate in the current HWood climate. Maybe <TARGET 1> or CK can do the next episode?',\n",
       " '<TWEET>: A complicated question amid the <TARGET 1> allegations: Do we miss Gawker? URL #USPolitics via @PostPolitics URL',\n",
       " '<TWEET>: If you immediately dismiss this as \"FAKE NEWS\" I would ask you to remember if you thought <TARGET 1> was the victim before he admitted he\\'d done everything of which he was accused.',\n",
       " '<TWEET>: people are gonna try to fuckin defend brand new because <TARGET 1> issued a half ass apology in which he misplaced the blame and passed it all off as \"sex addict sry :/\" w/ no mention of the victim or her age',\n",
       " '<TWEET>: I\\'d watch if they weren\\'t so biased. Call out the actors by name. Oh, but they are actually innocent until proven guilty. Well, <TARGET 1> already admitted his dirty deeds. They are still protective of their \"party\". Cold open about <TARGET 2>, but no skits about others. smh',\n",
       " '<TWEET>: Foreigners Hot Blooded sounds...different...in the wake of the <TARGET 1> news',\n",
       " '<TWEET>: At least 20 high-profile men have been accused of sexual misconduct since the <TARGET 1> scandal broke. Our list: URL',\n",
       " '<TWEET>: I could see Pauls neighbor breaking his ribs for what <TARGET 1> did but not the given reason of yard waste.',\n",
       " '<TWEET>: A complicated question amid the <TARGET 1> allegations: Do we miss Gawker? URL URL',\n",
       " '<TWEET>: What a life. What a funeral. Ms. Steinem paused &amp; looked out at the crowd. Dont you kind of wish we could read Kate on <TARGET 1>? URL\\n\\n<QUOTED TWEET>: Feminisms A-List Attends Kate Milletts Memorial in New York URL',\n",
       " '<TWEET>: #marvellous997 Kellyanne Conway on <TARGET 1> allegations: If true, that conduct is URL',\n",
       " '<TWEET>: #MeToo is working... URL\\n\\n<QUOTED TWEET>: At least 20 high-profile men have been accused of sexual misconduct since the <TARGET 2> scandal broke. Our list: URL',\n",
       " '<TWEET>: Its not these bad men. Or that dirty industry. Its this inhumane economic system of which we are all a part #MeToo\\n\\n<URL TITLE>: <TARGET 2> and the Economics of Consent\\n<URL DESCRIPTION>: The blunt power of the gatekeeper is the ability to enforce not just artistic, but also financial, exile.',\n",
       " '<TWEET>: I understand dropping <TARGET 1>, but also, why not make him go out in front of audiences and confront his new reality?',\n",
       " \"<TWEET>: <TARGET 1>, 'Star Trek' actor, denies sexual assault on former model in 1981 URL\",\n",
       " '<TWEET>: The #<TARGET 1> Moment and the #Trump Presidency The producer and other powerful men are facing repercussions for their alleged abusive behavior. Will the President? URL',\n",
       " '<TWEET>: #FtbolProfesional #RiverPlate - LOS 19 DE #RIVER QUE VIAJAN A <TARGET 1> - URL URL',\n",
       " '<TWEET>: Omg <TARGET 1> fran I literally said the same thing when I tweeted this i was like hahahahaaa......awww',\n",
       " '<TWEET>: Why Christopher Plummer is way more than a <TARGET 1> substitute @CNNI URL',\n",
       " '<TWEET>: In this world you are defending <TARGET 1>, Lieu supporter... <TARGET 1> admitted it, Moore has been accused,40 years later, just before election. Lieu is a marxist fool, <TARGET 1> supports him',\n",
       " '<TWEET>: A complicated question amid the <TARGET 1> allegations: Do we miss Gawker? URL URL',\n",
       " '<TWEET>: <TARGET 1> has a much more recognizable name to middle America',\n",
       " '<TWEET>: <TARGET 1> wasn\\'t \"cast out\" until after multiple times being caught. Hillary, who knew about his behavior, didn\\'t report. She was only concerned about how it would affect her campaign. Menendez and Bill still not \"cast out\". Kennedy was never \"cast out\". ',\n",
       " \"<TWEET>: Gal Gadot won't make 'Wonder Woman' sequel unless <TARGET 1> is out URL\",\n",
       " \"<TWEET>: Old Predators? Dems have 'em too but we punish ours when we find out, e.g. <TARGET 1>, <TARGET 2>, Louis, etc. You guys vote 'em into office. URL\\n\\n<QUOTED TWEET>: See? They're trying to delay an election until they can find a Republican who didn't try to fuck teenagers. URL\",\n",
       " \"<TWEET>: Judge <TARGET 1> Interview On Sean Hannity's Fox News Show!!! URL\",\n",
       " '<TWEET>: <TARGET 1> is facing a wave of criticism and national Republicans are bolting from his campaign  but will allegations of sexual misconduct matter in the Alabama Senate race? URL by @bridgetbhc',\n",
       " \"<TWEET>: The Batman - Official Teaser - <TARGET 1> 'Shadows of Gotham' 2019 Movie - (Fan Made): URL via @YouTube\",\n",
       " \"<TWEET>: Seeing Moretz in these photos with a boyfriend her own age reinforces how grossly sexualized <TARGET 1>'s depiction of her was in I LOVE YOU, DADDY. URL\",\n",
       " '<TWEET>: Love my Keurig and love that you pulled your advertising.of Hannity after awful <TARGET 1> comments. Thank u!',\n",
       " '<TWEET>: A complicated question amid the <TARGET 1> allegations: Do we miss Gawker? URL #SahelNews',\n",
       " '<TWEET>: Even In Sweden? Tracing the Worldwide <TARGET 1> Effect URL via @BillMoyers.',\n",
       " '<TWEET>: #TheNewYorkTimes  At least 20 high-profile men have been accused of sexual misconduct since the <TARGET 1> scandal URL',\n",
       " \"<TWEET>: Meanwhile, on the Left we see the same. From UK Daily Mail: <TARGET 1> said that the event 'simply did not occur' and he added that he does not know why the model has made these claims now, 36 years later.\",\n",
       " '<TWEET>: Ok but seriously, FUCK <TARGET 1>.',\n",
       " \"<TWEET>: STOP supporting pedophilia &amp; do the right thing &amp;stop sponsoring hate mongering @seanhannity #FireHannity #fireseanhannity Save&amp;share. When companies see their logos next 2 pedophiles, they don't like it.They take action.I have <TARGET 1> of these. #<TARGET 1>childmolester #fbr URL\",\n",
       " '<TWEET>: would make a far better Senator than <TARGET 1> (&amp; I know she is Israeli) URL',\n",
       " \"<TWEET>: Meanwhile, one year later in 1930's Germany, the media is expected to criticise the President and we now learn that <TARGET 1> asks first before he takes his dick out. URL\",\n",
       " \"<TWEET>: For one, <TARGET 1>'s allegations disappointed me. And two, <TARGET 2>'s recent allegations upset me. I liked both of these actors, but that doesn't excuse their behaviour...\",\n",
       " '<TWEET>: Actor <TARGET 1> accused of sexual assault by former actor, model URL',\n",
       " '<TWEET>: ignore admitted <TARGET 1> crime...',\n",
       " \"<TWEET>: Since you're entering whattaboutism: Did I miss your defense of <TARGET 1>, Bill Cosby or <TARGET 2>?\",\n",
       " '<TWEET>: Hoping that Gal Gadots recent statement that she wont do the sequel unless <TARGET 1> is not affiliated with the project will force a bit of self-reckoning.',\n",
       " '<TWEET>: fuck <TARGET 1> and his ugly ass apology riddled with nothing bit woe is me and narcissism.',\n",
       " '<TWEET>: Instead of debating whether or not #<TARGET 1> will make a comeback, lets check out the comedy of the many excellent women he admired enough to derail their careers.',\n",
       " '<TWEET>: Are women lesser beings incapable of protecting themselves and judging potentially risky situations? That seems to be the message. #<TARGET 1>',\n",
       " '<TWEET>: #<TARGET 1> was doing practical Jokes all this time URL',\n",
       " '<TWEET>: <TARGET 1> is the newest in sexual assault allegations, shocking but not shocking?',\n",
       " '<TWEET>: At least 20 high-profile men have been accused of sexual misconduct since the <TARGET 1> scandal broke. Our list: URL',\n",
       " '<TWEET>: Judge <TARGET 1> Maintains Double Digit Lead Over Democrat Doug Jones Before, After WaPo Smear #<TARGET 1>ChildMolester URL',\n",
       " \"<TWEET>: Shocked, I tell you, he's shocked.  #FeelMeUp<TARGET 1> URL URL\\n\\n<QUOTED TWEET>: <TARGET 1> Is Shocked By Sexual Assault Allegations URL URL\",\n",
       " \"<TWEET>: FALLEN CARDS...<TARGET 1> scandal: Report says 'everyone knew' about misconduct on 'House of Cards' set URL\",\n",
       " '<TWEET>: \"no one is defending <TARGET 1>\" _Many_ were silent about <TARGET 1>, for many years, despite many new fresh incidents to speak up about.',\n",
       " '<TWEET>: So, you think accusations of sexual assault is funny re Moore? Still waiting to see the <TARGET 1>/<TARGET 2> skits. SNL is a Democrat hack shop.',\n",
       " '<TWEET>: Thats fucking awesome. I mean, <TARGET 1> is out! Warner Bros. arent idiots. URL',\n",
       " '<TWEET>: Trumplings: <TARGET 1> is horrible and disgusting! We believe the accusers! Also Trumplings: <TARGET 2> would never! Those accusers are lying! Hypocrisy 101',\n",
       " '<TWEET>: In fact, I\\'ve hated <TARGET 1> before it was cool. I remember seeing PCU on Comedy Central like 20 years ago and thinking \"That guy\\'s an asshole in real life.\" #accidentalhipster',\n",
       " '<TWEET>: Gotta ask: Do women want to watch men masturbate? <TARGET 1> admits sexual misconduct allegations URL #JustAsking',\n",
       " '<TWEET>: <TARGET 1> sexual allegations ignite reaction from Hollywood URL',\n",
       " '<TWEET>: 14 year old cousin : *Looking at a dvd* Aw I love <TARGET 1> Me : Have you not heard whats been in the news about him? Cousin : Yeah but it doesnt matter, its probably not true Me : URL',\n",
       " '<TWEET>: Perspective: Now that <TARGET 1> on #sexual misconduct #allegations fake news URL',\n",
       " '<TWEET>: Saturday Night Live drags <TARGET 2>, lets <TARGET 1> off the hook URL',\n",
       " \"<TWEET>: Gal Gadot Says She Won't Do Another 'Wonder Woman' Movie If <TARGET 1> Is Involved URL URL\",\n",
       " \"<TWEET>: Brand New's <TARGET 1> Responds Following Claims He Solicited Nudes From A Minor -- #Bran... URL URL\",\n",
       " '<TWEET>: A Christian Response to the Allegations Against Judge <TARGET 1> - URL',\n",
       " '<TWEET>: Appreciation tweet to this <TARGET 1>ie thru thick and thin! Sabay pumasok, sabay ding lalabas??  Hbd <TARGET 1>!!! #KathleenDalawangDekada URL',\n",
       " '<TWEET>: This whole <TARGET 1> situation is very shitty. But I just want to say: no excuse is valid. Justice needs to be served. Enough of this.',\n",
       " '<TWEET>: Transgender actress decries fallout of <TARGET 1>s behavior URL Yeah, the trans are narcissistic selfish assholes.',\n",
       " '<TWEET>: I took out my <TARGET 1> and smacked her in the aeiou',\n",
       " '<TWEET>: <TARGET 1> Accused of Sexually Assaulting Former Model in 1981 URL',\n",
       " '<TWEET>: A complicated question amid the <TARGET 1> allegations: Do we miss Gawker? URL URL',\n",
       " \"<TWEET>: Pamela Adlon Is 'Devastated' After 'Friend &amp; Partner' <TARGET 1> Admits to Sexual Misconduct Claims URL via @yahoo\",\n",
       " '<TWEET>: Hats off to @Tobolowsky; this anecdote about <TARGET 1> is a slow and gentle burn with a fantastic pay-off. URL',\n",
       " '<TWEET>: Its not these bad men. Or that dirty industry. Its this inhumane economic system of which we are all a part #MeToo\\n\\n<URL TITLE>: <TARGET 2> and the Economics of Consent\\n<URL DESCRIPTION>: The blunt power of the gatekeeper is the ability to enforce not just artistic, but also financial, exile.',\n",
       " '<TWEET>: <TARGET 3>, <TARGET 2> and <TARGET 1> accused of sexual misconduct - The Washington Post URL',\n",
       " '<TWEET>: Best of Argentina @trapichewines #Ambrosia #malbec #<TARGET 1> #stand88 El Esteco #salta #calchaquivalley stunning #dondavid #torrontes #white &amp; #Altimus #cafayetevalley #redblend #malbec #cabernetsauvignon #cabernetfranc #luscious #stand89 #decanterfwe @landmarklondon @decanter URL',\n",
       " '<TWEET>: <TARGET 1> is Piloting the Kobayashi Maru URL URL',\n",
       " '<TWEET>: Top Gun star Anthony Edwards says he was molested by producer <TARGET 1> for years URL',\n",
       " '<TWEET>: Damn, somebody got the memo. When youve lost SNL etc. etc. Next week <TARGET 1> gets it in the neck. Drat! URL',\n",
       " \"<TWEET>: Yeah that too but it's <TARGET 1> I hate how closed and small they be lol\",\n",
       " '<TWEET>:  On the Gravity of What <TARGET 1> Did, and Why Minimizing It Is Harmful by @Shakestweetz URL',\n",
       " '<TWEET>: Una Lampara Dobles Tulipa De Pared Hierro. #DecoracionParaElHogar #<TARGET 1> #Lampara. URL URL',\n",
       " '<TWEET>: Oray ah <TARGET 1>. Singpet ken gaget nak gaminen',\n",
       " \"<TWEET>: From Rolling Stone - Brand New's <TARGET 1> Apologizes After Sexual Misconduct Allegations Surface URL #musicnews\",\n",
       " '<TWEET>: \"<TARGET 1>... never... held any power over me other Americans\" Those in the entertainment industry often wield tremendous amounts of power and influence over Americans.',\n",
       " \"<TWEET>: <TARGET 1> 'Shocked And Bewildered' By Former Model's Sexual Assault Allegation URL via @yahoo\",\n",
       " \"<TWEET>: NYT missed Anthony <TARGET 2>. I know he's pre-<TARGET 1>. But he's a multiple offender. Husband of Huma Abedein. Former Dem US Rep from NY &amp; NYC Mayoral candidate. He's also an inmate at the Federal Prison in Ft Devens MA. Just an FYI!\",\n",
       " '<TWEET>: ppl hellbent on defending/forgiving assholes like <TARGET 1> like we running out of comedians. long as we have Wanda Sykes we good. need no one else really',\n",
       " \"<TWEET>: Brand New's <TARGET 1> Apologizes After Sexual Misconduct Allegations Surface URL\",\n",
       " '<TWEET>: <TARGET 1> will be made out as the victim',\n",
       " '<TWEET>: JUST IN: WaPo Reporter Who Broke News On Judge <TARGET 1> Story Has A Criminal History Of Faking *... URL',\n",
       " '<TWEET>: Gal Gadot refusing Wonder Woman sequel over accused sex harasser <TARGET 1> involvement URL #ToughWomen',\n",
       " \"<TWEET>: Yes. I've supported Judge <TARGET 1> since the beginning of his tribulations in AL, being politically and legally assaulted continuously by anti-Christs pushing godless society (pagan gods were OK). <TARGET 1> stood by his principles, at the expense of his career; a rare man.\",\n",
       " \"<TWEET>: Brand New's <TARGET 1> Apologizes After Sexual Misconduct Allegations Surface URL\",\n",
       " '<TWEET>: Karma? Someone says they were violated, have some respect for them no matter how much you want to rub it in <TARGET 1>s/liberals faces. Sexual assault/assault crosses all the self-imposed boundaries.',\n",
       " '<TWEET>: <TARGET 1>s Public Statement Unnervingly Misunderstands the Concept of Consent URL',\n",
       " '<TWEET>: All men have a responsibility to work towards fixing the myriad of underlying problems that have enabled and protected men like Moore, <TARGET 1>, Cosby and Trump for centuries. Not as saviors or vengeful daddy figures but as allies and partners.',\n",
       " '<TWEET>: In the wake of <TARGET 1>, some women say Bollywood failing to address harassment - Reuters URL #FansnStars URL',\n",
       " '<TWEET>: <TARGET 1> Accused Of Sexual Harassment By LA-Based Writer - URL #GoogleAlerts',\n",
       " '<TWEET>: AMERICANS~Republican &amp; Democrat &amp; Independant Voters~Some of you are uninformed about certain things such as not knowing your constitutional rights, about Alinsky, Cloword <TARGET 1>, Agenda 21 &amp; more, so you innocently, ignorantly vote in Anti-Constitutionalists. STUDY! @COSProject ! URL',\n",
       " \"<TWEET>: <TARGET 1> blasted by woman's lawyer: 'He knows full well' why the women kept quiet - ABC News URL\",\n",
       " \"<TWEET>: So I never got around to watching Wonder Woman because I'm hella jaded on comic superhero movies, but the Gal Gadot / <TARGET 1> thing has me concerned in a way I haven't seen brought up -that- much.\",\n",
       " '<TWEET>: Interesting contrast in how power is used by a women. Love it! Gal Gadot may not return for Wonder Woman 2 if <TARGET 1> is involved URL',\n",
       " \"<TWEET>: I think Wiener has been legally convicted. Until <TARGET 1> has been legally convicted it's just rumor and accusations. Why can't the left have consistency in their arguments? Plus the voters of Alabama get to decide if Moore get's elected or not. Not us.\",\n",
       " '<TWEET>: Gal Gadot is threatening to walk away from Wonder Woman unless <TARGET 1> is axed URL',\n",
       " '<TWEET>: If an abuser was working in most other industries, he woulnt have got away with it as long as <TARGET 1> did. Its part of hollywood &amp; everyone turned a blind eye to it.',\n",
       " \"<TWEET>: How <TARGET 1>'s Comedy Has Uncomfortably Mirrored The Sexual Misconduct Claims Against Him URL via @Digg\",\n",
       " '<TWEET>: <TARGET 1>s Army of Spies URL',\n",
       " \"<TWEET>: <TARGET 1>: Expect 'revelations' about motivations behind Post article soon URL\",\n",
       " '<TWEET>: He looks like <TARGET 1> URL',\n",
       " '<TWEET>: I am sure you said the same abt <TARGET 1>.',\n",
       " \"<TWEET>: Gal Gadot Says She Won't Do Another 'Wonder Woman' Movie If <TARGET 1> Is Involved URL #Wonder_Woman #Gal_Gadot #Brett_<TARGET 1> #Entertainment #Entertainment URL\",\n",
       " '<TWEET>: Kellyanne Conway on <TARGET 1> allegations: If true, that conduct is disqualifying URL URL',\n",
       " \"<TWEET>: Brand New's <TARGET 1> Apologizes After Sexual Misconduct Allegations Surface URL\",\n",
       " '<TWEET>: Wait, what happened with <TARGET 1>?',\n",
       " '<TWEET>: When #seanhannity justified <TARGET 1>s sexual molestation of a 14-year-old girl by claiming it was consensual, he crossed a line that should NEVER be crossed. Nobody who defends a child molester should have a national platform +Fox News should fire Hannity now! #FireHannity',\n",
       " '<TWEET>: \"SNL Asks GOP: After Allegations Against <TARGET 1>, How Low Can It Go?\" #politics #feedly URL',\n",
       " '<TWEET>: Kansas <TARGET 1> announces first debate scheduled for February',\n",
       " '<TWEET>: <TARGET 1> and Michael Jackson once tried opening up kiddie attractions together. URL',\n",
       " '<TWEET>: Saturday Night Live Takes on <TARGET 1>s Allegations.. Related Articles: URL',\n",
       " '<TWEET>: The Libs are proven guilty and are found innocent! Libs have rigged the laws to protect themselves from crimes! As <TARGET 1>s contract! SAME!',\n",
       " '<TWEET>: Found a pet sidekick for #<TARGET 1>. URL',\n",
       " '<TWEET>: Power is neither good or bad, it is simply a tool, Id rather the good guys have it. In the hands of someone like the Dalai Lama, its going to be used well, and not to hurt people. In the hands of <TARGET 1>, maybe not. #GeneSimmons in new book \"Gene Simmons on Power\" URL',\n",
       " \"<TWEET>: Brand New's <TARGET 1> Apologizes After Sexual Misconduct Allegations Surface URL\",\n",
       " '<TWEET>: At The Governors Awards, <TARGET 1> Remains The Elephant In The Room URL via @adambvary',\n",
       " '<TWEET>: Brand New Frontman <TARGET 1> Responds to Accusation of Sexual Misconduct URL URL',\n",
       " '<TWEET>: <TARGET 1> Admitted To Sexually Harassing Men On A Howard Stern Podcast URL via @YouTube',\n",
       " \"<TWEET>: Dear Women who Voted for Trump.Please don't act appalled about <TARGET 1>.The man you voted into office was caught on tape bragging about doing the same,&amp; still got your vote.Shame On You.\",\n",
       " '<TWEET>: Also <TARGET 1> the lead singer of Brand New',\n",
       " '<TWEET>: I liked a @YouTube video URL Sour Shoes Voicemails feat <TARGET 1> &amp; Baba Booey',\n",
       " '<TWEET>: I think so? But I havent seen any stories on it in the post-<TARGET 1> context.',\n",
       " '<TWEET>: Brand New frontman <TARGET 1> has been accused of sexual misconduct with a minor URL via @UPROXX',\n",
       " '<TWEET>: Hollywood should do a remake of the Lord of the Rings trilogy starring <TARGET 1> as Frodo where the Eye of Sauron watches him jack off.',\n",
       " '<TWEET>: Richard JohnsonModel accuses <TARGET 1> of masturbating in front of her URL',\n",
       " '<TWEET>: This entire statement is worth reading: @amjoyshow <TARGET 1> Responds to Accusations: These Stories Are True URL',\n",
       " '<TWEET>: And yet none of the <TARGET 1> allegations have changed my opinion of Alabama in the slightest.',\n",
       " \"<TWEET>: How 'Saturday Night Live' Joked About <TARGET 1> URL URL\",\n",
       " '<TWEET>: Gal Gadot Reportedly Is Threatening To Pull Out Of Wonder Woman 2 Unless <TARGET 1> Is Removed URL',\n",
       " '<TWEET>: A complicated question amid the <TARGET 1> allegations: Do we miss Gawker? - Theblogweb <TARGET 1> ... - URL URL',\n",
       " '<TWEET>: <TARGET 1> was touchy feely with all the little boys in Hollywood smfh',\n",
       " '<TWEET>: Gal Gadot will only be Wonder Woman again if <TARGET 1> is out URL',\n",
       " \"<TWEET>: <TARGET 1>'s feeble apology that doesn't even address the elephant in the room. People in the comments calling the girl a liar. Other people in the comments asking where their Science Fiction vinyl is. A few reasons why I don't like things right now.\",\n",
       " \"<TWEET>: When you've said <TARGET 1> is a shit person for years &amp; it turns out he actually is a shit person. URL\",\n",
       " '<TWEET>: I think he was posting defense of <TARGET 1>. What he did to me probably never even registered for him.',\n",
       " \"<TWEET>: Until <TARGET 1> acknowledges the whole underage stuff, until he apologies DIRECTLY to those involved, that apology means nothing. The hole is only gonna get deeper for him. It's grim and disappointing, and whilst i'm not so shocked by this stuff anymore, it's still sad to see.\",\n",
       " \"<TWEET>: Bold Prediction: <TARGET 1> will win by double digits. I mean, come on...it's frickin' Alabama.\",\n",
       " \"<TWEET>: Brand New's <TARGET 1> Apologizes After Sexual Misconduct Allegations Surface URL\",\n",
       " '<TWEET>: Brand New Frontman <TARGET 1> Responds to Accusation of Sexual Misconduct URL URL',\n",
       " '<TWEET>: After <TARGET 1>: A List of Men Accused of Sexual Misconduct and the Fallout for Each URL URL',\n",
       " '<TWEET>: Aaah. <TARGET 1> is garbage but we all knew that right?',\n",
       " '<TWEET>: For Saturday Night Live, No Shortage of Targets, Including <TARGET 1> and <TARGET 2>. URL',\n",
       " '<TWEET>: Yet <TARGET 1>, the rapist, got a pass because it was a \"New York thing\"',\n",
       " \"<TWEET>: It's not like he <TARGET 1>'d them. And he didn't Bill Cosby them either... he asked to jerkoff off and they watched. If they were truly offended get up and leave.\",\n",
       " \"<TWEET>: .@CNN aka CommieNewsNetwork never gave any serious coverage to one of theirs, <TARGET 1>! Those women apparently don't matter, even though they came out unprovoked. The women that DO MATTER are those accusing @MooreSenate, unproven and just before the election. #CommieAlert URL\",\n",
       " \"<TWEET>: Music News:Brand New's <TARGET 1> Apologizes After Sexual Misconduct Allegations Surface URL\",\n",
       " '<TWEET>: <TARGET 1> denies sexually assaulting model in 1981 URL #pdx',\n",
       " '<TWEET>: DC Artist Rafael Albuquerque Sounds Off On <TARGET 1> Allegations URL URL',\n",
       " '<TWEET>: <TARGET 1> Denies Accusations That He Groped Model in 1981 URL',\n",
       " \"<TWEET>: Brand New's <TARGET 1> Apologizes After Sexual Misconduct Allegations Surface URL\",\n",
       " '<TWEET>: Comics industry reacts to <TARGET 1> suspension: I Reads You: I Reads You Juniors October 2017 - Update #29 URL',\n",
       " \"<TWEET>: Wonder Woman was great &amp; deserved to do well but DC have been more miss than hit &amp; could still mess things up before its squeal. We still don't know if <TARGET 1> will stay as Batman &amp; the early JusticeLeague reviews are calling it slightly above average. URL\",\n",
       " '<TWEET>: New article (Kasich: <TARGET 1> Should Step Aside  Everything in Life Cant Be About Who Wins an Election) has been published on The Daily Digest - URL URL',\n",
       " '<TWEET>: VIDEO | Miguel Nacho <TARGET 1> regres a Miami URL URL',\n",
       " '<TWEET>: VIDEO | Miguel Nacho <TARGET 1> regres a Miami URL',\n",
       " '<TWEET>: Fuck you bro leave <TARGET 1> out of all of this',\n",
       " '<TWEET>: <TARGET 1> scandal: Senate victory would be toxic for religious right URL',\n",
       " '<TWEET>: A complicated question amid the <TARGET 1> allegations: Do we miss Gawker? URL',\n",
       " '<TWEET>: Pedro <TARGET 1> #Mugshot\\n\\n<URL TITLE>: Pedro O <TARGET 1> Arrest Mugshot Virginia 2017-11-12\\n<URL DESCRIPTION>: Pedro O <TARGET 1> Arrest Mugshot Virginia 2017-11-12',\n",
       " '<TWEET>: #metoojustice URL\\n\\n<QUOTED TWEET>: At least 20 high-profile men have been accused of sexual misconduct since the <TARGET 2> scandal broke. Our list: URL',\n",
       " '<TWEET>: nytimes: At least 20 high-profile men have been accused of sexual misconduct since the <TARGET 1> scandal broke. Ou URL',\n",
       " \"<TWEET>: Don't remember *any* elected dems defending <TARGET 1>. A whole lot of elected and party officials are currently defending Moore.\",\n",
       " \"<TWEET>: I've written on here how much Brand New means to me so it's only fair to say that this news of <TARGET 1> is hard to hear but his apology was bullshit and he can go fuck himself. He hurt a lot of ppl in a broad sense but specifically a minor. That's monsterous &amp; so is he.\",\n",
       " '<TWEET>: <TARGET 1> took long enough to post his beautifully crafted apology, he is just trying to cover his A$$ URL\\n\\n<QUOTED TWEET>: Everyone applauding <TARGET 1> \"owning up\" in apology: he did it because NYT report and women going on the record forced him to. Here he is, just two months ago: Theyre rumors, thats all that is. URL URL',\n",
       " '<TWEET>: <TARGET 1> Shocked and Bewildered by Sexual Assault Allegations - URL #GoogleAlerts',\n",
       " '<TWEET>: It took me 40 years to tell my #metoo story @SenToomey Are you calling me a liar? URL URL\\n\\n<QUOTED TWEET>: \"It raises a question about the credibility... when someone waits for 40 years, that raises the credibility of the accusation itself,\" @SenToomey on accusations of sexual misconduct against AL Senate race candidate <TARGET 2>. #MTP',\n",
       " \"<TWEET>: We are discussing <TARGET 1>. Regardless of what Adam may have done (which isn't the fucking conversation and you're just projecting) Jesse got called out for years and nobody took Adam seriously. Stop it. Save the TBS pitchfork for another day.\",\n",
       " '<TWEET>: One was pre-<TARGET 1>, the other was post-<TARGET 1>.',\n",
       " '<TWEET>: Are you kidding? Remember, a <TARGET 1> skit would be rude. Its a NY thingy.',\n",
       " \"<TWEET>: Gal Gadot Says She Won't Do Another 'Wonder Woman' Movie If <TARGET 1> Is Involved URL URL\",\n",
       " '<TWEET>: URL @<TARGET 1> is a leading critic of Trump. Is it any wonder that this flimsy accusation should come up now?',\n",
       " '<TWEET>: Trans actress Jen Richards lost a role because of <TARGET 1>s sexual harassment URL URL',\n",
       " '<TWEET>: Ok, sure...by your reasoning then, <TARGET 1>, <TARGET 2>, etc, etc are all perfectly innocent and clearly being persecuted. Glad to see your defense of the Hollywood liberals. ',\n",
       " '<TWEET>: A lot of white male liberals are coming to the defense of <TARGET 1>. I get it. I really do. How about this though?... URL',\n",
       " '<TWEET>: Its <TARGET 1> not *Ray <TARGET 1>',\n",
       " '<TWEET>: Never liked <TARGET 1>\\'s work or thought he was funny. Never saw what the draw was with him. Now I realize my \"predator\" radar is intact.',\n",
       " \"<TWEET>: Brand New's <TARGET 1> Apologizes After Sexual Misconduct Allegations Surface - URL #nowplaying #KEXP #internetradio...\",\n",
       " '<TWEET>: Letters from Cicely by Ellis <TARGET 1> - book based on Northern Exposure TV series. V funny!',\n",
       " \"<TWEET>: Brand New's <TARGET 1> Apologizes After Sexual Misconduct Allegations Surface URL\",\n",
       " \"<TWEET>: The thing this days is 'I will do anything to get the job' and then I will cry about it when it's convenient to advance my career. #<TARGET 1>\",\n",
       " '<TWEET>: Its only one poll but @GDouglasJones gets a small lead against <TARGET 1> URL',\n",
       " '<TWEET>: Everyone talking <TARGET 2>, Kevin Spacy, <TARGET 1>, and the rest of the scumbags. Add Joe Biden to that list! URL',\n",
       " '<TWEET>: Also has Hayes asked his bosses why they buried the <TARGET 2> stories? Did he not see <TARGET 1> acting like a creep off camera. This is just Clinton bashing',\n",
       " '<TWEET>: An actress claims <TARGET 1> raped her in New York City on two occasions. URL',\n",
       " '<TWEET>: <TARGET 1>s Public Statement Unnervingly Misunderstands the Concept of Consent URL',\n",
       " '<TWEET>: Its not these bad men. Or that dirty industry. Its this inhumane economic system of which we are all a part #MeToo\\n\\n<URL TITLE>: <TARGET 2> and the Economics of Consent\\n<URL DESCRIPTION>: The blunt power of the gatekeeper is the ability to enforce not just artistic, but also financial, exile.',\n",
       " '<TWEET>: Watch: Republicans rabidly applaud <TARGET 1> as he attacks his accusers URL via @shareblue',\n",
       " '<TWEET>: Its becoming a witch hunt, and while I absolutely agree that sexual predators like <TARGET 1> should be called out publicly on their lewd disgusting behaviour, theres gonna be those who just want to get their 15 minuets.',\n",
       " '<TWEET>: For years <TARGET 1> was only able to get women based on who he was... via /r/Jokes URL',\n",
       " '<TWEET>: Trans actress Jen Richards lost a role because of <TARGET 1>s sexual harassment URL',\n",
       " '<TWEET>: Brand News <TARGET 1> Apologizes for Sexual Misconduct URL URL',\n",
       " '<TWEET>: should be behind bars next to anthony <TARGET 1>, not running for Senate.',\n",
       " '<TWEET>: Idk, having grown up around the scene or whatever you wanna call, I feel like already knew about the <TARGET 1> thing and also like it was REALLY common with guys in emo bands, regardless of popularity.',\n",
       " '<TWEET>: <TARGET 1> is a pervert, not a predator  a big difference URL',\n",
       " '<TWEET>: He also did all of <TARGET 1>s stunts in Marathon Man.',\n",
       " \"<TWEET>: David Edelstein on <TARGET 1>'s film you probably won't see URL via @cbsnews\",\n",
       " \"<TWEET>: How 'Saturday Night Live' Joked About <TARGET 1> URL\",\n",
       " '<TWEET>: While this is awesome &amp; I applaud Gal Gadot for taking a stand, why wasn\\'t she offered a multi film contract like every other person who stars in a superhero movie? @wbpictures #WonderWoman #get<TARGET 1>out URL\\n\\n<QUOTED TWEET>: EXCLUSIVE: Gal Gadot will only sign on for a \"Wonder Woman\" sequel if accused sexual harasser <TARGET 1> is completely removed from the franchise URL',\n",
       " '<TWEET>: So, in light of the news about <TARGET 1>, what exactly does Illumination Entertainment aim to do about The Secret Life of Pets 2 (The Sequel Life of Pets) in which he voices the main character of the franchise?',\n",
       " '<TWEET>: After <TARGET 1>: A List of Men Accused of Sexual Misconduct and the Fallout for Each URL URL',\n",
       " '<TWEET>: Irony - Lib idol Obama does it, its comedy; COMEDIAN <TARGET 1> does it, the reporters dont giggle. URL',\n",
       " '<TWEET>: Its not these bad men. Or that dirty industry. Its this inhumane economic system of which we are all a part #MeToo\\n\\n<URL TITLE>: <TARGET 2> and the Economics of Consent\\n<URL DESCRIPTION>: The blunt power of the gatekeeper is the ability to enforce not just artistic, but also financial, exile.',\n",
       " '<TWEET>: Gal Gadot threatening to leave DC Universe if <TARGET 1> remains involved. She is awesome. Wonder Woman equals best out there for superhero franchises.',\n",
       " \"<TWEET>: You have zero credibility on this issue. You've retweeted multiple tweets disparaging <TARGET 4>, <TARGET 2>, <TARGET 1>, and <TARGET 3> for their alleged sexual abuse-with no tangible evidence and no trial in a court of law-but for <TARGET 5>, you need tangible evidence? You're a sham.\",\n",
       " \"<TWEET>: FYI, there are far more people than I'd like to believe defending <TARGET 1>. I hate planet Earth.\",\n",
       " \"<TWEET>: <TARGET 1> Denies Years of Harassment and Exposing Himself to Journalist: 'I Flirted With All Women' URL\",\n",
       " \"<TWEET>: Hey, @MyPillowUSA, as a mother, I'm appalled that you're advertising with @seanhannity, who supports and defends the pedophile <TARGET 1>!\",\n",
       " '<TWEET>: A complicated question amid the <TARGET 1> allegations: Do we miss Gawker? URL',\n",
       " '<TWEET>: EVERYONE knows that \"liberal media\" reports on Dems also!!! (<TARGET 1>, Clinton)....These stories are real news, not FAKE news. Fox is fake news. Denial, denial, denial for Republicans only!!!!!!!!',\n",
       " \"<TWEET>: I disagree that what Tarantino is saying it's any better. He's just smarter about knowing what will garner the most sympathy for him. He hasn't committed to changing and even called <TARGET 1>. Why would you do that?\",\n",
       " '<TWEET>: friendship over relationship or vice versa? i need ur help pls.  both <TARGET 1> URL',\n",
       " \"<TWEET>: You aren't even an American. You have no opinion. Stop trolling me you stalker. You are no better then <TARGET 1> you freak\",\n",
       " \"<TWEET>: Brand New's <TARGET 1> Apologizes After Sexual Misconduct Allegations Surface URL URL\",\n",
       " '<TWEET>: <TARGET 1> Denies Accusations That He Groped Model in 1981 URL',\n",
       " '<TWEET>: Trans actress Jen Richards lost a role because of <TARGET 1>s sexual harassment URL URL',\n",
       " '<TWEET>: Gal Gadot Says She Wont Do Another Wonder Woman Movie If <TARGET 1> Is Involved URL URL',\n",
       " '<TWEET>: Go back to jacking off to <TARGET 1> movies.',\n",
       " '<TWEET>: What do you have to say about your \"friend\",<TARGET 1>,who has been accused by Anthony Edwards of molestation?Michael Egan may be in jail for an unrelated offense but Collins-Rector\\'s conviction,settlement and now this gives a helluva lot of credence to his accusations.',\n",
       " '<TWEET>: <TARGET 1>, that is.',\n",
       " '<TWEET>: <TARGET 1> is innocent until proven guilty by four Alabama women and thirty witnesses bravely going public with their experiences with a sexual predator while they were teenagers in a backward State.',\n",
       " \"<TWEET>: I don't know why would #Republicans elect one to be the POTUS #democrats pervs punished as anthony <TARGET 3> is looking for penpals in prison.clinton impeached.<TARGET 2>&amp;<TARGET 1> out of job-hope for good #republicans pervs elected to the WH and senate #weird moral decay URL\",\n",
       " \"<TWEET>: Why couldn't DC have suspended or fired <TARGET 1> when this shit was actually going on 5 years ago?\",\n",
       " '<TWEET>: <TARGET 1> ',\n",
       " \"<TWEET>: Don't matter. <TARGET 1> is a criminal in many other ways.\",\n",
       " \"<TWEET>: How about you pray for <TARGET 1>'s victims?\",\n",
       " '<TWEET>: God Bless President Trump &amp; the Filthy Democrat party of proven sexual Predators Bill Clinton, <TARGET 1>, Anthony <TARGET 3>, <TARGET 2> that fabricated 40 year old lies about Judge Moore should be banned &amp; broken up!',\n",
       " '<TWEET>: Ryan Gosling and More Hollywood Men Who Have Spoken Out Against <TARGET 1> URL via @yahoo',\n",
       " '<TWEET>: Franklin Graham: Im Praying for <TARGET 1> and His Family URL\\n\\n<QUOTED TWEET>: Im praying for <TARGET 1> and his family. URL',\n",
       " '<TWEET>: Zeke, <TARGET 1>, <TARGET 2>, <TARGET 3>, and <TARGET 4> all in a circle praising the great spirit',\n",
       " \"<TWEET>: Things you never read when the far broader instances of <TARGET 1>'s abuse broke. URL\\n\\n<QUOTED TWEET>: SNL pummels embattled Senate candidate <TARGET 2> over accusations he preyed on girls in the 1970s URL\",\n",
       " \"<TWEET>: <TARGET 1> and Jesus's parents what's the difference? Jesus Parents and <TARGET 1>s Gall URL\",\n",
       " '<TWEET>: They kept their mouths shut for years and yet they now have the audacity to pontificate to the rest of us during the kickfest on <TARGET 1>.',\n",
       " \"<TWEET>: <TARGET 1>'s bedroom #WeirdPlacesToFindWaldo\",\n",
       " '<TWEET>: The admin turned out to be a pedo ofcourse, the <TARGET 1> effect is in full swing',\n",
       " '<TWEET>: APA Agent <TARGET 1> Fired From Agency Following Sexual Assault Allegations URL',\n",
       " \"<TWEET>: If I missed something feel free to correct me but what was so controversial about <TARGET 1>'s statement?\",\n",
       " '<TWEET>: Hahahahahahaha yung madaling makalasing <TARGET 1>',\n",
       " '<TWEET>: WHY is <TARGET 1> not in jail????',\n",
       " '<TWEET>: oh i know <TARGET 1> ',\n",
       " '<TWEET>: Wampiry lewicy: <TARGET 1> z Hollywood... I Veronika Rossati URL',\n",
       " '<TWEET>: #JuddApatow Goes After #Tarantino For Staying Silent About #<TARGET 1> URL',\n",
       " '<TWEET>: <TARGET 1> thing also shows dynamic of patriarchy cuts across race and class.',\n",
       " '<TWEET>: #Globalism #BushIsAGlobalist #GeorgeWBush #Soros #NewWorldOrder #WIsAGlobalist #UnitedNations #UN #EuropeanUnion #EU #<TARGET 1> URL\\n\\n<QUOTED TWEET>: When I look at this photo, I see no party, I see no distinction between them. I see 5 bought and paid for Globalists whove been selling out America for the last 40 some years. Thank God for Trump  URL',\n",
       " '<TWEET>: <TARGET 1> he tried to talk to you and you wouldnt listen and instead sent in your bitchy mates? #MAFSNZ',\n",
       " '<TWEET>: All these male photographers are like <TARGET 1> on Twitter. Genetic mutation.',\n",
       " '<TWEET>: Everyone likes Luke except for his wife, <TARGET 1>',\n",
       " '<TWEET>: #<TARGET 1> seemed to fit right in. This is a form of liberalism that routinely blends self-righteousness with upper-class entitlement URL\\n\\n<QUOTED TWEET>: What <TARGET 1> tells us about the liberal world URL by @thomasfrank_ #rbnews #patriarchy #liberalism URL',\n",
       " '<TWEET>: Directors guild files disciplinary charges against <TARGET 1> URL URL',\n",
       " '<TWEET>: The <TARGET 1> allegations are monstrous. But its not just monsters who harass women URL',\n",
       " '<TWEET>: More than 40 women have accused the 65-year-old <TARGET 1> of harassment or abuse. URL',\n",
       " '<TWEET>: Fabulous opportunity for #women! .@Amazon: Search For Potential <TARGET 1> Replacement Focuses On Female Execs URL',\n",
       " '<TWEET>: #cinephiletweets #cinephiles <TARGET 1> accuser was scared to go public URL',\n",
       " '<TWEET>: #<TARGET 1> URL\\n\\n<QUOTED TWEET>: BREAKING: After Just 1 Week, #<TARGET 1> Leaves Sex Rehab Claiming \"I\\'m Cured\"... Why I Hate Pompous Hollywood Jerks #BoycottHollywood URL',\n",
       " \"<TWEET>: <TARGET 1>, Rape Accuser's Lawyer Touts New Client on Website - URL #starbuzz\",\n",
       " '<TWEET>: <TARGET 1> Jon Voight Midnight Cowboy Signed 11x14 Photo AFTAL #autographs URL URL',\n",
       " '<TWEET>: #MAFSNZ was <TARGET 1> just talking about herself ? ',\n",
       " \"<TWEET>: And NorthKorea!!!! Don't forget #NorthKorea #Hitler #Osama #loki #Spectra and #<TARGET 1>. All of them support the evil catalonians!!!\",\n",
       " '<TWEET>: Retweeted Vulture (@vulture): Update: <TARGET 1> has responded to Nyongos claim, saying he \"has a different... URL',\n",
       " '<TWEET>: Oh dear <TARGET 1>, you have no idea what marriage means #MAFSNZ',\n",
       " '<TWEET>: Which party was <TARGET 1> at where all this time to explain occured? #MAFSNZ',\n",
       " '<TWEET>: Youve all had 2 suffer? OReilly u &amp; @realDonaldTrump, <TARGET 1>, Bolling, Ailes, Cosby should all get together for a pity party then, STFU',\n",
       " '<TWEET>: <TARGET 1> faces 3 new accusers URL URL',\n",
       " \"<TWEET>: why don't you talk about <TARGET 1>?\",\n",
       " '<TWEET>: Also they always want to dominate the stage.<TARGET 1> thg exemplifies issue. Talking about men this/that. Just listen and shut up',\n",
       " '<TWEET>: So other late night hosts have been mum about <TARGET 1>? Which makes them? Complicit? Not Samantha Bee. #monologue URL',\n",
       " \"<TWEET>: Film Alert 101: Kicking a man when he's down - <TARGET 1> ge... URL\",\n",
       " '<TWEET>: Jackie Mason Blasts Hollywoods Phony F*cks: All <TARGET 1> Did Was Imitate Bill Clinton (Exclusive) URL URL',\n",
       " '<TWEET>: <TARGET 1> URL',\n",
       " \"<TWEET>: I agree it may be racism but it also may be because Nyong'o exudes dignity, brilliance and credibility and threatens <TARGET 1>.\",\n",
       " '<TWEET>: My pain is everyday: After <TARGET 1>s fall, Trump accusers wonder: Why not him? URL',\n",
       " '<TWEET>: Many wonder how <TARGET 1> could be brought down, while prez remains untouched. URL #TrumpHaiku #TrumpSexualAbuse',\n",
       " '<TWEET>: After <TARGET 1>s fall, Trumps accusers wonder: Why not him? - URL URL',\n",
       " '<TWEET>: Will you talk about OReilly paying 32 million and Fox/hosts complicitness and hypocrisy on billO v <TARGET 1> /hating Hollywood #antivicatty',\n",
       " '<TWEET>: <TARGET 1> has different recollection of events on Lupita Nyongo claims URL',\n",
       " '<TWEET>: Besides that, as it can be noted, objectively Mr. <TARGET 1> is not a witch ]',\n",
       " \"<TWEET>: No it hasn't. The courts in FL are even thinking about opening the records too. Why do people believe <TARGET 1> is guilty but not Trump?\",\n",
       " '<TWEET>: I feel like <TARGET 1> is like a broken record #MAFSNZ',\n",
       " '<TWEET>: <TARGET 1>',\n",
       " '<TWEET>: <TARGET 1> was international! URL\\n\\n<QUOTED TWEET>: A Russian film executive says <TARGET 1> sexually harassed her at film festivals URL',\n",
       " '<TWEET>: What <TARGET 1> tells us about the liberal world URL by @thomasfrank_ #rbnews #patriarchy #liberalism URL',\n",
       " '<TWEET>: Lauren Sivan says <TARGET 1> once forced her to watch him masturbate (video) URL URL',\n",
       " '<TWEET>: Amazon deals !!! URL #toyspotting #toys #lettoysbetoys #amazontoys #Toys #toyspotting #Yankees #SundayBrunch #<TARGET 1> URL',\n",
       " \"<TWEET>: I'll take you Luke...and so will the other 99.99% of Kiwi ladies out there. <TARGET 1> is a DICK for treating you this way. #mafsnz\",\n",
       " '<TWEET>: A Russian film executive says <TARGET 1> sexually harassed her at film festivals URL',\n",
       " '<TWEET>: After <TARGET 1>s fall, Trumps accusers wonder: Why not him? - URL URL',\n",
       " \"<TWEET>: Well if it isn't the leader of the <TARGET 1> patrol, boning up on his nerd lessons! -- Homer Simpson Boy-Scoutz n the Hood #Simpsons\",\n",
       " \"<TWEET>: Ex-chauffeur says woman begged <TARGET 1> 'not to hurt her' URL\",\n",
       " '<TWEET>: Careful Luke....the cat may be a plant by Bel to spy on you for <TARGET 1>. #MAFSNZ',\n",
       " '<TWEET>: Breaking? <TARGET 1> URL',\n",
       " '<TWEET>: Id be surprised if <TARGET 1> ever finds anyone after this. The dude would need his head read for going anywhere near her! #MAFSNZ',\n",
       " \"<TWEET>: OMG <TARGET 1>. You can't complain and say Luke didn't talk to you. He tried, and you said no. Aaarrrggghhh. #MAFSNZ\",\n",
       " '<TWEET>: We  Luke. We just hate the growth on his side...called <TARGET 1> #MAFSNZ',\n",
       " '<TWEET>: was it a review? Does <TARGET 1> have syphilis? Does the author want more Instagram followers? Should I go see Reece W in Home Again?',\n",
       " '<TWEET>: Hmm.. Gotta question the timing, heh. #Pedogate #<TARGET 1>',\n",
       " '<TWEET>: #<TARGET 1> #clinton #Obama #Soros #Hollywood #NewWorldOrder #Globalism URL',\n",
       " '<TWEET>: <TARGET 1> Fully Exposed | My Involvement With The Scandal URL via @YouTube',\n",
       " \"<TWEET>: <TARGET 1>. Darling. Let me stop you right there. These 'scientists' don't know shit about ANYTHING, but you could be less of a cow #MAFSNZ\",\n",
       " '<TWEET>: New York trends now: alcs, Long Island, Anthem, Bronx, <TARGET 1>. URL',\n",
       " '<TWEET>: More Actors Accuse <TARGET 1> of Coercion and Assault URL via Yahoo!',\n",
       " \"<TWEET>: I mean <TARGET 1> I want to listen to what you're saying but also how did you make SUCH a mess of your hotel room #MAFSNZ\",\n",
       " '<TWEET>: <TARGET 1> has allegedly continued to sexually harass women after going sober URL',\n",
       " '<TWEET>: Does <TARGET 1> have an allergic reaction to kindness rn? #MAFSNZ',\n",
       " '<TWEET>: That @FlyAirNZ Elite tag much <TARGET 1> #MAFSNZ ?',\n",
       " '<TWEET>: Someone has a serious touch of static going on today!!! #<TARGET 1> #<TARGET 1>kate #statichair #hair URL',\n",
       " '<TWEET>: Dusclops - 73.3 (10/13/10) - <TARGET 1> Estates. 02:07:42am (1m 56s). URL',\n",
       " '<TWEET>: <TARGET 1> is extremely irritating #mafsnz',\n",
       " '<TWEET>: Still amazes me that <TARGET 1> is crucified while Trump was elected leader. Two predators, diametrically opposing reactions #trumpsucks',\n",
       " '<TWEET>: Sky Views: And the Oscar for most sanctimonious <TARGET 1> reaction goes to... URL',\n",
       " '<TWEET>: Trump voters believe sex allegations against <TARGET 1>, but not against Trump URL via @HuffPostPol',\n",
       " '<TWEET>: <TARGET 1> Faces 3 New Accusers, All Former Fashion Models URL #fashionweek #voguemagaz URL',\n",
       " '<TWEET>: ... #History #Occult #SocialEngineering #Pedogate #Censorship #sextrafficking #TopNews #<TARGET 1> ... URL',\n",
       " \"<TWEET>: #Cine  Rose McGowan's tweet suggests a poetic justice for <TARGET 1>'s poison - The Guardian URL #IsabelleHuppert\",\n",
       " \"<TWEET>: Since you didn't get any big movie rolls, can I guess your one of the few actresses who didn't suck <TARGET 1>'s dick??\",\n",
       " '<TWEET>: This whole <TARGET 1> thing makes me feel so gross inside b/c as a tiny lady server person, I am basically THE PRIME TARGET for this sort of shit.',\n",
       " '<TWEET>: #HollywoodNews Los Angeles police investigating <TARGET 1> in 2013 sexual assault allegation',\n",
       " '<TWEET>: Kevin Smith Is The First Man In Hollywood To Step Up To Right <TARGET 1>s Wrongs URL',\n",
       " '<TWEET>: More Actors Accuse <TARGET 1> of Coercion and Assault URL',\n",
       " \"<TWEET>: <TARGET 1> is the epitome of a privileged entitled spoilt child-adult who's parents clearly told her she was a princess &amp; she believes it #MAFSNZ\",\n",
       " '<TWEET>: Retweeted The Sun (@TheSun): <TARGET 1> finishes sex addict rehab in ONE WEEK URL... URL',\n",
       " '<TWEET>: My pain is everyday: After <TARGET 1>s fall, Trump accusers wonder: Why not him? URL',\n",
       " \"<TWEET>: charged but I still wouldn't elect him president. <TARGET 1> was fired after 12 women came forward. Trump had 15 accusers.\",\n",
       " \"<TWEET>: Full Video: URL <TARGET 1> Leoni's nice natural titties cover... Add me on snapchat: mysuperass  URL\",\n",
       " '<TWEET>: Wonder what <TARGET 1> and Gordon were doing during this game. Also, we need to know more about Obis involvement! #Saw',\n",
       " '<TWEET>: We find out about abuses of power like <TARGET 1>s because of the internet. Keep supporting those who come forward and denounce complicity!',\n",
       " '<TWEET>: <TARGET 1> scandal has NJ lawmakers pushing ban on keeping sex harassment secret - NJ URL',\n",
       " '<TWEET>: Pikachu - 93.3 (13/14/15) - <TARGET 1> Estates. 02:31:12am (23m 28s). URL',\n",
       " '<TWEET>: Regret that <TARGET 1>, having lost all he could, fails to publish examples of aspiring actresses blatantly bartering for preference.',\n",
       " '<TWEET>: <TARGET 1> has allegedly continued to sexually harass women after going sober URL',\n",
       " '<TWEET>: How <TARGET 1> used his fashion business as a pipeline to models URL URL',\n",
       " '<TWEET>: <TARGET 1> Gives Names of Hollywood &amp; Washington DC Pedophiles to FBI  Wake Up Top URL',\n",
       " '<TWEET>: <TARGET 1> revelations prompt culture shift on sexual harassment . Its more like a serial rapist. URL via @HuffPostPol',\n",
       " '<TWEET>: Former #Actress #Accuses #<TARGET 1> of #Sexual #Assault - URL - URL',\n",
       " \"<TWEET>: A screenwriter who worked with <TARGET 1> says 'everybody f---ing knew'  via @BIAUS URL via @EntInsider\",\n",
       " '<TWEET>: I added a video to a @YouTube playlist URL <TARGET 1> and the child molester paradox',\n",
       " '<TWEET>: Upvoted - While the world focused on <TARGET 1>, something shocking happened: URL',\n",
       " '<TWEET>: While the world focused on <TARGET 1>, something shocking happened URL',\n",
       " '<TWEET>: Lauren Holly Reveals Her <TARGET 1> Bathroom Horror Story URL via @TMZ',\n",
       " '<TWEET>: <TARGET 1> case in point, no man could withstand the attacks Clinton takes daily, that is what you call #power',\n",
       " \"<TWEET>: If <TARGET 1> can now being given a wide berth (without a trial) how come he wasn't 20 or so years ago? Is it safety in numbers?\",\n",
       " \"<TWEET>: I'm a bit concerned as to how you're so well acquainted with Mr <TARGET 1>'s footwear collection...\",\n",
       " \"<TWEET>: Hey tough why don't you punch <TARGET 1> in the face? URL\\n\\n<QUOTED TWEET>: URL\",\n",
       " '<TWEET>: Weekend Update on <TARGET 1> - SNL URL via @YouTube',\n",
       " '<TWEET>: Investigation into <TARGET 1> shows forces have priorities wrong URL via @MailOnline',\n",
       " '<TWEET>: <TARGET 1> is already being used as way to shoe-horn new harassment laws in URL',\n",
       " '<TWEET>: Kichler <TARGET 1> II Antique Pewter 52-Inch LED Ceiling Fan - 300024AP URL',\n",
       " '<TWEET>: <TARGET 1>, Im Gonna Keep Making Movies, With or Without TWC URL URL',\n",
       " \"<TWEET>: Patriarchy. Capitalism. <TARGET 1>. Thread. URL\\n\\n<QUOTED TWEET>: one of the reasons it's so hard to break through to certain men about <TARGET 1> is that he exemplifies the conversion of other capitals into sexual capital, which is the keystone that holds up the fragile promise made by every product and film aimed towards men their whole lives\",\n",
       " '<TWEET>: <TARGET 1> most likely yan... i mean, its tENYA',\n",
       " '<TWEET>: Investigation into <TARGET 1> shows forces have priorities wrong - Daily Mail URL',\n",
       " '<TWEET>: <TARGET 1> Going To Rehab For Sex Addiction Could It Get Him His Job Back?? URL URL',\n",
       " '<TWEET>: British actress accuses <TARGET 1> of rapeBritish actress Lysette Anthony has become the l...#cnn URL',\n",
       " '<TWEET>: .@TheView calls out Mayim Bialik\\'s \"ignorant\" and \"tone deaf\" <TARGET 1> op-ed URL',\n",
       " '<TWEET>: the press may help create environment/conditions for certain behaviour to be seen as acceptable. But no direct <TARGET 1> connection',\n",
       " '<TWEET>: Joyce Ching and Maine <TARGET 1> are so cute  #ALDUBLoveisFOREVER URL',\n",
       " '<TWEET>: #ClassActionLawSuit time for #<TARGET 1> #bob #MiraMax #<TARGET 1>Co #Disney &amp;all other #complicit ones URL',\n",
       " '<TWEET>: With <TARGET 1>, the Society to Dismantle Patriarchy from Within has doubled in size! | First Dog on the Moon URL',\n",
       " '<TWEET>: Donald Trump is the <TARGET 1> of Washington | The... URL',\n",
       " '<TWEET>: Donald Trump is the <TARGET 1> of Washington | The Resistance with Keith Olbermann URL URL',\n",
       " \"<TWEET>: <TARGET 1> has refuted Bjrk's sexual harassment allegations. URL\",\n",
       " \"<TWEET>: The MSM bury their heads in the ground, Hillary probably won't return the cash <TARGET 1> donated to the DNC and Hollywood will defend him URL\",\n",
       " \"<TWEET>: Take a sneak peek at Maine <TARGET 1>'s book, 'Yup, I am That Girl!' LOOK: URL URL\",\n",
       " '<TWEET>: America is crucifying <TARGET 1> but still have Trump as their president? Wtf.',\n",
       " '<TWEET>: Oscar foundation bans <TARGET 1>: Found guilty before trial.',\n",
       " \"<TWEET>: I made the mistake of reading about all the disgusting things <TARGET 1> did and now I'm going to sleep with that in my memory\",\n",
       " '<TWEET>: I liked a @YouTube video URL This is the Reason the Controllers Choose to Burn <TARGET 1>!!!',\n",
       " '<TWEET>: Film producer <TARGET 1> has recently been accused of multiple accounts of rape and sexual abuse. The... URL',\n",
       " '<TWEET>: How powerful was <TARGET 1>? Almost no one has been thanked at the Oscars more #media URL URL',\n",
       " '<TWEET>: James Corden Jokes About <TARGET 1> at Charity Event VIDEO URL',\n",
       " '<TWEET>: Oscar-winning actor caught up in <TARGET 1> sex abuse scandal URL',\n",
       " '<TWEET>: Thank you @Okwonga great and insightful piece - <TARGET 1>, and the crisis in masculinity. URL',\n",
       " '<TWEET>: Gavin Polone on <TARGET 1> and Whos to Blame: Accomplices Must Be Exposed URL',\n",
       " '<TWEET>: Primo film travolto dallo scandalo <TARGET 1>!! #TheCurrentWar #The<TARGET 1>Company #trashcult #trashcultdotcom URL',\n",
       " '<TWEET>: Woody Allens <TARGET 1> Comments Example of Men Protecting Men, Activist Says URL URL',\n",
       " \"<TWEET>: <TARGET 1>, I'm Gonna Keep Making Movies, With or Without TWC URL\",\n",
       " '<TWEET>: Damon Dash \"<TARGET 1>\" (Advice to Women) URL @claudiajordan @rosemcgowan @drboycewatkins @miaspeight',\n",
       " '<TWEET>:  Stop Mentioning Daughters When You Denounce <TARGET 1> URL via @vulture',\n",
       " '<TWEET>: The <TARGET 1> scandal brings problems of sexual harassment back to the fore in France URL',\n",
       " '<TWEET>: A week after <TARGET 1> was kicked out of the Academy, the Producers Guild of America has also expelled him URL',\n",
       " '<TWEET>: Writer Scott Rosenberg claims everyone knew about <TARGET 1> URL via @MailOnline',\n",
       " '<TWEET>: Beautiful Girls Scribe Scott Rosenberg On A Complicated Legacy With <TARGET 1> URL via @deadline',\n",
       " \"<TWEET>: Screenwriter close to <TARGET 1> calls out Hollywood: 'Everybody f**king knew' URL via @mashable\",\n",
       " '<TWEET>: Harveywood <TARGET 1>s Fall Opens the Floodgates in Hollywood URL',\n",
       " '<TWEET>: Ao 2005 - Courtney Love Warning Actresses of <TARGET 1> in 2005 URL va @YouTube',\n",
       " '<TWEET>: shared - While the world focused on <TARGET 1>, something shocking happened: URL',\n",
       " '<TWEET>: Ben Shapiro On <TARGET 1> URL via @YouTube',\n",
       " '<TWEET>: Ex-<TARGET 1> staffer says assistants were manipulated: We werent safe either URL',\n",
       " '<TWEET>: [<TARGET 1> Estates] Meganium , till 04:23:35am. (29m 38s remaining) URL',\n",
       " '<TWEET>: Beautiful Girls Scribe Scott Rosenberg On A Complicated Legacy With <TARGET 1> URL',\n",
       " '<TWEET>: Tina Brown on former collaborator <TARGET 1>... and Trump. URL via @WomenintheWorld',\n",
       " '<TWEET>: Hello Nicole, is there anyway we could arrange an interview? Not about <TARGET 1>, but the darker demonic side of this world',\n",
       " '<TWEET>: This is Terry Richardson. He is a celebrity/fashion photographer. He makes <TARGET 1> URL URL',\n",
       " '<TWEET>: Peak performance from Noah Baumbach, Adam Sandler, <TARGET 1>, and basically everyone in the cast. Deeply affecting.',\n",
       " '<TWEET>: <TARGET 1> scandal puts several movies on hold: By Michael Academy votes to immediately URL',\n",
       " '<TWEET>: News post: \"<TARGET 1>\\x92s Fall Opens the Floodgates in Hollywood\" URL',\n",
       " '<TWEET>: Scandinavia can take place of <TARGET 1>. It is not a work. Dancer in the dark one of the rare movies of his \"filmography\".',\n",
       " '<TWEET>: New accuser: <TARGET 1> opened door at his Westport home... URL',\n",
       " '<TWEET>: Ben Shapiro On Hillary Going After <TARGET 1> When Bill Was Just As Bad URL via @YouTube',\n",
       " \"<TWEET>: I'm trying to imagine a world where <TARGET 1> and R Kelly can go about their lives abusing women. Most of the women I know have never even reported it let alone gone to court. But carry on.\",\n",
       " \"<TWEET>: She isn't a victim George try to keep up. And you have zero room to talk with your support of trump and <TARGET 1>\",\n",
       " \"<TWEET>: Rose McGowan: Lisa Bloom Offered Millions to 'Silence Me' About <TARGET 1> URL\",\n",
       " \"<TWEET>: He just agreed with @javukasin because she's a blonde. He wants to #<TARGET 1> her the first chance he gets!\",\n",
       " \"<TWEET>: Richard Madeley follows in James Corden's footsteps by joking about <TARGET 1> during charity speech URL\",\n",
       " '<TWEET>: <TARGET 1> Co. in Talks to Sell Company to Friend of President Trump URL URL',\n",
       " '<TWEET>: Near-collapse of the <TARGET 1> Co reminds me of this URL Avoiding toxic workers is better for firms than hiring stars',\n",
       " '<TWEET>: Producers Guild of America votes to expel <TARGET 1> URL',\n",
       " '<TWEET>: Talks to buy <TARGET 1> company URL',\n",
       " '<TWEET>: Hate to say it, but look like each gender has its version of <TARGET 1>. URL',\n",
       " '<TWEET>: Star Trek has been gay since <TARGET 1>! \\u200d',\n",
       " '<TWEET>: Writer Scott Rosenberg claims everyone knew about <TARGET 1> URL via @MailOnline',\n",
       " '<TWEET>: bunduki: <TARGET 1>I AWASILISHA USHAHIDI WA TATU TAKUKURU URL',\n",
       " '<TWEET>: Disgraced moviemaker <TARGET 1> once told Howard Stern he didnt sleep with aspiring actresses URL URL',\n",
       " '<TWEET>: Question to @JeffBezos - Who paid #LIsaBlooms fee to threaten, lie abt &amp;Intimidate #IsaHackett for complaining abt #<TARGET 1>? #Amazon? WHY?',\n",
       " \"<TWEET>: <TARGET 1>, I'm Gonna Keep Making Movies, With or Without TWC URL via URL\",\n",
       " '<TWEET>: Me Too: Alyssa Milano elevates <TARGET 1> conversation URL',\n",
       " '<TWEET>: Latest for @GQAustralia, on <TARGET 1>, etc. URL',\n",
       " '<TWEET>: <TARGET 1>s Fall Opens the Floodgates in Hollywood URL URL',\n",
       " '<TWEET>: Day 1. Public complain that Jimmy Kimmel not making #<TARGET 1> was condoning the behaviour Day 2. People upset at James Corden making jokes',\n",
       " '<TWEET>: bob Gets Emotional on \"Depraved\" Harvey, Saving the Company and His \"Waking Nightmare\" (Exclusive) URL',\n",
       " '<TWEET>: Only rich people have demons. The poor people go to prison. Andy Hamilton on <TARGET 1>.',\n",
       " '<TWEET>: <TARGET 1>s Fall Opens the Floodgates in Hollywood URL',\n",
       " \"<TWEET>: How come your sister knew about <TARGET 1> and you didn't? I find that hard to believe!!\",\n",
       " '<TWEET>: Not only did co-workers and corp officers at Miramax &amp; the <TARGET 1> Co fail to stop him, enabled him to continue. URL',\n",
       " '<TWEET>: Who are the <TARGET 1>s of India? Horror stories from our film industries URL via @indiatoday',\n",
       " \"<TWEET>: Clinton Foundation Pockets <TARGET 1>'s $250,000 Donation URL\",\n",
       " '<TWEET>: #Cine  French President Emmanuel Macron plans to strip <TARGET 1> of his Legion of Honor award - Daily Mail URL',\n",
       " '<TWEET>: The lesson of <TARGET 1>: If you see something, say something - URL',\n",
       " '<TWEET>: <TARGET 1>\\'s go-to line \"Sit, Watch Me Use The Toilet\" ?? URL',\n",
       " '<TWEET>: Its not just <TARGET 1> who exploits their power - this editor compiled a List of Women who say Trump Assaulted them URL',\n",
       " '<TWEET>: Harvey and bob, Showdown Tuesday Will Get Loud and Ugly URL',\n",
       " \"<TWEET>: I'll be in <TARGET 1>, Lima and Santiago over the coming week - hope to catch up with many of you #latam #investment #conference #travel\",\n",
       " '<TWEET>: \"As a father of three girls... I am heartbroken.\" Or just as a human person? #<TARGET 1> URL',\n",
       " '<TWEET>: because of the United States of Anthony <TARGET 1> is not working. They have no credibility!',\n",
       " \"<TWEET>: Why <TARGET 1> can't redeem himself through charity alone URL #<TARGET 1>\",\n",
       " '<TWEET>: 7) I had a chance to talk to Kevin Devine and <TARGET 1> but BLEW IT cause I wanted to be somewhat respectful of their boundaries',\n",
       " '<TWEET>: Magikarp - 91.1 (12/15/14) - <TARGET 1> Estates. 04:26:01am (29m 6s). URL',\n",
       " \"<TWEET>: In the wake of the Harvery <TARGET 1> news (that he's a complete monster if you didn't hear) there's been a... URL\",\n",
       " '<TWEET>: Catherine Zeta-Jones disgusted by <TARGET 1> claims URL',\n",
       " '<TWEET>: The Travel Almanac #13 is featuring <TARGET 1> by Juergen Teller, Greta Gerwig by Collier Schorr and more: URL URL',\n",
       " '<TWEET>: Co-workers and corporate officers at Miramax and the <TARGET 1> Co. apparently knew all about <TARGET 1>s attacks URL',\n",
       " '<TWEET>: \"I am deeply, deeply hurt.\" Mayim Bialik denies victim blaming <TARGET 1>... #breakingnews  NOW on URL',\n",
       " \"<TWEET>: 'The Guinness family heiress Ivana Lowell worked for <TARGET 1> at Miramax Books and dated his brother. She... URL\",\n",
       " '<TWEET>: YA U R A RAPIST Woody Allen Sad <TARGET 1>, Twitter R //clickout.sharethrough.com/?clickout_url=http%3A%2F%2Fusm.ag%2F2gGCW8O via @UsWeekly',\n",
       " \"<TWEET>: 6) I stood where Batman's parents were killed, but unfortunately it was from the <TARGET 1> movies, not the Bale ones\",\n",
       " '<TWEET>: Weinsten and Big <TARGET 1> are out...Blow Job Madona is in',\n",
       " \"<TWEET>: #GobShite KTHopkins: Many #<TARGET 1> women used their bodies to get an Oscar. That's ok. But also ok to be brutall URL\\n\\n<QUOTED TWEET>: What has one got to do with the other? You using your body to manipulate men is a bizarre comparison that demeans those who have suffered\",\n",
       " '<TWEET>: poetic justice in the fact it was Allens estranged son, journalist Ronan Farrow, New Yorker article on <TARGET 1> URL',\n",
       " \"<TWEET>: #ThemToo: 'An Open Secret' is free on Vimeo in wake of <TARGET 1> scandal URL\",\n",
       " '<TWEET>: Beautiful Girls Scribe Scott Rosenberg On A Complicated Legacy With <TARGET 1>  Deadline URL',\n",
       " '<TWEET>: Tracing the long money trail between <TARGET 1>, the Clintons URL via @YouTube',\n",
       " '<TWEET>: The accusers of Trump have no proof. <TARGET 1> has been protected &amp; enabled by hollywood for decades. Just like Hillary enabled Bill.',\n",
       " \"<TWEET>: Has the <TARGET 1> scandal 'freed' women from their silence? - YouTube URL via @skinnergj\",\n",
       " '<TWEET>: Ansakit <TARGET 1> hahaha',\n",
       " \"<TWEET>: hasn't taken donations from sexual predators. Big dif b/w talking bout grabbing pussy years ago &amp; #<TARGET 1> sexual assault\",\n",
       " \"<TWEET>: making sure they obey the letter of the law even while they're breaking it in spirit. <TARGET 1> just got sloppy.\",\n",
       " '<TWEET>: Screenwriter Scott Rosenberg says he knew all about <TARGET 1>  and so did everyone else - blows that theory! URL',\n",
       " '<TWEET>: Opinion | Save the Phony <TARGET 1> Outrage, Republicans URL',\n",
       " \"<TWEET>: Donald Trump Jr clears up the meaning of 'witch hunt' for Woody Allen 'in wake of <TARGET 1> scandal' URL\",\n",
       " \"<TWEET>: Read this, it's disgusting. @metpoliceuk @NYPDDetectives #lockhimup #<TARGET 1> and his legal and PR enablers URL\\n\\n<QUOTED TWEET>: In the 1990s, Rosanna Arquette was supposed to meet <TARGET 1> for dinner at a hotel. He moved it to his room. URL\",\n",
       " '<TWEET>: I think she is a <TARGET 1> girl',\n",
       " '<TWEET>: Disagree that hotness has to do w it: having others celebrate your physical beauty is not the way-on point. #MeToo\\n\\n<URL TITLE>: Opinion | Mayim Bialik: Being a Feminist in <TARGET 2>s World\\n<URL DESCRIPTION>: I have always had an uncomfortable relationship with being employed in an industry built on the objectification of women.',\n",
       " '<TWEET>: Now he needs 2 destroy his friend <TARGET 1>!',\n",
       " \"<TWEET>: Surely, if making jokes about <TARGET 1> adds to his thoroughly deserved humiliation it's a good thing?\",\n",
       " '<TWEET>: You can call that a outright lie, since he admits sex w/ some, but denies the lack of consent. Why are you still covering for <TARGET 1>?',\n",
       " '<TWEET>: <TARGET 1> Pal Robert De Niro Attacks Trump AGAIN, Calls Him a Lowlife URL via @truthfeednews',\n",
       " \"<TWEET>: WHEN I WAS 15 YES AND IM SO IN LOVE WITH <TARGET 1> CLAIRE AJKAJAKAB #BTSShow #Taemin_Move URL\\n\\n<QUOTED TWEET>: 51. Do you watch ASNTM (Asia's Next Top Model)? #BTSShow #MPN @BTS_twt\",\n",
       " '<TWEET>: Producers Guild of America votes to expel <TARGET 1> URL',\n",
       " \"<TWEET>: Producers' group moves to expel <TARGET 1> URL URL\",\n",
       " '<TWEET>: Delingpole: <TARGET 1> is a Model of Liberal Values URL via @BreitbartNews',\n",
       " '<TWEET>: Yup bill cosby is just a rapist but <TARGET 1> is humanised, new someone would do this same ol same ol  URL',\n",
       " '<TWEET>: And now #theindependent says Islam is good for women and could have prevented <TARGET 1> abuse??? URL',\n",
       " '<TWEET>: <TARGET 1> aussi... bref URL\\n\\n<QUOTED TWEET>: Hilarie Burton, aka Peyton des Frres Scott, a t agresse sexuellement par <TARGET 1> URL URL',\n",
       " '<TWEET>: (The latest on the <TARGET 1> sexual misconduct allegations) The Big Buzz - URL URL',\n",
       " '<TWEET>: <TARGET 1>\\'s go-to line \"Sit, Watch Me Use The Toilet\" ?? URL',\n",
       " \"<TWEET>: Sexual exploitation didn't begin with <TARGET 1>. URL\",\n",
       " '<TWEET>: <TARGET 1> risponde a Bjrk URL #musica',\n",
       " '<TWEET>: Catherine Zeta-Jones &amp;#8216;disgusted&amp;#8217; by <TARGET 1> claimsURL-newz.com',\n",
       " '<TWEET>: Catherine Zeta-Jones &amp;#8216;disgusted&amp;#8217; by <TARGET 1> claims URL',\n",
       " '<TWEET>: Courtney Love Warning Actresses Of <TARGET 1> In 2005! URL #<TARGET 1>',\n",
       " \"<TWEET>: Hard to find humor these days. Sex, Money, Hollywood= Obama, Hillary's corrupted puppet are in <TARGET 1>'s pocket. Betrayed by NFL, Piles of illegals. Lock Hillary and her puppets in Jail, remove all of NFL Traders permanently, Deport all illegals immediately. Build the walls.\",\n",
       " '<TWEET>: The <TARGET 1> scandal isnt even about <TARGET 1>. Its about the subjugation of women in whatever form by men with the power to inflict it.',\n",
       " '<TWEET>: #RobertDeniro Robert De Niro is a nasty Dirtbag no wonder he and <TARGET 1> were friends they both abusedwomen URL',\n",
       " '<TWEET>: Am I the only person hoping that, after the BBCs revelation on treatment of @ryanairpilots and crew, @Ryanair will go bust? #<TARGET 1> #Ryanair',\n",
       " \"<TWEET>: Retweeted Fox News (@FoxNews): FLASHBACK: @MichelleObama Praised <TARGET 1> as a 'Wonderful Human Being'... URL\",\n",
       " \"<TWEET>: I'm at Flia. <TARGET 1> Escobar URL\",\n",
       " '<TWEET>: <TARGET 1>: Clinton Friend, Fundraiser, Sexist Pig URL @vrmeg9',\n",
       " '<TWEET>: #<TARGET 1> You\\'ll never change an \"old dinosaur\". Maybe the way people perceive it? Once again Hollywood Libs and Dems with no Moral Compass',\n",
       " \"<TWEET>: Let's focus on <TARGET 1> for now since he is the monster in the news.\",\n",
       " '<TWEET>: \"<TARGET 1> trapped her in the hallway of a restaurant and masturbated in front of her until he ejaculated into a... URL',\n",
       " '<TWEET>: Schumer will donate <TARGET 1> contributions to charities supporting women URL URL',\n",
       " '<TWEET>: Cheers to well spent productive Saturday. Hindi ako tumunganga <TARGET 1> ',\n",
       " '<TWEET>: Now that the truth about <TARGET 1> is coming out, these libs are donating that money they received from him to other causes.',\n",
       " '<TWEET>: Okay, then, never gonna eat at Socialistas... #<TARGET 1> is a pig All of Hollywood knows it and yet, said nothing. URL',\n",
       " \"<TWEET>: If you've never read Ken Auletta's 2002 @NewYorker profile of <TARGET 1> ... you should: URL\",\n",
       " '<TWEET>: This video was just sold on @<TARGET 1>Starrxxx website \"<TARGET 1> &amp; Pandora Share Young Black Plaything\"\\n\\n<URL TITLE>: <TARGET 1> Starr Adult BBW GILF Performer\\n<URL DESCRIPTION>: The home of UKAP Award Winning International Porn Star <TARGET 1>Starr. Come and see all my hardcore movies and photos!',\n",
       " '<TWEET>: So, no <TARGET 1> coverage then?',\n",
       " '<TWEET>: URL \"Sexual Predator <TARGET 1> made 13 visits to Obama\\'s White House between 2010 and 2014, meeting Obama, Mich',\n",
       " '<TWEET>: Sigung posing for a photo op with <TARGET 1> outside of the VTAA competition. URL',\n",
       " '<TWEET>: TV Journalist Says <TARGET 1> Masturbated In Front Of Her URL',\n",
       " '<TWEET>: Not a movie for a family Saturday night but have you seen <TARGET 1>?',\n",
       " '<TWEET>: de Rothschild Aguaribay <TARGET 1> Malbec 2015 A terrific #Malbec JS-91 from Lafites South American cousin. $9.99 price.',\n",
       " \"<TWEET>: Don't lump all liberals into this disgusting piece of garbage, <TARGET 1>. If you're just using the story to bash liberals, get lost.\",\n",
       " '<TWEET>: W1A Actress Tweets About Losing A Role After Refusing To \"Screen Test In A Bikini\" For <TARGET 1> URL #fitness URL',\n",
       " '<TWEET>: Wow article ulit from @McDo_PH ambassadors @maymayentrata07 and Maine <TARGET 1> #MAYWARDXMcFreezeNewFlavors',\n",
       " \"<TWEET>: you're literally posting this under a tweet from someone trying to deflect criticism of <TARGET 1> and avoid the subject, rather than condemn\",\n",
       " '<TWEET>: <TARGET 1> I feel you and I love you URL',\n",
       " '<TWEET>: Freedom of the press, innocent until proven guilty (<TARGET 1> has not been convicted has he?) both gone. America, I hardly know you.',\n",
       " '<TWEET>: VIDEO - After <TARGET 1> Scandal, Colbert Hits ... Trump for Trying to Date Brooke Shields in 90s URL',\n",
       " '<TWEET>: <TARGET 1>...? URL',\n",
       " '<TWEET>: Whats Next for <TARGET 1>, Trumps Iran Move: DealBook Briefing URL',\n",
       " \"<TWEET>: Menendez was indicted in 2015, is on trial with essentially no Defense. What's new corrupt Democrats? #saturdaymorning #<TARGET 1> #AMJoy URL\",\n",
       " '<TWEET>: DNC to Donate Just $30K of Nearly $250K Contributed by <TARGET 1> URL',\n",
       " '<TWEET>: Hollywood Reporter: <TARGET 1> sure puts the Obamas, Clintons in a pickle, eh? URL',\n",
       " '<TWEET>: is an admitted sexual offender. #justsaying. Both <TARGET 1> and trump should be shunned.',\n",
       " '<TWEET>: Maybe you should ask Ivanka or Donny about <TARGET 1>? @DonaldJTrumpJr @IvankaTrump URL',\n",
       " \"<TWEET>: <TARGET 1>'s brother may have been mastermind behind sex allegation expos URL via @pagesix\",\n",
       " '<TWEET>: Flashback: <TARGET 1> And Jennifer Lawrence Present Bill Clinton With GLAAD Award URL',\n",
       " \"<TWEET>: I really don't get your comment on this. The <TARGET 1> story is everywhere. And, he is a pig. I really disagree w/u on this one.\",\n",
       " '<TWEET>: A New post <TARGET 1> Will Reportedly Be Suspended From His Company has been published on URL',\n",
       " '<TWEET>: PARAAQUE <TARGET 1> ',\n",
       " '<TWEET>: DNC to Donate Just $30K of Nearly $250K Contributed by <TARGET 1> URL via @BreitbartNews',\n",
       " '<TWEET>: Snorlax - 33.3 (6/5/4) - <TARGET 1> Estates. 05:08:06am (27m 12s). URL',\n",
       " '<TWEET>: Two More <TARGET 1> Company Board Members Quit Amid <TARGET 1> Scandal URL URL',\n",
       " '<TWEET>: Did White House Know? <TARGET 1> Visited White House 13 Times, Malia Obama Interned With Him URL via @YoungCons',\n",
       " \"<TWEET>: #EnablerInChief - #Msm won't tell you. <TARGET 1> Visited Obama White House 13 Times #DirtyMoney #HypocrisyOfTheLeft URL\",\n",
       " '<TWEET>: And he only now realized who <TARGET 1> was and how he behaved. Please. People are smarter than that. Problem is now that it is public.',\n",
       " \"<TWEET>: Do you think Meryl Streep, Nicole Kidman and Gweneth Paltrow have all baked <TARGET 1>'s carrot in their ovens? #RT\",\n",
       " '<TWEET>: Some Pics of The Meyorwitz Stories Q&amp;A Emma Thompson, Adam Sandler &amp; <TARGET 1>(Legend) and director Noah Baumbach #LFF17 #Netflix URL',\n",
       " '<TWEET>: Democrats return <TARGET 1> donations in wake of sexual abuse allegations URL via @ABCNews',\n",
       " '<TWEET>: <TARGET 1> Anderson  URL',\n",
       " '<TWEET>: Sigung posing for a photo op with <TARGET 1> outside of the VTAA competition. URL',\n",
       " '<TWEET>: <TARGET 1> Says JUSTICE LEAGUE Finally Brings Humor To The DC Films Universe URL',\n",
       " '<TWEET>: Hollywood Elitists Go Silent on Serial Sex Predator <TARGET 1>: URL',\n",
       " '<TWEET>: IS <TARGET 1> using Strong Arm Celebrity Pimping to gain economically? Extorting celebrities?!',\n",
       " \"<TWEET>: But what's Susan Rice have to do with <TARGET 1>? Or you suggesting it's all on Huma Abedin's laptop? Or this what Wasserman Shulz is hiding?\",\n",
       " '<TWEET>: because then they will not have the choice roles how else do they make- <TARGET 1> took full advantage of that',\n",
       " '<TWEET>: Some of those keen to call out Hollywood stars for working for <TARGET 1> seem to be having trouble finding any men who worked for him.',\n",
       " '<TWEET>: <TARGET 1>s Media Enablers URL',\n",
       " '<TWEET>: Check Out This Article on Movies, Comicbooks, or TV.. Dont forget to Follow Us.. #cnageeks <TARGET 1> Says JUS... URL',\n",
       " \"<TWEET>: Jimmy Kimmel, SNL &amp; all late night shows will have a field day bashing #<TARGET 1> 4 jerking off into a potted plant wait he's a DEM it's ok URL\",\n",
       " '<TWEET>: Sigung posing for a photo op with <TARGET 1> outside of the VTAA competition. URL',\n",
       " '<TWEET>: Sigung posing for a photo op with <TARGET 1> outside of the VTAA competition. URL',\n",
       " '<TWEET>: hahahahahahahah SAME <TARGET 1> same  #dpaMessageForDonny @donnypangilinan URL\\n\\n<QUOTED TWEET>: me right now: @donnypangilinan #dpaMessageForDonny @Donnys_Army URL',\n",
       " '<TWEET>: gonna restart house of cards <TARGET 1> is my man',\n",
       " '<TWEET>: THE HILL: \"Schumer will donate <TARGET 1> contributions to charities supporting women URL URL\"',\n",
       " '<TWEET>: Great analogy Jane. Russell Crowe, <TARGET 1>, Jack Nicholson all hit it out of the park.',\n",
       " \"<TWEET>: There's a specific <TARGET 1> bit that seems appropriate\",\n",
       " '<TWEET>: I so respect all women and regret what happened, he added. - @<TARGET 1>  IF so, drop #lawsuit against @nytimes who made you own up URL\\n\\n<QUOTED TWEET>: Exclusive: <TARGET 1> masturbated in front of a TV reporter. She spoke to me and is named in the story. URL',\n",
       " '<TWEET>: What Trumps Access Hollywood tape reveals about <TARGET 1> and men in power URL',\n",
       " \"<TWEET>: Now how can I get you to stand next to <TARGET 1>, Terry? Clandestinely. And, well...something REAL bad just happens to him as a result? URL\\n\\n<QUOTED TWEET>: I'm standing right next to you on this. URL\",\n",
       " '<TWEET>: (His excuses are BS!) At NBC News, the <TARGET 1> scandal barely exists: URL via @HuffPostPol',\n",
       " '<TWEET>: Stars go silent and offer no public support for Ashley Judd on her allegations of sexual harassment against <TARGET 1> URL',\n",
       " \"<TWEET>: <TARGET 1> scandal, Day 2: New graphic allegation; 'indefinite' leave of absence URL\",\n",
       " '<TWEET>: Maine <TARGET 1> as the Most Influential Female Celebrity Endorser of the Year!  (1)  ramsdavid86 #ALDUBEdukCircleAwardees URL',\n",
       " '<TWEET>: Let me be clear: <TARGET 1> is abuser &amp; vile sexual predator. But nobody is commenting on the DELAY in accusations. $$ &amp; fame is their God,',\n",
       " '<TWEET>: walang kwarta <TARGET 1> #dpaMessageForDonny @donnypangilinan URL',\n",
       " '<TWEET>: <TARGET 1> Blames The NRA After He Is Caught Sexually Harassing Women? URL',\n",
       " '<TWEET>: Regarding <TARGET 1>, all I have to say is: \"He who has not masturbated into a potted plant, cast the first stone!\"',\n",
       " '<TWEET>: <TARGET 1> Accused of Masturbating in Front of Female TV Reporter. Is that wrong to do? Dont Liberals protect woman? URL',\n",
       " '<TWEET>: If true, bob is a hero for exposing this Perv, albeit way too late but it is done.',\n",
       " \"<TWEET>: What's Affecting my Wallet? Some Democrats Returning Money They Received From <TARGET 1> URL\",\n",
       " '<TWEET>: Making News Today: Democrats return <TARGET 1> donations in wake of sexual abuse allegations URL',\n",
       " '<TWEET>: Company Scrambles as <TARGET 1> Takes Leave and a Third of the Board Resigns URL',\n",
       " \"<TWEET>: Love that he's our president!! <TARGET 1> is he your guy\",\n",
       " '<TWEET>: Maine <TARGET 1> as the Most Influential Female Celebrity Endorser of the Year!  (3)  ramsdavid86 #ALDUBEdukCircleAwardees URL',\n",
       " '<TWEET>: Top story: TV Reporter Says <TARGET 1> Masturbated In Front Of Her | Huff URL, see more URL',\n",
       " \"<TWEET>: Why do liberals disregard facts? There is no comparison-<TARGET 1> took actions in hotel rooms with employees/others. He's bad just admit it.\",\n",
       " \"<TWEET>: But DNC so bad because... <TARGET 1>. ~Per republicans and lefty roses. URL\\n\\n<QUOTED TWEET>: <TARGET 1> outed as sexual harasser: DNC send his money to women's groups. Trump outed as sexual predator: RNC nominates him for president.\",\n",
       " '<TWEET>: Maine <TARGET 1> as the Most Influential Female Celebrity Endorser of the Year!  (2)  ramsdavid86 #ALDUBEdukCircleAwardees URL',\n",
       " \"<TWEET>: Haven't heard one single celeb condemn Harvey sex case <TARGET 1>.. Hmmm.. And they all said fuck all about nonce Polanski.\",\n",
       " \"<TWEET>: Am I the only one who visually thought of Mrs. Doubtfire's gay brother- Harvey Fierstein- when all this <TARGET 1> stuff came out? URL\",\n",
       " '<TWEET>: <TARGET 1> dining with the Obamas. URL',\n",
       " \"<TWEET>: Now you are the right track!!!! So you got <TARGET 1>, BFD. Not exactly public enemy #1. DON'T GLOAT, VOTE!!!!\",\n",
       " \"<TWEET>: We're waiting for your <TARGET 1> jokes.\",\n",
       " '<TWEET>: I liked a @YouTube video URL <TARGET 1> Gets Shot While Preparing for Bullet Catch',\n",
       " '<TWEET>: If this thing about <TARGET 1> was still hidden...these liberal politicians would have kept that money. Sick sick people.',\n",
       " '<TWEET>: Gengar - ? (?/?/?) - <TARGET 1> Estates. 05:15:31am (27m 43s). URL',\n",
       " \"<TWEET>: you don't seem to care much when a sexual abuser is outed... Your tone is little more than a yawn on <TARGET 1>\",\n",
       " '<TWEET>: Democrats have definitely criticized <TARGET 1>. WTF are you talking about?',\n",
       " '<TWEET>: [ URL ] <TARGET 1> Will Reportedly Be Suspended URL | URL',\n",
       " \"<TWEET>: <TARGET 1>'s brother may have been mastermind behind sex allegation expos URL via @pagesix\",\n",
       " '<TWEET>: Far too many men: Well <TARGET 1> never tried to rape ME!',\n",
       " \"<TWEET>: Hollywood, we now permit you to speak up #<TARGET 1> #TeamJudd Pin drop! URL\\n\\n<QUOTED TWEET>: Remember Hollywood, we are the Kings and you are just drug-addled Court Jesters. You'll speak only when we permit you to. #BoycottTheOscars\",\n",
       " \"<TWEET>: No prob. I haven't looked recently, but I'd bet <TARGET 1>'s donations aren't much compared to DeVos+Prince family to GOP.\",\n",
       " \"<TWEET>: Stay safe don't let <TARGET 1> abuse you\",\n",
       " '<TWEET>: I RTd a pic of the Drumpfs with <TARGET 1>. ',\n",
       " '<TWEET>: When will dems break the silence on <TARGET 1>?',\n",
       " '<TWEET>: Top story: TV Reporter Says <TARGET 1> Masturbated In Front Of Her | Huff URL, see more URL',\n",
       " '<TWEET>: Top story: TV Reporter Says <TARGET 1> Masturbated In Front Of Her | Huff URL, see more URL',\n",
       " '<TWEET>: Republicans and Democrats war over <TARGET 1> donations URL',\n",
       " '<TWEET>: Former TV anchor says <TARGET 1> masturbated in front of her URL via @MailOnline',\n",
       " '<TWEET>: <TARGET 1> probably already knows libel law &amp; his chances of success are practically null; this is so much posturing. URL',\n",
       " '<TWEET>: Top story: Lisa Bloom, <TARGET 1>s Adviser, Criticizes His Behavior Towa URL, see more URL',\n",
       " '<TWEET>: <TARGET 1> ejaculated quickly into a potted plant ... URL',\n",
       " '<TWEET>: The same people who told you endlessly that Trump was a rapist for the \"grab \\'em by the p\" remark won\\'t go on record about <TARGET 1>',\n",
       " '<TWEET>: Regarding <TARGET 1>, all I have to say is: \"He who has not masturbated into a potted plant, cast the first stone!\"',\n",
       " \"<TWEET>: #DePeliQlas Armageddon ( Aerosmith - I Don't Want To Miss a Thing ) Bruce Willis, <TARGET 1> y Liv Tyler URL\",\n",
       " '<TWEET>: Reuters: Goldman Sachs marks stake in <TARGET 1> Co down to zero: source URL URL',\n",
       " '<TWEET>: \"<TARGET 1>s Former Manager Apologizes for Not Confronting the Comedian\" by CARA BUCKLEY via NYT URL URL',\n",
       " \"<TWEET>: aagghHHHHHH <TARGET 1> I'M DOWN FOR THIS URL\\n\\n<QUOTED TWEET>: Cypher in Manila  URL\",\n",
       " '<TWEET>: Good look. URL\\n\\n<QUOTED TWEET>: <TARGET 1> described persuading men into sex to Howard Stern URL URL',\n",
       " '<TWEET>: <TARGET 1>s Former Manager Apologizes for Not Confronting the Comedian URL',\n",
       " '<TWEET>: <TARGET 1> is a disgusting fuck and i am so proud of the oth ladies for coming forward',\n",
       " \"<TWEET>: The parents were responsible for reporting it. If you are a stage parent you might not want to make the top dogs hesitant to hire your child. What's extremely sad here is <TARGET 1> is a criminal. A real sleaze, but the girl has to be lying.\",\n",
       " '<TWEET>: No worries! <TARGET 1> is going to do the Republicans what no Democrat could ever hope to accomplish! Together with the dictates of the molester in chief theyre going to destroy the Republican party! I should say whats left of the Republican Party!',\n",
       " '<TWEET>: Its definitely everywhere. I havent had to time to keep with all of it. Busy, family, career and golf. That <TARGET 1> thing, the irony there is that culture thrived on that to get ahead. Granted it sounds like he went overboard. I think that set it off.',\n",
       " '<TWEET>: Goldman Sachs marks stake in <TARGET 1> Co down to zero: source URL URL #klout #maga',\n",
       " '<TWEET>: Retweeted Barracuda Brigade (@BB4SP): Judge <TARGET 1> said he intends to sue the Washington Post for a series of... URL',\n",
       " '<TWEET>: After <TARGET 1>: A List of Men Accused of Sexual Misconduct and the Fallout for Each URL',\n",
       " \"<TWEET>: Sources say she won't tolerate <TARGET 1> connection URL\",\n",
       " '<TWEET>: #Confused These White women outraged by <TARGET 1>, Moore in Alabama and distraught about disrespect and abuse of... URL',\n",
       " \"<TWEET>: Looking at <TARGET 1>'s website, he was Deputy DA, not DA in 1977. This latest accuser's yearbook has just DA, which makes it more suspicious. The December date on the yearbook lines up with last accuser's story, but yearbooks are issued and typically signed in August. Collusion?\",\n",
       " '<TWEET>: Why is <TARGET 1> not the spokesman for Aflac? #DeepState #toughquestions #thereisnosymetryintheworld #daredevil',\n",
       " '<TWEET>: #Woman says <TARGET 1> attacked her in a car when she was 16 URL URL',\n",
       " \"<TWEET>: I don't know your work on ISIS, but the thoughtful <TARGET 1> column brought me here. I hope you continue in that vein from time to time.\",\n",
       " '<TWEET>: <TARGET 1> as well.',\n",
       " '<TWEET>: <TARGET 1> is on his apology tour #SkimmLife URL via @theSkimm',\n",
       " \"<TWEET>: Sorry guys, <TARGET 1> is going to win that Alabama Senate's seat judging by the vicious attack from Washington Deep-State swamp. In fact this seems more like endorsement for him in every regard. This was the same scene that got played out when Trump shocked the world in Nov. 8th.\",\n",
       " '<TWEET>: <TARGET 1> Review of Museums published today URL',\n",
       " '<TWEET>: #BeverlyYNelson, anyone who doesn\\'t believe U was not paying attn or has no @<TARGET 2>Senate: Ur goose overdone! U can\\'t say U never met her! #yearbook \"You\\'re just a child. I am the District Atty...If you tell anyone about this, no one will ever believe you.\" @GloriaAllred #MeToo URL\\n\\n<QUOTED TWEET>: New <TARGET 2> accuser says she thought he was going to rape me when she was 16 years old URL',\n",
       " '<TWEET>: One Tree Hill creator <TARGET 1> accused of sexual harassment by cast and crew URL',\n",
       " '<TWEET>: Showrunner <TARGET 1> Accused Of Sexual Harassment By One Tree Hill Cast, Crew URL URL',\n",
       " '<TWEET>: Can we maybe stop employing ppl like Mel Gibson, Roman Polanski, Casey <TARGET 1>, Woody Allen??....SHALL I GO ON?! URL\\n\\n<QUOTED TWEET>: Box office: With #DaddysHome2, Mel Gibson is once again family-friendly URL URL',\n",
       " \"<TWEET>: IT'S A FAKE! Analyst Says Judge <TARGET 1> Signature Inside Gloria Allred Accuser's Yearbook Was FORGED URL\",\n",
       " '<TWEET>: New post (<TARGET 1> admits masturbating in front of female colleagues | SML News) has been published on BuzzyBuzz - URL URL',\n",
       " \"<TWEET>: Gal Gadot refuses to play Wonder Woman if WB doesn't cut ties with <TARGET 1>. Just posted on URL\",\n",
       " '<TWEET>: Seems fitting that <TARGET 1>s fictional avatar is returning as <TARGET 1> himself has been suspended. No better reminder of AKs continuing negative impact on this feminist show.',\n",
       " '<TWEET>: <TARGET 1> Blurr - live URL',\n",
       " '<TWEET>: Maine <TARGET 1> Philippines URL us vote MAINE ONE OF THE MOST (NATURAL) BEAUTIFUL WOMEN IN THE WORLD2017',\n",
       " '<TWEET>: My question wasnt directed towards you. Also, I have vehemently opposed the position of <TARGET 1> and have denounced him and the egregious nature of his conduct since these revelations have been made public.',\n",
       " '<TWEET>: Despite \"overwhelming\" evidence against actor <TARGET 1>, rape case has stalled URL # via @HuffPostEnt',\n",
       " \"<TWEET>: 1. The actress who played Chloe Sullivan was revealed to have been part of a sex cult. 2. That statutory r*pe red herring was unnecessary, and (imo) doesn't exactly help with the <TARGET 1> conversation, or larger conversation at hand. 3. In light of what was confirmed recently...\",\n",
       " \"<TWEET>: Gal Gadot refuses to play Wonder Woman if WB doesn't cut ties with <TARGET 1>. Just posted on URL\",\n",
       " '<TWEET>: <TARGET 1> said a lot more to Howard than that. Did you guys listen to Cocktober?',\n",
       " \"<TWEET>: In 2017, <TARGET 1> wouldn't pass a fair character &amp; fitness background check for bar admission. He's too reprehensible to be a lawyer &amp; he has no place in the Senate. #No<TARGET 1> URL\\n\\n<QUOTED TWEET>: He should not be allowed anywhere near legislation and policy. URL\",\n",
       " '<TWEET>: I absolutely love house of cards and so a lot of people have asked me how I feel about the <TARGET 1> allegations.',\n",
       " '<TWEET>: Completely forgot that <TARGET 1> plays Batman in these #JusticeLeague movies. Still think of Christian Bale when people say Batman #JimmyKimmelLive #JKL #Kimmel #ThursdayThoughts',\n",
       " \"<TWEET>: Here's how I feel about it: it's a fucking TV show, its not important, it doesn't matter. <TARGET 1> raped a 14yr old. Put him in jail.\",\n",
       " '<TWEET>: .@GingerMcQueen on #Periscope: <TARGET 1> story beyond disturbing. An 11 year old? URL',\n",
       " '<TWEET>: Jason Momoa, Henry Cavill, Ezra Miller, Gal Gadot, Ray Fisher and <TARGET 1> at the premiere of #JusticeLeague in Los Angeles, California (November 13, 2017) URL',\n",
       " '<TWEET>: no but Brand New - <TARGET 1> abuse scandal MOBO - indefinite hiatus TFB - i just love them',\n",
       " '<TWEET>: #Tinder <TARGET 1> URL #GWBchat @USBloggerRT @StatesideBBabes @Yourblogretweet @QualityBlogRT #MakeABloggersDay URL',\n",
       " '<TWEET>: <TARGET 1> Was Removed From Movie Set for Allegedly Violating 11-Year Old Girl URL',\n",
       " '<TWEET>: One of the benefits of being a barely employed shut-in is Ill most likely never be accused of sexual assault. #glasshalffull #brightside #perks #<TARGET 1>',\n",
       " '<TWEET>: Coming back to see your crew?#HarveyWeinsten #RayMoore #<TARGET 2> #RayMoore #<TARGET 3> #<TARGET 1> #<TARGET 4> URL',\n",
       " '<TWEET>: My biggest hot take on this is simple. If DC covered for <TARGET 1> for six years after multiple women came forward, what else have they done? Who else have they shielded? How many more cases of harassment are there at DC? URL\\n\\n<QUOTED TWEET>: URL Wow, only three years after he was publicly outed! Justice like lightning over at DC.',\n",
       " \"<TWEET>: Why do <TARGET 1>'s comments remind me of the Salem Witch Trials?\",\n",
       " \"<TWEET>: <TARGET 1>, I'm Gonna Keep Making Movies, With or Without TWC URL\",\n",
       " '<TWEET>: The times I caught my sexy man my crush live on Instagram . @<TARGET 1>_Mo my <TARGET 1> Pooh URL',\n",
       " '<TWEET>: <TARGET 1> URL',\n",
       " '<TWEET>: Maine <TARGET 1> URL our Love for MAINE let us vote Her. Most Natural Beautiful Filipino Actress2017',\n",
       " '<TWEET>: Because of Utahs absentee tolling, #<TARGET 1> can still be charged with this disgusting crime. Perhaps @UtahAG @SimGillDA wont fail her like everyone else did: URL',\n",
       " '<TWEET>: Same Boies from Theranos... / <TARGET 1> Co. directors say they didnt know lawyer David Boies invested in firms movies URL via @WSJ',\n",
       " '<TWEET>: Love Family Guy, but you MUST rename James Woods High because James Woods maybe another <TARGET 2>/<TARGET 1>! Kick James Woods out of Family Guy!',\n",
       " \"<TWEET>: Clinton, <TARGET 1>, the list goes on, political party shouldn't stop you from calling them all out.\",\n",
       " '<TWEET>: I\\'m with you on the music now having a tainted feel &amp; the general behavior is severely troubling on many levels. I think his apology ( like <TARGET 1>\\'s) has some merit but it also feels like a \"sorry I got caught\" type apology. At least he said sorry in his apology.',\n",
       " \"<TWEET>: <TARGET 1>'s admission of sexual misconduct is the final straw for several networks - Los Angeles Times Los Angeles URL\",\n",
       " '<TWEET>: Photos: Justice League  <TARGET 1>, Gal Gadot, Henry Cavill and more stars attend premiere in LA URL #ThingsToDo #',\n",
       " '<TWEET>: Opinion | The Deep Confusion of the Post-<TARGET 1> Moment URL',\n",
       " '<TWEET>: .@TiffanyHaddish didnt shy away from going after <TARGET 1> on @SNL. Why was this diss somewhat surprising? Find out NEXT on #PageSixTV! URL',\n",
       " '<TWEET>: Hey! <TARGET 1> in jimmy kimmel! The chicks used to tell me I looked like him. Then I gained 75 lbs or so. But my hair isnt gray now so piss on him. Ha',\n",
       " '<TWEET>: We Are All Implicated in the Post-<TARGET 1> Reckoning URL via @thecut',\n",
       " '<TWEET>: How does <TARGET 1> celebrate  day? By planting his seed',\n",
       " '<TWEET>: Tru. We have Sad <TARGET 1>. URL',\n",
       " '<TWEET>: <TARGET 1> was accused of rape by @anthonyedwards. He has teamed up with his pal Bryan Singer on this project URL which is set to be released next year.',\n",
       " \"<TWEET>: there goes my <TARGET 1>'s. URL\\n\\n<QUOTED TWEET>: Hi Ali - We removed Hannity from our advertising plans. We will be sure to provide your feedback with our team. Our advertising is not intended to be an endorsement of or sponsorship of any particular program. Thank you.\",\n",
       " '<TWEET>: Disturbing <TARGET 1> Allegation, Involving 11-Year-Old Co-Star, Surfaces URL',\n",
       " '<TWEET>: I bet <TARGET 1> raped a bunch of children in Vietnam.',\n",
       " '<TWEET>: ALL THE MONEY Trailer #1 (2017) Mark Wahlberg, <TARGET 1> Crime Movie HD URL via @YouTube',\n",
       " '<TWEET>: in Little <TARGET 1> #bombqueen - nirvanabathandbody @ URL',\n",
       " '<TWEET>: Speaking of...did you hear about <TARGET 1>? ',\n",
       " '<TWEET>: One Tree Hill Showrunner <TARGET 1> Accused of Sexual Harassment URL',\n",
       " \"<TWEET>: BBC News - <TARGET 1>: Woman claims US Senate candidate 'tried to rape me' URL\",\n",
       " \"<TWEET>: Showrunner <TARGET 1> Accused of Sexual Harassment by 'One Tree Hill' Cast, Crew URL\",\n",
       " \"<TWEET>: As more US Senate Republicans condemn child predator <TARGET 1>, US Sen-wannabe Josh Mandel sez 'U can say we didn't respond.'' URL\",\n",
       " \"<TWEET>: GOP to Brown man with a gun: ISIS! GOP to White man with a gun: misunderstood! GOP on <TARGET 1>: disgusting pig, liberals stop protecting predators!! GOP on Moore: They're lying, he's a good man. Yep, double standards.\",\n",
       " '<TWEET>: \"We must stop the flow of illegal aliens across both our northern and southern borders. Open borders are a threat to our national security and to our economy.\" <TARGET 1>',\n",
       " \"<TWEET>: Is he reinacting some <TARGET 1> brothers moves? URL\\n\\n<QUOTED TWEET>: Jimmy's 6th birthday wish finally came true 44 years later! Batman is here! @<TARGET 2> #JusticeLeague URL\",\n",
       " '<TWEET>: Oh my *<TARGET 1> voice* URL',\n",
       " '<TWEET>: Just think they haven\\'t touched the tip of the iceberg. Since <TARGET 1> 20 perverts from entertainment industry named. In the immortal words of Fred Astaire \"That\\'s Entertainment \" all of Hollywood is tainted',\n",
       " \"<TWEET>: Showrunner <TARGET 1> Accused of Sexual Harassment by 'One Tree Hill' Cast, Crew URL URL\",\n",
       " '<TWEET>: Showrunner <TARGET 1> Accused Of Sexual Harassment By One Tree Hill Cast, Crew URL URL',\n",
       " \"<TWEET>: Didn't her daughter just defend <TARGET 1>???\",\n",
       " '<TWEET>: It was a tough call for GQ once they narrowed it down between <TARGET 1> in this scumbag.',\n",
       " \"<TWEET>: Oh no. I've always admired @<TARGET 1>. This is depressing. URL\\n\\n<QUOTED TWEET>: My latest @thr investigation: Actor <TARGET 1> was removed from a 2003 movie set in Utah for allegedly violating an 11-year-old girl. A dozen cast and crewmembers tell me about the incident. <TARGET 1> himself chose not to comment. URL\",\n",
       " '<TWEET>: It\\'s not really a surprise that <TARGET 1> is a piece of shit. But good looking out Hollywood. Same shit with Roman Polanski. Covering for pedophiles while slamming <TARGET 2>. All of these \"men\" are shit human beings. But they certainly aren\\'t alone. What say you, Hollywood? URL\\n\\n<QUOTED TWEET>: THR spoke to a dozen people involved with the production of the film, who confirmed <TARGET 1> was sent home over the alleged incident URL',\n",
       " \"<TWEET>: Republicans couldn't remove Bill Clinton over sex scandals. What makes you think they could, or would, remove Trump on the same grounds? <TARGET 1> isn't in the Senate yet, but Trump is POTUS. Much easier to keep somebody out than oust them once they're already there.\",\n",
       " \"<TWEET>: Sources say she won't tolerate <TARGET 1> connection URL\",\n",
       " \"<TWEET>: With grt remorse the guy who I used to look up to <TARGET 1> the funniest man on the planet has been accused of sexual misconduct with several women It's so depressing that when I go bck n listen to all his bits now they dnt make the same sense as they used to do @real<TARGET 1>\",\n",
       " \"<TWEET>: Ummm.................You won't find one tweet where I've said I believe the <TARGET 1> accusations...but this is much different.\",\n",
       " '<TWEET>: When will <TARGET 1> learn that he is not superhero material??? Hes now ruined TWO superheroes....Daredevil and Batman. ',\n",
       " '<TWEET>: <TARGET 1>s scenes deleted, re-shot for upcoming movie. Hit TV show canceled URL',\n",
       " \"<TWEET>: URL Hey <TARGET 1>'s I'll buy it from you... if I can make it triple X\",\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "552212a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I admit, the great majority of films released before say 1933 are just not for me. Of the dozen or so \"major\" silents I have viewed, one I loved (The Crowd), and two were very good (The Last Command and City Lights, that latter Chaplin circa 1931).<br /><br />So I was apprehensive about this one, and humor is often difficult to appreciate (uh, enjoy) decades later. I did like the lead actors, but thought little of the film.<br /><br />One intriguing sequence. Early on, the guys are supposed to get \"de-loused\" and for about three minutes, fully dressed, do some schtick. In the background, perhaps three dozen men pass by, all naked, white and black (WWI ?), and for most, their butts, part or full backside, are shown. Was this an early variation of beefcake courtesy of Howard Hughes?',\n",
       " 'label': -1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c9bae52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweet_id', 'user_id', 'text', 'body_target_mentions_validated', '__index_level_0__'],\n",
       "    num_rows: 2061369\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3020c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "121220f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__ (self, df, X_col):\n",
    "        '''\n",
    "        So that we can move the entire dataset to the GPU.\n",
    "        :param X: float32 data scaled numpy array\n",
    "        :param y: float32 data scaled numpy vector\n",
    "        :param device: 'cpu' or 'cuda:0'\n",
    "        '''\n",
    "        self.X = list(df[X_col])\n",
    "        # y vector needs to be in a column vector (or at least it\n",
    "        # did in the normal dataset.)\n",
    "#         self.y = torch.from_numpy(df[y_col])\n",
    "\n",
    "    def __len__(self):\n",
    "        return list(self.X.size())[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.X[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acdedb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_col = \"clean_tweet_masked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6ee5377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          <TWEET>:  I do love you. . I love you, <TARG...\n",
       "4          <TWEET>: <TARGET 1> apologizes for 'aggressive...\n",
       "5          <TWEET>: No one should have to endure this kin...\n",
       "6          <TWEET>: \"New <TARGET 1> sexual assault accusa...\n",
       "8          <TWEET>: Yes this. <TARGET 1>, this clown, the...\n",
       "                                 ...                        \n",
       "4683894    <TWEET>: Democratic National Committee to Give...\n",
       "4683895    <TWEET>: We are also tired of Hollywood; they ...\n",
       "4683898    <TWEET>: <TARGET 1>'s photobombing. The ladies...\n",
       "4683901    <TWEET>: Lisa Bloom, Lawyer Advising <TARGET 1...\n",
       "4683902    <TWEET>: Don Jr. trolls silent Hillary over <T...\n",
       "Name: clean_tweet_masked, Length: 2061369, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[X_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11398702",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = MyDataSet(pred_df, \"clean_tweet_masked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2149bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(pred_dataset,batch_size=64,shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9586004e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-16550f80f33b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal_handling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_SIGCHLD_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_pids_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;31m# prime the prefetch loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefetch_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e09cb48138ba>\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "for X in loader:\n",
    "    print(X)\n",
    "    print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f17667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'body', 'postedTime', 'retweetCount', 'favoritesCount',\n",
       "       'quoted_status_id', 'quoted_status_user_id', 'quoted_status_body',\n",
       "       'quoted_status_user_postedTime', 'gnip_url_title',\n",
       "       'gnip_url_description', 'is_RT', 'RT_body', 'RT_user_id', 'RT_id',\n",
       "       'tweet_id', 'user_id', 'RT_target_mentions', 'body_target_mentions',\n",
       "       'gnip_url_title_mentions', 'lang_pred', 'lang_pred_prob',\n",
       "       'quoted_status_target_mentions', 'RT_target_mentions_metoo',\n",
       "       'all_fields_n_targets', 'body_target_mentions_metoo',\n",
       "       'body_target_mentions_n_targets', 'body_target_mentions_target',\n",
       "       'gnip_url_title_mentions_metoo', 'quoted_status_target_mentions_metoo',\n",
       "       'masked_body', 'propn_masked_body', 'body_target_mentions_validated',\n",
       "       'body_target_mentions_validated_true', 'clean_targets_n', 'clean_tweet',\n",
       "       'clean_tweet_masked', 'mask_map', 'modified_quote_tweet', 'time_check',\n",
       "       'all_target_mentions_metoo', 'gnip_url_title_mentions_n_targets',\n",
       "       'gnip_url_title_mentions_target', 'gnip_url_title_mentions_validated',\n",
       "       'gnip_url_title_mentions_validated_true',\n",
       "       'quoted_status_target_mentions_n_targets',\n",
       "       'quoted_status_target_mentions_target', 'masked_quoted_status_body',\n",
       "       'propn_masked_quoted_status_body',\n",
       "       'quoted_status_target_mentions_validated',\n",
       "       'quoted_status_target_mentions_validated_true'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6338a7fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          <TWEET>:  I do love you. . I love you, <TARG...\n",
       "1                                                        NaN\n",
       "2                                                        NaN\n",
       "3                                                        NaN\n",
       "4          <TWEET>: <TARGET 1> apologizes for 'aggressive...\n",
       "                                 ...                        \n",
       "4683900    <TWEET>: But but but dude you're a rapist HOW ...\n",
       "4683901    <TWEET>: Lisa Bloom, Lawyer Advising <TARGET 1...\n",
       "4683902    <TWEET>: Don Jr. trolls silent Hillary over <T...\n",
       "4683903                                                  NaN\n",
       "4683904                                                  NaN\n",
       "Name: clean_tweet_masked, Length: 4683905, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_masked_texts = pred_data.clean_tweet_masked\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "694a7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = Dataset.from_pandas(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64e51097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweet_id', 'user_id', 'clean_tweet_masked', 'body_target_mentions_validated', '__index_level_0__'],\n",
       "    num_rows: 2061369\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c3c6662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f2a73dd65d48b2a6310972d59b9352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2062 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataCollatorWithPadding' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-89279a2a549c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtokenized_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata_collator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataCollatorWithPadding' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"clean_tweet_masked\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = pred_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3578537",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f47c8f",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b2dbdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['__index_level_0__', 'attention_mask', 'body_target_mentions_validated', 'clean_tweet_masked', 'input_ids', 'token_type_ids', 'tweet_id', 'user_id'],\n",
       "    num_rows: 2061369\n",
       "})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9828825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"./sample_model.p\"\n",
    "model = torch.load(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ba933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3d9379b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['__index_level_0__', 'attention_mask', 'body_target_mentions_validated', 'input_ids', 'token_type_ids', 'tweet_id', 'user_id'],\n",
       "    num_rows: 2061369\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f49f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"body_target_mentions_validated\"])\n",
    "# tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f47f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(tokenized_datasets, shuffle=False, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e1da46b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'numpy.str_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-5e934f778c28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_all_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             \u001b[0mformat_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1523\u001b[0m         )\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, format_type, format_columns, output_all_columns, format_kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         formatted_output = format_table(\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m         )\n\u001b[1;32m   1513\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatted_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"row\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mformat_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"torch.Tensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mrecursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types)\u001b[0m\n\u001b[1;32m    204\u001b[0m         mapped = [\n\u001b[1;32m    205\u001b[0m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         ]\n\u001b[1;32m    208\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    204\u001b[0m         mapped = [\n\u001b[1;32m    205\u001b[0m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         ]\n\u001b[1;32m    208\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;31m# Singleton first to spare some computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytorch tensors cannot be instantied from an array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstruct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubstruct\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/in_progress/Transgressions/transgressions-env/lib/python3.6/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mdefault_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_tensor_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'numpy.str_'"
     ]
    }
   ],
   "source": [
    "for batch in test_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b963b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenv",
   "language": "python",
   "name": "tenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
