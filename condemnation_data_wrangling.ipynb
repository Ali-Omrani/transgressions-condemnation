{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "603d448e",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49fbfb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping jedi as it is not installed.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall jedi\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0be7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the jsonl dataset\n",
    "data_dir = Path(\"../joes_transgression_ambiguity_project/data/annotated_tweets/ta_tweets.jsonl\")\n",
    "\n",
    "import pandas as pd    \n",
    "jsonObj = pd.read_json(path_or_buf=data_dir, lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021f7abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reject'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonObj.head()[\"answer\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3779822d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'meta', '_input_hash', '_task_hash', 'label', 'score',\n",
       "       'priority', 'spans', '_session_id', '_view_id', 'answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonObj.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b849720e",
   "metadata": {},
   "source": [
    "### Huggingface dataset loading script\n",
    "can be used later to publish the dataset on huggingface hub for better outreach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734138b3",
   "metadata": {},
   "source": [
    "### Testing the dataset loading script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d96bed9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset condemnation_dataset/condemnation (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/geev/.cache/huggingface/datasets/condemnation_dataset/condemnation/1.1.0/4316c50c4e4ffaba14acbd793416d72132d364d43fd27c03abe2ff72eab3c9fc...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath my_dataset_loading_script/condemnation_train.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath my_dataset_loading_script/condemnation_test.csv\n",
      "Dataset condemnation_dataset downloaded and prepared to /home/geev/.cache/huggingface/datasets/condemnation_dataset/condemnation/1.1.0/4316c50c4e4ffaba14acbd793416d72132d364d43fd27c03abe2ff72eab3c9fc. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"my_dataset_loading_script\", name=\"condemnation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4088a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3f5c2a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344, 2)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5067b061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'As multiple sexual allegations come to light with people like <OTHER TARGET 1>, NPR’s -JOHN DOE-, and Michael Fallon, just to name a few...',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "69e77d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9890aad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227819"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d64df113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('text',\n",
       "              ['As multiple sexual allegations come to light with people like <OTHER TARGET 1>, NPR’s -JOHN DOE-, and Michael Fallon, just to name a few...',\n",
       "               'Matt Damon and -JOHN DOE- are trash',\n",
       "               'Thought we all knew tht -JOHN DOE- is a narcissistic asshole??',\n",
       "               '-JOHN DOE- you disgusting pig!',\n",
       "               'Breaking #FoxNews Alert : Amazon executive -JOHN DOE- suspended as sexual harassment accusations surface',\n",
       "               \"The more stories of sexual assault I hear, the more I fear raising a child in today's world. #<OTHER TARGET 1> #<OTHER TARGET 2> #-JOHN DOE- #Trump #Oreilly\",\n",
       "               'In -JOHN DOE-’s worldview, REAL men drug and violently rape women like he does. As a writer, he’s done. But he might have a future in the GOP…',\n",
       "               'im just reading about -JOHN DOE- and i cant believe garbage created something that changed my life and gave me so much happiness',\n",
       "               \"-JOHN DOE- and <OTHER TARGET 1> and their ilk and all the enablers fucked up women's lives and they should all, you know, just eat shit and\",\n",
       "               \"“We are seeing a difference in basic, fundamental, moral, values.” #-JOHN DOE- is literally in prison for sexting a child. Where's the @GOP outrage? #<OTHER TARGET 3>ChildMolester URL\"]),\n",
       "             ('label', [1, 1, 1, 1, 0, 1, 1, 1, 1, 1])])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dataset.set_format(type=\"torch\", columns=[\"label\"])\n",
    "train_dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c1d4fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def encode(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"longest\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "# train_dataset.set_format(type=\"torch\", columns=[\"label\"], output_all_columns=True)\n",
    "train_dataset.set_transform(encode, columns=[\"text\"], output_all_columns=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a8d6fd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  2004,  3674,  4424,  9989,  2272,  2000,  2422,  2007,  2111,\n",
       "          2066,  1026,  2060,  4539,  1015,  1028,  1010, 21411,  1521,  1055,\n",
       "          1011,  2198, 18629,  1011,  1010,  1998,  2745, 16443,  1010,  2074,\n",
       "          2000,  2171,  1037,  2261,  1012,  1012,  1012,   102]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ccd19854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'As multiple sexual allegations come to light with people like <OTHER TARGET 1>, NPR’s -JOHN DOE-, and Michael Fallon, just to name a few...',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.reset_format()\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e24f7",
   "metadata": {},
   "source": [
    "### Generating the Train-Test Split\n",
    "-----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e0c60441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=0.2,\n",
      "            train_size=None)\n",
      "[1509  415  988 ...  864 1143   91]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "data_dir = \"my_dataset_loading_script\"\n",
    "file_name = \"nour_jillian_condemnation_r2_to_r7_maj_vote.jsonl\"\n",
    "def create_train_test(data_dir, file_name):\n",
    "    file_path = os.path.join(data_dir, file_name )\n",
    "    ds_df = pd.read_json(file_path, lines=True)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "    sss.get_n_splits(ds_df, ds_df[\"label\"])\n",
    "    print(sss)\n",
    "#     print(ds_df)\n",
    "    for train_index, test_index in sss.split(ds_df, ds_df[\"label\"]):\n",
    "        print(train_index)\n",
    "        train_df= ds_df.iloc[train_index,:]\n",
    "        test_df= ds_df.iloc[test_index,:]\n",
    "\n",
    "#         test_df = ds_df[test_index]\n",
    "    return train_df, test_df\n",
    "train_df, test_df = create_train_test(data_dir, file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa207517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6264880952380952"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_df.label)/len(train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a620d81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6279761904761905"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_df.label)/len(test_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5084b99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1344"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "de755bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1b8daf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARE_U_SURE = False\n",
    "if ARE_U_SURE:\n",
    "    train_df.to_csv(\"my_dataset_loading_script/condemnation_train.csv\", index=False)\n",
    "    test_df.to_csv(\"my_dataset_loading_script/condemnation_test.csv\", index=False)\n",
    "else:\n",
    "    print(\"This will regenerate the test set! are you sure?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d48613",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c83da0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transgression-env",
   "language": "python",
   "name": "transgression-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
